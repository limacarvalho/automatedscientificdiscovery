{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.models.base.tabular_dataset import TabularDataset\n",
    "from ml.preprocess import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader \n",
    "\n",
    "import torch\n",
    "# from torch.nn import functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = data.get_dataset(f_name = '20220319_covid_merge_processed.csv' , sep = ',')\n",
    "# X_tilda = X.drop(brisk_xgboost.DROP_LIST, axis = 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "# generate indices: instead of the actual data we pass in integers instead\n",
    "train_indices, test_indices, _, _ = train_test_split(\n",
    "    X, y,\n",
    "    # stratify=data.targets,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# generate subset based on indices\n",
    "train_split = Subset(data, train_indices)\n",
    "test_split = Subset(data, test_indices)\n",
    "\n",
    "# create batches\n",
    "train_batches = DataLoader(X, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_batches = DataLoader(test_split.dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = DataLoader(X, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_batches\u001b[39m.\u001b[39;49msize()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "train_batches.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "82",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 82",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_batches):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 82"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch_idx, (data, target) in enumerate(train_batches):\n",
    "    print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModuleClass(pl.LightningDataModule):\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        #Define required parameters here\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.TEST_SIZE = 0.3\n",
    "        self.VAL_SIZE = 0.2\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.SEED = 42\n",
    "        self.train_split = None\n",
    "        self.test_split = None\n",
    "        self.val_split = None\n",
    "\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        # Define steps that should be done on \n",
    "        # every GPU, like splitting data, applying\n",
    "        # transform etc.\n",
    "        # generate indices: instead of the actual data we pass in integers instead\n",
    "        train_indices, test_indices, _, _ = train_test_split(\n",
    "            self.X, \n",
    "            self.y,\n",
    "            # stratify=data.targets,\n",
    "            test_size=self.TEST_SIZE,\n",
    "            random_state=self.SEED\n",
    "        )\n",
    "\n",
    "        # generate subset based on indices\n",
    "        self.train_split = Subset(self.X, train_indices)\n",
    "        self.test_split = Subset(self.X, test_indices)\n",
    "\n",
    "        # print(self.test_split)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # Return DataLoader for Training Data here\n",
    "        return DataLoader(self.train_split, batch_size=self.BATCH_SIZE, shuffle=True)\n",
    "        \n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        # Return DataLoader for Testing Data here\n",
    "        return DataLoader(self.test_split, batch_size=self.BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7fed851b4dc0>\n"
     ]
    }
   ],
   "source": [
    "# Create MNIST DataModule instance\n",
    "data_module = DataModuleClass(X, y, batch_size=64)\n",
    "data_module.setup()\n",
    "train = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 48",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m xb, yb \u001b[39min\u001b[39;00m train:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(xb\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 48"
     ]
    }
   ],
   "source": [
    "for xb, yb in train:\n",
    "    print(xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = iter(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fed63e038e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #sample = {\n",
    "        #    'feature': torch.tensor([self.x[index]], dtype=torch.float32), \n",
    "        #    'label': torch.tensor([self.y[index]], dtype=torch.long)}\n",
    "        #return sample    \n",
    "        num_array = torch.tensor([self.x.loc[index]], dtype=torch.float32)\n",
    "        # num_array = torch.tensor(num_array, dtype = torch.float32)\n",
    "        # label_array = self.df[self.label_col].iloc[idx]\n",
    "        label_array = torch.tensor([self.y.loc[index]], dtype=torch.float32)\n",
    "        return num_array, label_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdataset = CDataset(X, y)\n",
    "dl = DataLoader(cdataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "122",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 122",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# dl.size()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dl))\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 18\u001b[0m in \u001b[0;36mCDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#sample = {\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m#    'feature': torch.tensor([self.x[index]], dtype=torch.float32), \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#    'label': torch.tensor([self.y[index]], dtype=torch.long)}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m#return sample    \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     num_array \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx[index]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# num_array = torch.tensor(num_array, dtype = torch.float32)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# label_array = self.df[self.label_col].iloc[idx]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     label_array \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my[index]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 122"
     ]
    }
   ],
   "source": [
    "# dl.size()\n",
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModuleClass(pl.LightningDataModule):\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        #Define required parameters here\n",
    "        super().__init__()\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.TEST_SIZE = 0.3\n",
    "        self.VAL_SIZE = 0.2\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.SEED = 42\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.val = None\n",
    "        self.dataset = TabularDataset(X, y)\n",
    "\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        # Define steps that should be done on \n",
    "        # every GPU, like splitting data, applying\n",
    "        # transform etc.\n",
    "        # generate indices: instead of the actual data we pass in integers instead\n",
    "        train_indices, test_indices, _, _ = train_test_split(\n",
    "            self.X, \n",
    "            self.y,\n",
    "            # stratify=data.targets,\n",
    "            test_size=self.TEST_SIZE,\n",
    "            random_state=self.SEED\n",
    "        )\n",
    "\n",
    "        # generate subset based on indices\n",
    "        self.train_split = Subset(self.X, train_indices)\n",
    "        self.test_split = Subset(self.X, test_indices)\n",
    "\n",
    "        data_len = self.X.shape[0]\n",
    "\n",
    "        train_size = int((1 - self.TEST_SIZE) * data_len)\n",
    "        test_size = data_len - train_size\n",
    "        \n",
    "        self.train, self.test = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        print(self.train.dataset)\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # Return DataLoader for Training Data here\n",
    "        return DataLoader(self.X, batch_size=self.BATCH_SIZE, shuffle=True)\n",
    "        # print(self.train.indices.shape)\n",
    "        return self.train\n",
    "        \n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        # Return DataLoader for Testing Data here\n",
    "        # return DataLoader(self.test_split, batch_size=self.BATCH_SIZE, shuffle=True)\n",
    "        return self.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_manual = torch.utils.data.DataLoader(\n",
    "    X,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "training_data_size = 0.8\n",
    "train_size = int(training_data_size * len(train_loader_manual))\n",
    "test_size = len(train_loader_manual) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(X, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_manual = torch.utils.data.DataLoader(\n",
    "    train_dataset.dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "37",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 37",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader_manual):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 37"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader_manual):\n",
    "    print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TabularDataset object at 0x7fed7d75bd90>\n"
     ]
    }
   ],
   "source": [
    "data_module = DataModuleClass(X, y, batch_size=64)\n",
    "data_module.setup()\n",
    "train = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 11",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 11"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train):\n",
    "    print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>new_cases_per_million</th>\n",
       "      <th>population_cov</th>\n",
       "      <th>life_expectancy_cov</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area_km2</th>\n",
       "      <th>Density_km2</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>Meningitis</th>\n",
       "      <th>Neoplasms</th>\n",
       "      <th>Fire, heat, and hot substances</th>\n",
       "      <th>Malaria</th>\n",
       "      <th>Drowning</th>\n",
       "      <th>Interpersonal violence</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>Drug use disorders</th>\n",
       "      <th>Tuberculosis</th>\n",
       "      <th>Road injuries</th>\n",
       "      <th>Maternal disorders</th>\n",
       "      <th>Lower respiratory infections</th>\n",
       "      <th>Neonatal disorders</th>\n",
       "      <th>Alcohol use disorders</th>\n",
       "      <th>Exposure to forces of nature</th>\n",
       "      <th>Diarrheal diseases</th>\n",
       "      <th>Environmental heat and cold exposure</th>\n",
       "      <th>Nutritional deficiencies</th>\n",
       "      <th>Self-harm</th>\n",
       "      <th>Conflict and terrorism</th>\n",
       "      <th>Diabetes mellitus</th>\n",
       "      <th>Poisonings</th>\n",
       "      <th>Protein-energy malnutrition</th>\n",
       "      <th>Cardiovascular diseases</th>\n",
       "      <th>Chronic kidney disease</th>\n",
       "      <th>Chronic respiratory diseases</th>\n",
       "      <th>Cirrhosis and other chronic liver diseases</th>\n",
       "      <th>Digestive diseases</th>\n",
       "      <th>Acute hepatitis</th>\n",
       "      <th>Alzheimer's disease and other dementias</th>\n",
       "      <th>Parkinson's disease</th>\n",
       "      <th>Total</th>\n",
       "      <th>air_polution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4171.944</td>\n",
       "      <td>39835428.0</td>\n",
       "      <td>64.83</td>\n",
       "      <td>37171921.0</td>\n",
       "      <td>252071.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.057159</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.022205</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.050299</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>0.065358</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.166779</td>\n",
       "      <td>0.015165</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.585498</td>\n",
       "      <td>52.99812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>92109.327</td>\n",
       "      <td>2872934.0</td>\n",
       "      <td>78.57</td>\n",
       "      <td>2882740.0</td>\n",
       "      <td>11100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.163213</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.447630</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.028272</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.018281</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.031810</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>18.45981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5782.052</td>\n",
       "      <td>44616626.0</td>\n",
       "      <td>76.88</td>\n",
       "      <td>42228408.0</td>\n",
       "      <td>919590.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.026170</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.020735</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.019421</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.455347</td>\n",
       "      <td>32.91557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>473136.492</td>\n",
       "      <td>77354.0</td>\n",
       "      <td>83.73</td>\n",
       "      <td>77006.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219463</td>\n",
       "      <td>0.020778</td>\n",
       "      <td>0.050645</td>\n",
       "      <td>0.015583</td>\n",
       "      <td>0.035062</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.762278</td>\n",
       "      <td>9.51265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2898.709</td>\n",
       "      <td>33933611.0</td>\n",
       "      <td>61.15</td>\n",
       "      <td>30809787.0</td>\n",
       "      <td>481351.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.041516</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.035002</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.054535</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.041490</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.041987</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.013090</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.083493</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.029117</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.562613</td>\n",
       "      <td>28.02152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>17289.124</td>\n",
       "      <td>28704947.0</td>\n",
       "      <td>72.06</td>\n",
       "      <td>28887118.0</td>\n",
       "      <td>352143.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.120369</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.212932</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.016243</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.627702</td>\n",
       "      <td>22.21524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>23856.549</td>\n",
       "      <td>98168829.0</td>\n",
       "      <td>75.40</td>\n",
       "      <td>95545962.0</td>\n",
       "      <td>127782.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.117811</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.019552</td>\n",
       "      <td>0.025279</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.251357</td>\n",
       "      <td>0.022487</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.024739</td>\n",
       "      <td>0.032765</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.020367</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.648126</td>\n",
       "      <td>20.19471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>366.236</td>\n",
       "      <td>30490639.0</td>\n",
       "      <td>66.12</td>\n",
       "      <td>28498683.0</td>\n",
       "      <td>203848.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.041114</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.022068</td>\n",
       "      <td>0.066607</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.047027</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.566672</td>\n",
       "      <td>44.64506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>16236.562</td>\n",
       "      <td>18920657.0</td>\n",
       "      <td>63.89</td>\n",
       "      <td>17351708.0</td>\n",
       "      <td>290583.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.011901</td>\n",
       "      <td>0.056415</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.027530</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.129901</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.041633</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.104641</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.037622</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.691580</td>\n",
       "      <td>25.92371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>15266.334</td>\n",
       "      <td>15092171.0</td>\n",
       "      <td>61.49</td>\n",
       "      <td>14438802.0</td>\n",
       "      <td>150871.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.085554</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.143516</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.072478</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.008962</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.059624</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.123348</td>\n",
       "      <td>0.015874</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.855611</td>\n",
       "      <td>20.84664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location  new_cases_per_million  ...     Total  air_polution\n",
       "0           0               4171.944  ...  0.585498      52.99812\n",
       "1           1              92109.327  ...  0.771315      18.45981\n",
       "2           2               5782.052  ...  0.455347      32.91557\n",
       "3           3             473136.492  ...  0.762278       9.51265\n",
       "4           4               2898.709  ...  0.562613      28.02152\n",
       "..        ...                    ...  ...       ...           ...\n",
       "186       186              17289.124  ...  0.627702      22.21524\n",
       "187       187              23856.549  ...  0.648126      20.19471\n",
       "188       188                366.236  ...  0.566672      44.64506\n",
       "189       189              16236.562  ...  0.691580      25.92371\n",
       "190       190              15266.334  ...  0.855611      20.84664\n",
       "\n",
       "[191 rows x 41 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 41)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train, test = random_split(dataset, [100, 91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BriskModel(pl.LightningModule): \n",
    "    def __init__(self, hidden_size = 40): \n",
    "        super(BriskModel, self).__init__() \n",
    "\n",
    "        # Defining learning rate\n",
    "        self.lr = 0.089\n",
    "\n",
    "        # Defining our model architecture\n",
    "        self.layer_0 = nn.BatchNorm1d(40)\n",
    "        self.layer_1 = nn.Linear(hidden_size, 243)\n",
    "        self.layer_2 = nn.Linear(hidden_size, 90)\n",
    "        self.layer_3 = nn.Linear(hidden_size, 22)\n",
    "        self.layer_final = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # nn.init.xavier_normal_(self.layer_1.weight)\n",
    "        # self.layer_2 = nn.BatchNorm1d(16)\n",
    "        # self.layer_3 = nn.Linear(16, 96)\n",
    "        # nn.init.xavier_normal_(self.layer_3.weight)\n",
    "        # self.layer_4 = nn.Linear(96, 1)\n",
    "        # nn.init.xavier_normal_(self.layer_4.weight)\n",
    "        # self.out = nn.Flatten(0, 1)\n",
    "                  \n",
    "          \n",
    "        # Defining loss \n",
    "        ##self.loss = nn.BCEWithLogitsLoss()\n",
    "        # self.loss = nn.MSELoss()\n",
    "    \n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "#        return self.model(x)\n",
    "\n",
    "\n",
    "        # Defining the forward pass of the model\n",
    "        # print(x)\n",
    "        # batch_size, _= x.size() \n",
    "        # x = x.view(batch_size, -1) \n",
    "        \n",
    "        # Pass the tensor through the layers\n",
    "        #x = self.layer_1(x)\n",
    "        #x = nn.relu(x)\n",
    "        #x = self.layer_2(x)\n",
    "        #x = self.layer_3(x)\n",
    "        #x = F.relu(x)\n",
    "        #x = self.layer_4(x)\n",
    "        #x = F.sigmoid(x)\n",
    "        #x = self.out(x)\n",
    "        #return x\n",
    "\n",
    "        x = self.layer_0(x)\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.layer_out(self.layer_final(x))\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "          # Defining and returning the optimizer for our model\n",
    "        # with the defines parameters\n",
    "        #return torch.optim.SGD(self.parameters(), lr = self.lr) \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx): \n",
    "        # Defining training steps for our mode\n",
    "\n",
    "        x, y = train_batch\n",
    "        pred = self.forward(x)\n",
    "        loss = nn.MSELoss(pred, y)\n",
    "        return loss\n",
    "\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)#.to(torch.float32)\n",
    "        \n",
    "        logits = torch.round(torch.sigmoid(logits))\n",
    "        \n",
    "        # logits = logits.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "        # print('train_y:' + str(len(y)) + ' train_prec_y:' + str(len(logits)))\n",
    "        # print('train:' + str(max(logits)) + ' min:' + str(min(logits)))\n",
    "        loss = self.loss(logits, y)\n",
    "        \n",
    "        bin_acc = binary_acc(logits, y)  \n",
    "        \n",
    "        print('train los:' + str(loss) + ' train acc: '+ str(bin_acc))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = nn.MSELoss(preds, y)\n",
    "        # preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = nn.MSELoss(preds, y)\n",
    "        # preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "clf = BriskModel() \n",
    "# data = DataModuleClass() \n",
    "data = DataModuleClass(X, y, batch_size=64)\n",
    "trainer = pl.Trainer(min_epochs=10, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataModuleClass at 0x7fed84ff17c0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/lightning_logs\n",
      "\n",
      "  | Name          | Type        | Params\n",
      "----------------------------------------------\n",
      "0 | layer_0       | BatchNorm1d | 80    \n",
      "1 | layer_1       | Linear      | 10.0 K\n",
      "2 | layer_2       | Linear      | 3.7 K \n",
      "3 | layer_3       | Linear      | 902   \n",
      "4 | layer_final   | Linear      | 41    \n",
      "5 | relu          | ReLU        | 0     \n",
      "6 | val_accuracy  | Accuracy    | 0     \n",
      "7 | test_accuracy | Accuracy    | 0     \n",
      "----------------------------------------------\n",
      "14.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.7 K    Total params\n",
      "0.059     Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected data to be int, Sequence or Mapping, but got Subset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/pytorch.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(clf, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    737\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1166\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1168\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1252\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1283\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1282\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:195\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_skip()\n\u001b[1;32m    193\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 195\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_run_start(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    197\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    198\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:211\u001b[0m, in \u001b[0;36mFitLoop.on_run_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iteration_based_training():\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_progress\u001b[39m.\u001b[39mcurrent\u001b[39m.\u001b[39mcompleted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_progress\u001b[39m.\u001b[39mcurrent\u001b[39m.\u001b[39mprocessed\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mreset_train_dataloader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mlightning_module)\n\u001b[1;32m    212\u001b[0m \u001b[39m# reload the evaluation dataloaders too for proper display in the progress bar\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_loop\u001b[39m.\u001b[39m_should_check_val_epoch():\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1844\u001b[0m, in \u001b[0;36mTrainer.reset_train_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[39m# wrap the sequence of train loaders to a CombinedLoader object for computing the num_training_batches\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, CombinedLoader):\n\u001b[0;32m-> 1844\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader \u001b[39m=\u001b[39m CombinedLoader(loaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_connector\u001b[39m.\u001b[39;49mmultiple_trainloader_mode)\n\u001b[1;32m   1846\u001b[0m module \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule\n\u001b[1;32m   1847\u001b[0m orig_train_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_training_batches \u001b[39m=\u001b[39m (\n\u001b[1;32m   1848\u001b[0m     \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader)\n\u001b[1;32m   1849\u001b[0m     \u001b[39mif\u001b[39;00m has_len_all_ranks(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, module)\n\u001b[1;32m   1850\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1851\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py:349\u001b[0m, in \u001b[0;36mCombinedLoader.__init__\u001b[0;34m(self, loaders, mode)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m mode\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmax_size_cycle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_loaders_max_size_cycle()\n\u001b[1;32m    351\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loaders_iter_state_dict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py:456\u001b[0m, in \u001b[0;36mCombinedLoader._wrap_loaders_max_size_cycle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m\"\"\"Wraps all loaders to make sure they are cycled until the longest loader is exhausted.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m    the wrapped loaders\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m all_lengths \u001b[39m=\u001b[39m apply_to_collection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaders, Iterable, get_len, wrong_dtype\u001b[39m=\u001b[39m(Sequence, Mapping))\n\u001b[0;32m--> 456\u001b[0m length \u001b[39m=\u001b[39m _nested_calc_num_data(all_lengths, \u001b[39mmax\u001b[39;49m)\n\u001b[1;32m    458\u001b[0m \u001b[39m# multiple loaders\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaders, (Sequence, Mapping)):\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py:596\u001b[0m, in \u001b[0;36m_nested_calc_num_data\u001b[0;34m(data, compute_func)\u001b[0m\n\u001b[1;32m    593\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    595\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Sequence):\n\u001b[0;32m--> 596\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected data to be int, Sequence or Mapping, but got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(data)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    598\u001b[0m new_data \u001b[39m=\u001b[39m []\n\u001b[1;32m    600\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data:\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected data to be int, Sequence or Mapping, but got Subset"
     ]
    }
   ],
   "source": [
    "trainer.fit(clf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6ff7914d2bc405bfa61a835d0564ba294eb5f3f9b4c24865f45d9397593b123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
