{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.models.base.tabular_dataset import TabularDataset\n",
    "from ml.preprocess import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "# from torch.nn import functional as F\n",
    "from torchmetrics import Accuracy, MeanSquaredError\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_orig, y = data.get_dataset(f_name = '20220319_covid_merge_processed.csv' , sep = ',')\n",
    "# X_tilda = X.drop(brisk_xgboost.DROP_LIST, axis = 1)\n",
    "X = X_train_orig.drop(['location'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TabularDataset(Dataset):    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        # num_array = torch.tensor(num_array, dtype = torch.float32)\n",
    "        # num_array = torch.tensor(self.x.loc[index], dtype=torch.float32)        \n",
    "        num_array = torch.tensor(self.x.iloc[index], dtype=torch.float32)        \n",
    "        # label_array = self.df[self.label_col].iloc[idx]\n",
    "        label_array = torch.tensor(self.y.iloc[index], dtype=torch.float32)\n",
    "        # label_array = label_array.reshape(self.x[0], )\n",
    "        return num_array, label_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class BriskDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        #Define required parameters here\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.TEST_SIZE = 0.3\n",
    "        self.VAL_SIZE = 0.2\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.SEED = 42\n",
    "        # self.train_dataset = None\n",
    "        # self.test_dataset = None\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.pred_dataset = None\n",
    "\n",
    "        # self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, random_state=self.SEED, test_size=self.TEST_SIZE)\n",
    "\n",
    "        X_train, self.X_test, y_train, self.y_test = train_test_split(self.X, self.y, random_state=self.SEED,\n",
    "                                                                                                 shuffle=True, test_size=self.TEST_SIZE)\n",
    "    \n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X_train, y_train, random_state=self.SEED,\n",
    "                                                                                                 shuffle=True, test_size=self.VAL_SIZE)\n",
    "\n",
    "\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        # Define steps that should be done on \n",
    "        # every GPU, like splitting data, applying\n",
    "        # transform etc.\n",
    "        # generate indices: instead of the actual data we pass in integers instead\n",
    "        # print(self.test_split)\n",
    "\n",
    "        # self.X = StandardScaler().fit_transform(self.X)\n",
    "\n",
    "\n",
    "        # print(X_train.shape)\n",
    "        # self.train_dataset = TabularDataset(X_train, y_train)\n",
    "         #self.test_dataset = TabularDataset(X_test, y_test)\n",
    " \n",
    "        # self.train_split = DataLoader(cdataset, batch_size=8, shuffle=True)\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = TabularDataset(self.X_train, self.y_train)\n",
    "            self.val_dataset = TabularDataset(self.X_val, self.y_val)\n",
    "            # print('fit')\n",
    "\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.test_dataset = TabularDataset(self.X_test, self.y_test)\n",
    "            # print('test')\n",
    "            \n",
    "\n",
    "        if stage == \"predict\":\n",
    "            self.pred_dataset = TabularDataset(self.X_test, self.y_test)\n",
    "            # print('predict')\n",
    "        \n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Return DataLoader for Training Data here\n",
    "        # print('train_loader')        \n",
    "        return DataLoader(self.train_dataset, batch_size=self.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Return DataLoader for Testing Data here\n",
    "        # print('val_dataloader')\n",
    "        dl = DataLoader(self.val_dataset, batch_size=self.BATCH_SIZE, shuffle=False)\n",
    "        return dl\n",
    "\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        # Return DataLoader for Testing Data here\n",
    "        # print('test_dataloader')\n",
    "        return DataLoader(self.test_dataset, batch_size=self.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        # print('predict_dataloader')\n",
    "        return DataLoader(self.pred_dataset, batch_size=self.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BriskModel(pl.LightningModule): \n",
    "    def __init__(self, input_dim = 40): \n",
    "        super(BriskModel, self).__init__() \n",
    "\n",
    "        # Defining learning rate\n",
    "        self.lr = 0.004\n",
    "        #self.batch_size = batch_size\n",
    "        #self.X = X\n",
    "        #self.y = y\n",
    "        #hidden_size = X.shape[0]\n",
    "\n",
    "        # Defining our model architecture\n",
    "        self.layer_0 = nn.BatchNorm1d(num_features = input_dim)\n",
    "        # self.layer_0 = nn.Linear(hidden_size, 200)\n",
    "        self.layer_1 = nn.Linear(in_features = input_dim, out_features = 115)\n",
    "        self.layer_2 = nn.Linear(115, 99)\n",
    "        self.layer_3 = nn.Linear(99, 164)\n",
    "        self.layer_final = nn.Linear(164, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.flatten = torch.nn.Flatten(0, 1)\n",
    "\n",
    "        # nn.init.xavier_normal_(self.layer_1.weight)\n",
    "        # self.layer_2 = nn.BatchNorm1d(16)\n",
    "        # self.layer_3 = nn.Linear(16, 96)\n",
    "        # nn.init.xavier_normal_(self.layer_3.weight)\n",
    "        # self.layer_4 = nn.Linear(96, 1)\n",
    "        # nn.init.xavier_normal_(self.layer_4.weight)\n",
    "        # self.out = nn.Flatten(0, 1)\n",
    "                  \n",
    "          \n",
    "        # Defining loss \n",
    "        ##self.loss = nn.BCEWithLogitsLoss()\n",
    "        # self.loss = nn.MSELoss()\n",
    "    \n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "\n",
    "        self.predictions = []\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "#        return self.model(x)\n",
    "\n",
    "        # Defining the forward pass of the model\n",
    "        # print(x)\n",
    "        # batch_size, _= x.size() \n",
    "        # x = x.view(batch_size, -1) \n",
    "        \n",
    "        # Pass the tensor through the layers\n",
    "        #x = self.layer_1(x)\n",
    "        #x = nn.relu(x)\n",
    "        #x = self.layer_2(x)\n",
    "        #x = self.layer_3(x)\n",
    "        #x = F.relu(x)\n",
    "        #x = self.layer_4(x)\n",
    "        #x = F.sigmoid(x)\n",
    "        #x = self.out(x)\n",
    "        #return x\n",
    "\n",
    "        x = self.relu(self.layer_0(x))\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.flatten(self.layer_final(x))\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "          # Defining and returning the optimizer for our model\n",
    "        # with the defines parameters\n",
    "        #return torch.optim.SGD(self.parameters(), lr = self.lr) \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx): \n",
    "        # Defining training steps for our mode\n",
    "        x, y = train_batch        \n",
    "        y = y.reshape(y.shape[0], )\n",
    "\n",
    "        pred = self.forward(x)        \n",
    "\n",
    "        #print(pred.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # mean_squared_error(pred, y)\n",
    "\n",
    "        loss = nn.MSELoss()(pred, y)\n",
    "\n",
    "        # print(f'train los:{loss}')\n",
    "\n",
    "        # self.log(\"my_loss\", loss, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "\n",
    "        self.train_mse.update(pred, y)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)#.to(torch.float32)\n",
    "        \n",
    "        logits = torch.round(torch.sigmoid(logits))\n",
    "        \n",
    "        # logits = logits.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "        # print('train_y:' + str(len(y)) + ' train_prec_y:' + str(len(logits)))\n",
    "        # print('train:' + str(max(logits)) + ' min:' + str(min(logits)))\n",
    "        loss = self.loss(logits, y)\n",
    "        \n",
    "        bin_acc = binary_acc(logits, y)  \n",
    "        \n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_end(self) -> None:\n",
    "        print(f'training ended: MSE {self.train_mse.compute()}')\n",
    "        return super().on_train_end()\n",
    "\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.reshape(y.shape[0], )\n",
    "        pred = self.forward(x)\n",
    "        \n",
    "\n",
    "        loss = nn.MSELoss()(pred, y)\n",
    "\n",
    "        # print(f'val loss {loss}')\n",
    "        # self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.val_mse.update(pred, y)\n",
    "#       \n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        #self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        # self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "\n",
    "    def on_validation_end(self) -> None:\n",
    "        print(f'validation ended: MSE {self.val_mse.compute()}')\n",
    "        return super().on_validation_end()\n",
    "\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        x, y = test_batch\n",
    "        y = y.reshape(y.shape[0], )\n",
    "        pred = self.forward(x)\n",
    "        loss = nn.MSELoss()(pred, y)\n",
    "\n",
    "        self.test_mse.update(pred, y)\n",
    "\n",
    "        list_np = pred.cpu().detach().numpy()\n",
    "\n",
    "        self.predictions.extend(list_np)\n",
    "        # preds = torch.argmax(logits, dim=1)\n",
    "        #self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        #self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        #self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def on_test_end(self) -> None:\n",
    "        print(f'test ended: MSE {self.test_mse.compute()}')\n",
    "        return super().on_test_end()\n",
    "\n",
    "    def on_predict_end(self) -> None:\n",
    "        \n",
    "        return super().on_predict_end()\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    # def prepare_data(self):\n",
    "    #     # download\n",
    "    #     self.TEST_SIZE = 0.3\n",
    "    #     self.VAL_SIZE = 0.2\n",
    "    #     self.SEED = 42\n",
    "    #     self.train_dataset = None\n",
    "    #     self.test_dataset = None\n",
    "    #     self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, random_state=self.SEED, test_size=self.TEST_SIZE)\n",
    "\n",
    "    #     self.train_dataset = TabularDataset(self.X_train, self.y_train)\n",
    "    #     self.test_dataset = TabularDataset(self.X_test, self.y_test)\n",
    "\n",
    "\n",
    "    #def train_dataloader(self):\n",
    "     \n",
    "    #     return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    # def val_dataloader(self):\n",
    "    #     return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    # def test_dataloader(self):\n",
    "    #     return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation ended: MSE 3367578.0\n",
      "validation ended: MSE 2784127.75\n",
      "validation ended: MSE 2362753.25\n",
      "validation ended: MSE 2036817.0\n",
      "validation ended: MSE 1825850.625\n",
      "validation ended: MSE 1690776.5\n",
      "validation ended: MSE 1623812.0\n",
      "validation ended: MSE 1613365.875\n",
      "validation ended: MSE 1654475.875\n",
      "validation ended: MSE 1741227.875\n",
      "validation ended: MSE 1864921.75\n",
      "validation ended: MSE 2010703.375\n",
      "validation ended: MSE 2165355.5\n",
      "validation ended: MSE 2323644.25\n",
      "validation ended: MSE 2480604.75\n",
      "validation ended: MSE 2636054.25\n",
      "training ended: MSE 674998.875\n"
     ]
    }
   ],
   "source": [
    "clf = BriskModel(input_dim = 40)\n",
    "X_scalar = StandardScaler().fit_transform(X)\n",
    "data = BriskDataModule(X_scalar, y, batch_size=8)\n",
    "# data.setup()\n",
    "trainer = pl.Trainer(min_epochs=10, max_epochs=15, enable_progress_bar=False)\n",
    "trainer.fit(clf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation ended: MSE 2772766.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(clf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ended: MSE 1159812.375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(clf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[642.51807,\n",
       " 22.145275,\n",
       " 920.18005,\n",
       " 885.9208,\n",
       " 1534.6659,\n",
       " 119.19596,\n",
       " 1084.5883,\n",
       " 46.34888,\n",
       " 1012.996,\n",
       " 1562.5753,\n",
       " 2141.5884,\n",
       " 1670.9703,\n",
       " 3010.036,\n",
       " 863.91846,\n",
       " 58.483875,\n",
       " 2410.4988,\n",
       " 749.8333,\n",
       " 39.044827,\n",
       " 1634.5511,\n",
       " 826.71204,\n",
       " 488.48053,\n",
       " 237.09915,\n",
       " 157.33914,\n",
       " 1438.2742,\n",
       " 493.89413,\n",
       " 878.25464,\n",
       " 502.72635,\n",
       " 406.95267,\n",
       " 734.8441,\n",
       " 2244.5544,\n",
       " 3273.3074,\n",
       " 846.9385,\n",
       " 191.31969,\n",
       " 2687.222,\n",
       " 1508.3539,\n",
       " 1652.4308,\n",
       " 368.1294,\n",
       " 2151.7327,\n",
       " 116.3273,\n",
       " 96.399956,\n",
       " 1115.7792,\n",
       " 22.405722,\n",
       " 586.69684,\n",
       " 1858.5703,\n",
       " 1574.1672,\n",
       " 1529.2097,\n",
       " 1093.684,\n",
       " 58.240833,\n",
       " 2192.2852,\n",
       " 1058.5497,\n",
       " 795.8325,\n",
       " 819.9603,\n",
       " 1591.4465,\n",
       " 94.195015,\n",
       " 109.405045,\n",
       " 944.9503,\n",
       " 2539.932,\n",
       " 1346.3926]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countary</th>\n",
       "      <th>deaths</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>642.518066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4896.644</td>\n",
       "      <td>22.145275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1486.844</td>\n",
       "      <td>920.180054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>55.799</td>\n",
       "      <td>885.920776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>153.473</td>\n",
       "      <td>1534.665894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2252.476</td>\n",
       "      <td>119.195961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>146.353</td>\n",
       "      <td>1084.588257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.348881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>604.743</td>\n",
       "      <td>1012.995972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>45.966</td>\n",
       "      <td>1562.575317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1900.397</td>\n",
       "      <td>2141.588379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>79.899</td>\n",
       "      <td>1670.970337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3204.928</td>\n",
       "      <td>3010.035889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>29.081</td>\n",
       "      <td>863.918457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3822.309</td>\n",
       "      <td>58.483875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>617.233</td>\n",
       "      <td>2410.498779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1043.390</td>\n",
       "      <td>749.833313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>354.972</td>\n",
       "      <td>39.044827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>113.700</td>\n",
       "      <td>1634.551147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>102.229</td>\n",
       "      <td>826.712036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>691.002</td>\n",
       "      <td>488.480530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1556.962</td>\n",
       "      <td>237.099152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1592.490</td>\n",
       "      <td>157.339142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>912.035</td>\n",
       "      <td>1438.274170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>108.901</td>\n",
       "      <td>493.894135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>164.589</td>\n",
       "      <td>878.254639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2036.132</td>\n",
       "      <td>502.726349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2485.236</td>\n",
       "      <td>406.952667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2651.960</td>\n",
       "      <td>734.844116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2820.237</td>\n",
       "      <td>2244.554443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>10.335</td>\n",
       "      <td>3273.307373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2648.125</td>\n",
       "      <td>846.938477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>78.378</td>\n",
       "      <td>191.319687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>35.511</td>\n",
       "      <td>2687.221924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>34.318</td>\n",
       "      <td>1508.353882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>22.357</td>\n",
       "      <td>1652.430786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1078.310</td>\n",
       "      <td>368.129395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>394.845</td>\n",
       "      <td>2151.732666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>202.467</td>\n",
       "      <td>116.327301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>321.415</td>\n",
       "      <td>96.399956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2168.010</td>\n",
       "      <td>1115.779175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.405722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1790.229</td>\n",
       "      <td>586.696838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>90.771</td>\n",
       "      <td>1858.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>867.739</td>\n",
       "      <td>1574.167236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>159.134</td>\n",
       "      <td>1529.209717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>1562.173</td>\n",
       "      <td>1093.683960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58.240833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    countary    deaths  predictions\n",
       "0          0     0.000   642.518066\n",
       "1          1  4896.644    22.145275\n",
       "2          2  1486.844   920.180054\n",
       "3          3    55.799   885.920776\n",
       "4          4   153.473  1534.665894\n",
       "5          5  2252.476   119.195961\n",
       "6          6   146.353  1084.588257\n",
       "7          7     0.000    46.348881\n",
       "8          8   604.743  1012.995972\n",
       "9          9    45.966  1562.575317\n",
       "10        10  1900.397  2141.588379\n",
       "11        11    79.899  1670.970337\n",
       "12        12  3204.928  3010.035889\n",
       "13        13    29.081   863.918457\n",
       "14        14  3822.309    58.483875\n",
       "15        15   617.233  2410.498779\n",
       "16        16  1043.390   749.833313\n",
       "17        17   354.972    39.044827\n",
       "18        18   113.700  1634.551147\n",
       "19        19   102.229   826.712036\n",
       "20        20   691.002   488.480530\n",
       "21        21  1556.962   237.099152\n",
       "22        22  1592.490   157.339142\n",
       "23        23   912.035  1438.274170\n",
       "24        24   108.901   493.894135\n",
       "25        25   164.589   878.254639\n",
       "26        26  2036.132   502.726349\n",
       "27        27  2485.236   406.952667\n",
       "28        28  2651.960   734.844116\n",
       "29        29  2820.237  2244.554443\n",
       "30        30    10.335  3273.307373\n",
       "31        31  2648.125   846.938477\n",
       "32        32    78.378   191.319687\n",
       "33        33    35.511  2687.221924\n",
       "34        34    34.318  1508.353882\n",
       "35        35    22.357  1652.430786\n",
       "36        36  1078.310   368.129395\n",
       "37        37   394.845  2151.732666\n",
       "38        38   202.467   116.327301\n",
       "39        39   321.415    96.399956\n",
       "40        40  2168.010  1115.779175\n",
       "41        41     0.000    22.405722\n",
       "42        42  1790.229   586.696838\n",
       "43        43    90.771  1858.570312\n",
       "44        44   867.739  1574.167236\n",
       "45        45   159.134  1529.209717\n",
       "46        46  1562.173  1093.683960\n",
       "47        47     0.000    58.240833"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(X_train_orig['location'].values, y_test.values.reshape(48, ), clf.predictions )),\n",
    "               columns =['countary', 'deaths', 'predictions'])\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BriskModel(\n",
       "  (layer_0): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer_1): Linear(in_features=40, out_features=115, bias=True)\n",
       "  (layer_2): Linear(in_features=115, out_features=99, bias=True)\n",
       "  (layer_3): Linear(in_features=99, out_features=164, bias=True)\n",
       "  (layer_final): Linear(in_features=164, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=0, end_dim=1)\n",
       "  (val_accuracy): Accuracy()\n",
       "  (test_accuracy): Accuracy()\n",
       "  (val_mse): MeanSquaredError()\n",
       "  (train_mse): MeanSquaredError()\n",
       "  (test_mse): MeanSquaredError()\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "briskmodel_loaded = BriskModel(input_dim = 40)\n",
    "\n",
    "briskmodel_loaded.load_from_checkpoint(checkpoint_path='./lightning_logs/version_42/checkpoints/epoch=14-step=210.ckpt')\n",
    "\n",
    "# clf.load_from_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6ff7914d2bc405bfa61a835d0564ba294eb5f3f9b4c24865f45d9397593b123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
