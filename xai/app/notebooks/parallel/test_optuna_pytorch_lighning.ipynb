{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optuna example that optimizes multi-layer perceptrons using PyTorch Lightning.\n",
    "In this example, we optimize the validation accuracy of fashion product recognition using\n",
    "PyTorch Lightning, and FashionMNIST. We optimize the neural network architecture. As it is too time\n",
    "consuming to use the whole FashionMNIST dataset, we here use a small subset of it.\n",
    "You can run this example as follows, pruning can be turned on and off with the `--pruning`\n",
    "argument.\n",
    "    $ python pytorch_lightning_simple.py [--pruning]\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from packaging import version\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version.parse(pl.__version__) < version.parse(\"1.0.2\"):\n",
    "    raise RuntimeError(\"PyTorch Lightning>=1.0.2 is required for this example.\")\n",
    "\n",
    "PERCENT_VALID_EXAMPLES = 0.1\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 10\n",
    "DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout: float, output_dims: List[int]):\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        input_dim: int = 28 * 28\n",
    "        for output_dim in output_dims:\n",
    "            layers.append(nn.Linear(input_dim, output_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = output_dim\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, CLASSES))\n",
    "\n",
    "        self.layers: nn.Module = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.layers(data)\n",
    "        return F.log_softmax(logits, dim=1)\n",
    "\n",
    "\n",
    "class LightningNet(pl.LightningModule):\n",
    "    def __init__(self, dropout: float, output_dims: List[int]):\n",
    "        super().__init__()\n",
    "        self.model = Net(dropout, output_dims)\n",
    "\n",
    "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(data.view(-1, 28 * 28))\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int) -> torch.Tensor:\n",
    "        data, target = batch\n",
    "        output = self(data)\n",
    "        return F.nll_loss(output, target)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx: int) -> None:\n",
    "        data, target = batch\n",
    "        output = self(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        accuracy = pred.eq(target.view_as(pred)).float().mean()\n",
    "        self.log(\"val_acc\", accuracy)\n",
    "        self.log(\"hp_metric\", accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self) -> optim.Optimizer:\n",
    "        return optim.Adam(self.model.parameters())\n",
    "\n",
    "\n",
    "class FashionMNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        self.mnist_test = datasets.FashionMNIST(\n",
    "            self.data_dir, train=False, download=True, transform=transforms.ToTensor()\n",
    "        )\n",
    "        mnist_full = datasets.FashionMNIST(\n",
    "            self.data_dir, train=True, download=True, transform=transforms.ToTensor()\n",
    "        )\n",
    "        self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.mnist_train, batch_size=self.batch_size, shuffle=True, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.mnist_val, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.mnist_test, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "\n",
    "    # We optimize the number of layers, hidden units in each layer and dropouts.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "    output_dims = [\n",
    "        trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True) for i in range(n_layers)\n",
    "    ]\n",
    "\n",
    "    model = LightningNet(dropout, output_dims)\n",
    "    datamodule = FashionMNISTDataModule(data_dir=DIR, batch_size=BATCHSIZE)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        logger=True,\n",
    "        limit_val_batches=PERCENT_VALID_EXAMPLES,\n",
    "        enable_checkpointing=False,\n",
    "        max_epochs=EPOCHS,\n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_acc\")],\n",
    "    )\n",
    "    hyperparameters = dict(n_layers=n_layers, dropout=dropout, output_dims=output_dims)\n",
    "    trainer.logger.log_hyperparams(hyperparameters)\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--pruning]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"d4faee66-c9c8-4f69-9bc1-13cd00067a62\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/vagrant/.local/share/jupyter/runtime/kernel-v2-362ecxhNiC0lK8i.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description=\"PyTorch Lightning example.\")\n",
    "parser.add_argument(\n",
    "    \"--pruning\",\n",
    "    \"-p\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Activate the pruning feature. `MedianPruner` stops unpromising \"\n",
    "    \"trials at the early stages of training.\",\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\n",
    "pruner: optuna.pruners.BasePruner = (\n",
    "    optuna.pruners.MedianPruner() if args.pruning else optuna.pruners.NopPruner()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-18 16:34:34,178]\u001b[0m A new study created in memory with name: no-name-3caebf71-5683-4878-ac44-94b788234e9b\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae095fd078f4c558ae341b696a9b7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/train-images-idx3-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812f9a82fe01403b84b760dabd211b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5875af00b9204e93a2f922cfb60c051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee53e0c269a400c8e8351549e8a98b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /mnt/c/Users/rwmas/GitHub/xai/xai_api/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | Net  | 22.5 K\n",
      "-------------------------------\n",
      "22.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.5 K    Total params\n",
      "0.090     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0abf9c1f1144fdbe9cb4f8622198f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e48914a10374ec1a410ee4925a9bcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749daba5846c4e138a18034ddbdf0e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9580662a9f42188e0685e39f62b8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "\u001b[32m[I 2022-09-18 16:35:18,021]\u001b[0m Trial 0 finished with value: 0.837890625 and parameters: {'n_layers': 2, 'dropout': 0.2509245006357079, 'n_units_l0': 27, 'n_units_l1': 33}. Best is trial 0 with value: 0.837890625.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | Net  | 12.4 K\n",
      "-------------------------------\n",
      "12.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.4 K    Total params\n",
      "0.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c88b84caf24c039486ba9c9b390fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e8ce6e657e44e58aab5af9464e025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10, timeout=600)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is\n",
    "from utils import dasker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-18 16:40:31,965]\u001b[0m A new study created in memory with name: no-name-09928987-158e-4dd0-8332-f2e53ab40872\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dashboard is available at http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-09-18 16:40:32,184]\u001b[0m Trial 2 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,189 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-1a54e9c86e7840e288fcbecc31035569\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7fa3bcf0db80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7fa39c818670>, [<optuna.study.Study object at 0x7fa30e454dc0>, <function objective at 0x7fa30e3c7790>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,204]\u001b[0m Trial 9 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,211 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-3f8c81d9fdef47b3b913937b281f6b4c\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7f0858323b80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7f0837c0d670>, [<optuna.study.Study object at 0x7f07a90708e0>, <function objective at 0x7f07a8f4d4c0>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,217]\u001b[0m Trial 7 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,222 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-b63adcd3a62a41ffb092f550706821ba\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7faa5d28db80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7faa3cb84670>, [<optuna.study.Study object at 0x7fa9adff0af0>, <function objective at 0x7fa9aded4670>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,226]\u001b[0m Trial 0 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,232 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-d930f42d79d248efab3bddb8937c4a9e\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7fa3bcf0db80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7fa39c818670>, [<optuna.study.Study object at 0x7fa30efaf580>, <function objective at 0x7fa30e5e4dc0>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,253]\u001b[0m Trial 3 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,256 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-8b7aed3d36984d00aa58d318e94e970b\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7f6967008b80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7f6946908670>, [<optuna.study.Study object at 0x7f68b90ba670>, <function objective at 0x7f68b8546ee0>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,263]\u001b[0m Trial 1 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,266 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-045139948e8d49a4861e5d7442eea221\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7f6967008b80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7f6946908670>, [<optuna.study.Study object at 0x7f68b90bac40>, <function objective at 0x7f68b84c7430>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,268]\u001b[0m Trial 4 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,272 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-30309e588b9b400e99b0cf4c139120c1\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7faa5d28db80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7faa3cb84670>, [<optuna.study.Study object at 0x7fa9adff0fd0>, <function objective at 0x7fa9aded4700>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,290]\u001b[0m Trial 5 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,294 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-5ec1fb4677a54391850d10d15decbd9b\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7f0858323b80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7f0837c0d670>, [<optuna.study.Study object at 0x7f07a9070f40>, <function objective at 0x7f07a9023b80>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,302]\u001b[0m Trial 6 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,305 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-29c7ca3318394664bd3985074a32251b\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7faa5d28db80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7faa3cb84670>, [<optuna.study.Study object at 0x7fa9ae000ee0>, <function objective at 0x7fa9adf36e50>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n",
      "\u001b[33m[W 2022-09-18 16:40:32,322]\u001b[0m Trial 8 failed because of the following error: AssertionError('daemonic processes are not allowed to have children')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/tmp/ipykernel_7848/3099996763.py\", line 13, in objective\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 345, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 534, in __init__\n",
      "    self._setup_on_init()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 619, in _setup_on_init\n",
      "    self._log_device_info()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1740, in _log_device_info\n",
      "    if CUDAAccelerator.is_available():\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 91, in is_available\n",
      "    return device_parser.num_cuda_devices() > 0\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\", line 347, in num_cuda_devices\n",
      "    with multiprocessing.get_context(\"fork\").Pool(1) as pool:\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/vagrant/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 118, in start\n",
      "    assert not _current_process._config.get('daemon'), \\\n",
      "AssertionError: daemonic processes are not allowed to have children\n",
      "2022-09-18 16:40:32,325 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       batch_of__optimize_sequential_1_calls-a7a8bf04e1764c8886a14b3d3950fb5d\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7f0858323b80>, batch_of__optimize_sequential_1_calls, [], {'tasks': [(<function _optimize_sequential at 0x7f0837c0d670>, [<optuna.study.Study object at 0x7f07aa3c7100>, <function objective at 0x7f07a9068e50>, 1, None, (), None, False], {'reseed_sampler_rng': True, 'time_start': datetime.datetime(2022, 9, 18, 16, 40, 31, 971835), 'progress_bar': None})]}))\n",
      "kwargs:    {}\n",
      "Exception: \"AssertionError('daemonic processes are not allowed to have children')\"\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "daemonic processes are not allowed to have children",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(storage\u001b[39m=\u001b[39mstorage, direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m joblib\u001b[39m.\u001b[39mparallel_backend(\u001b[39m\"\u001b[39m\u001b[39mdask\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# study = optuna.create_study(direction=\"maximize\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# study.optimize(objective, n_trials=10, timeout=600)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials)))\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/optuna/study.py:306\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    230\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     _optimize(\n\u001b[1;32m    307\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    308\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    309\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    310\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    311\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    312\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    313\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    314\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    315\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    316\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py:101\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m     91\u001b[0m                 parallel\u001b[39m.\u001b[39m_backend, joblib\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39mThreadingBackend\n\u001b[1;32m     92\u001b[0m             ) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(study\u001b[39m.\u001b[39m_storage, storages\u001b[39m.\u001b[39mInMemoryStorage):\n\u001b[1;32m     93\u001b[0m                 warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     94\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mThe default storage cannot be shared by multiple processes. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mPlease use an RDB (RDBStorage) when you use joblib for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m     99\u001b[0m                 )\n\u001b[0;32m--> 101\u001b[0m             parallel(\n\u001b[1;32m    102\u001b[0m                 delayed(_optimize_sequential)(\n\u001b[1;32m    103\u001b[0m                     study,\n\u001b[1;32m    104\u001b[0m                     func,\n\u001b[1;32m    105\u001b[0m                     \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    106\u001b[0m                     timeout,\n\u001b[1;32m    107\u001b[0m                     catch,\n\u001b[1;32m    108\u001b[0m                     callbacks,\n\u001b[1;32m    109\u001b[0m                     gc_after_trial,\n\u001b[1;32m    110\u001b[0m                     reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    111\u001b[0m                     time_start\u001b[39m=\u001b[39;49mtime_start,\n\u001b[1;32m    112\u001b[0m                     progress_bar\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    113\u001b[0m                 )\n\u001b[1;32m    114\u001b[0m                 \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m _iter\n\u001b[1;32m    115\u001b[0m             )\n\u001b[1;32m    116\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     study\u001b[39m.\u001b[39m_optimize_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/distributed/worker.py:2908\u001b[0m, in \u001b[0;36mapply_function_simple\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2906\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m   2907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2908\u001b[0m     result \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2909\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   2910\u001b[0m     msg \u001b[39m=\u001b[39m error_message(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/distributed/worker.py:2780\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2778\u001b[0m \u001b[39mif\u001b[39;00m istask(task):\n\u001b[1;32m   2779\u001b[0m     func, args \u001b[39m=\u001b[39m task[\u001b[39m0\u001b[39m], task[\u001b[39m1\u001b[39m:]\n\u001b[0;32m-> 2780\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(execute_task, args))\n\u001b[1;32m   2781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(task, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   2782\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(execute_task, task))\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/dask/utils.py:71\u001b[0m, in \u001b[0;36mapply\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"Apply a function given its positional and keyword arguments.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39mEquivalent to ``func(*args, **kwargs)``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m>>> dsk = {'task-name': task}  # adds the task to a low level Dask task graph\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/joblib/_dask.py:124\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39m'\u001b[39m\u001b[39mdask\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    123\u001b[0m     \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m tasks:\n\u001b[0;32m--> 124\u001b[0m         results\u001b[39m.\u001b[39mappend(func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py:156\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    157\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/optuna/_optimize.py:189\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m trial_number \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mnumber\n\u001b[1;32m    188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     value \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     \u001b[39m# Register the last intermediate value if present as the value of the trial.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[39m# TODO(hvy): Whether a pruned trials should have an actual value can be discussed.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     frozen_trial \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39m_storage\u001b[39m.\u001b[39mget_trial(trial_id)\n",
      "\u001b[1;32m/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb Cell 8\u001b[0m in \u001b[0;36mobjective\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m LightningNet(dropout, output_dims)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m datamodule \u001b[39m=\u001b[39m FashionMNISTDataModule(data_dir\u001b[39m=\u001b[39mDIR, batch_size\u001b[39m=\u001b[39mBATCHSIZE)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     logger\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     limit_val_batches\u001b[39m=\u001b[39mPERCENT_VALID_EXAMPLES,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     enable_checkpointing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39mEPOCHS,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     callbacks\u001b[39m=\u001b[39m[PyTorchLightningPruningCallback(trial, monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m\"\u001b[39m)],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m hyperparameters \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(n_layers\u001b[39m=\u001b[39mn_layers, dropout\u001b[39m=\u001b[39mdropout, output_dims\u001b[39m=\u001b[39moutput_dims)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/rwmas/GitHub/xai/xai_api/app/notebooks/test_optuna_pytorch_lighning.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m trainer\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog_hyperparams(hyperparameters)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py:345\u001b[0m, in \u001b[0;36minsert_env_defaults\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    344\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:534\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_grad_norm: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(track_grad_norm)\n\u001b[1;32m    533\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m detect_anomaly\n\u001b[0;32m--> 534\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_on_init()\n\u001b[1;32m    536\u001b[0m \u001b[39m# configure tuner\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtuner\u001b[39m.\u001b[39mon_trainer_init(auto_lr_find, auto_scale_batch_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:619\u001b[0m, in \u001b[0;36m_setup_on_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_on_init\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_device_info()\n\u001b[1;32m    621\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshould_stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m TrainerState()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1740\u001b[0m, in \u001b[0;36m_log_device_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_device_info\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[39mif\u001b[39;00m CUDAAccelerator\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m   1741\u001b[0m         gpu_available \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m         gpu_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m (cuda)\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py:91\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_available\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m device_parser\u001b[39m.\u001b[39mnum_cuda_devices() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py:347\u001b[0m, in \u001b[0;36mnum_cuda_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfork\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m torch\u001b[39m.\u001b[39mmultiprocessing\u001b[39m.\u001b[39mget_all_start_methods() \u001b[39mor\u001b[39;00m _is_forking_disabled():\n\u001b[1;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m--> 347\u001b[0m \u001b[39mwith\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mget_context(\u001b[39m\"\u001b[39m\u001b[39mfork\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mPool(\u001b[39m1\u001b[39m) \u001b[39mas\u001b[39;00m pool:\n\u001b[1;32m    348\u001b[0m     \u001b[39mreturn\u001b[39;00m pool\u001b[39m.\u001b[39mapply(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/context.py:119\u001b[0m, in \u001b[0;36mPool\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m'''Returns a process pool object'''\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpool\u001b[39;00m \u001b[39mimport\u001b[39;00m Pool\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[1;32m    120\u001b[0m             context\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_context())\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py:212\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_processes \u001b[39m=\u001b[39m processes\n\u001b[1;32m    211\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_repopulate_pool()\n\u001b[1;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py:303\u001b[0m, in \u001b[0;36m_repopulate_pool\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repopulate_pool\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_repopulate_pool_static(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ctx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mProcess,\n\u001b[1;32m    304\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_processes,\n\u001b[1;32m    305\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inqueue,\n\u001b[1;32m    306\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outqueue, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initializer,\n\u001b[1;32m    307\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initargs,\n\u001b[1;32m    308\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maxtasksperchild,\n\u001b[1;32m    309\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_exception)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py:326\u001b[0m, in \u001b[0;36m_repopulate_pool_static\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m w\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mProcess\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPoolWorker\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    325\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    327\u001b[0m pool\u001b[39m.\u001b[39mappend(w)\n\u001b[1;32m    328\u001b[0m util\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39madded worker\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/process.py:118\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcannot start a process twice\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \\\n\u001b[1;32m    117\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mcan only start a process object created by current process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[1;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: daemonic processes are not allowed to have children"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "import joblib\n",
    "import optuna\n",
    "import dask_optuna\n",
    "\n",
    "\n",
    "\n",
    "# with Client() as client:\n",
    "client = dasker.get_dask_client()\n",
    "print(f\"Dask dashboard is available at {client.dashboard_link}\")\n",
    "\n",
    "storage = dask_optuna.DaskStorage()\n",
    "study = optuna.create_study(storage=storage, direction=\"minimize\")\n",
    "\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=10, timeout=600)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6ff7914d2bc405bfa61a835d0564ba294eb5f3f9b4c24865f45d9397593b123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
