{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '../..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "from utils import helper, config, rayer\n",
    "from ml.models.ensemble_v2 import Ensemble\n",
    "from ml.xai.model.explainable import Explainable\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "from ml.models import common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2022-11-23 06:52:49.788828 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Healthy:\n",
      " 1 head-group\n",
      " 2 small-group\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Usage:\n",
      " 0.0/5.0 CPU\n",
      " 0.00/16.764 GiB memory\n",
      " 0.00/4.909 GiB object_store_memory\n",
      "\n",
      "Demands:\n",
      " {'CPU': 1}: 5+ from request_resources()\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "rayer.get_global_cluster(num_cpus=5)\n",
    "!ray status --address='raycluster-autoscaler-head-svc.dev.svc.cluster.local:6379'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2022-11-17 08:37:13.186794 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Healthy:\n",
      " 1 head-group\n",
      " 3 small-group\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Usage:\n",
      " 2.0/7.0 CPU\n",
      " 0.00/24.214 GiB memory\n",
      " 0.00/7.114 GiB object_store_memory\n",
      "\n",
      "Demands:\n",
      " {'CPU': 1}: 5+ from request_resources()\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray status --address='raycluster-autoscaler-head-svc.dev.svc.cluster.local:6379'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.autoscaler.sdk.request_resources(num_cpus=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X, df_y = helper.get_covid_dataset()\n",
    "df_X = df_X.drop(['location'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=config.rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train_scalar = pd.DataFrame(ss.fit_transform(X_train.copy()), columns=X_train.columns)\n",
    "X_test_scalar = pd.DataFrame(ss.fit_transform(X_test.copy()), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_base_models = ['BriskXGBoost', 'SlugXGBoost', 'SlugANN', 'SlugRF', 'SlugKNN', 'BriskBagging']\n",
    "\n",
    "ensemble_set = Ensemble(\n",
    "                        list_base_models = list_base_models,\n",
    "                        n_trials=10, ### for all models\n",
    "                        boosted_round=50, ### for tree models only\n",
    "                        epochs=15, ### for DNN models\n",
    "\n",
    "                        ensemble_boosted_round=10, ### for ensemble model which is also a free model\n",
    "                        ensemble_n_trials=3,\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23T06:52:56CST : INFO : ensemble_v2 : fetch_models : 108 : Message : Ensemble: starting discovery process for models [<ml.models.base.v2.brisk_xgboost.BriskXGBoost object at 0x7f7d580b5940>, <ml.models.base.v2.slug_xgboost.SlugXGBoost object at 0x7f7d580b4730>, <ml.models.base.v2.slug_ann.SlugANN object at 0x7f7d580b4910>, <ml.models.base.v2.slug_rf.SlugRF object at 0x7f7d580b4880>, <ml.models.base.v2.slug_knn.SlugKNN object at 0x7f7d580b4520>, <ml.models.base.v2.brisk_bagging.BriskBagging object at 0x7f7d580b4670>]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2022-11-23 04:53:00,387 E 74 74] (raylet) worker_pool.cc:1108: Failed to send exit request: GrpcUnavailable: RPC Error message: Connection reset by peer; RPC Error details: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:00PST : INFO : brisk_xgboost : __discover_model__ : 109 : Message : brisk_xgb: Starting training for trials:10, boosted rounds: 50, max depth: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 121 : Message : brisk_xgb: Number of trials: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 123 : Message : Best trial:8\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 125 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     booster gbtree\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     lambda 0.2964777747149863\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     alpha 0.11099502821642898\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     max_depth 1\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     eta 0.0013582596027432489\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     gamma 0.37012516326133776\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 127 : Message :     grow_policy depthwise\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 144 : Message :   test r2 score: -0.8618234540916516\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : __discover_model__ : 152 : Message : brisk_xgb: Model saved at /tmp/covid_autolearn/brisk_xgb/saved/brisk_xgb_8.pickle\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:01PST : INFO : brisk_xgboost : load_score : 200 : Message : brisk_xgb: scores loaded: [-0.780242599582226, -0.8618234540916516]\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:05PST : INFO : slug_ann : __discover_model__ : 216 : Message : slug_ann: Starting train for trials:10 with epochs: 15\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:06PST : INFO : slug_rf : __discover_model__ : 96 : Message : slug_rf: Starting training for trials:10, max depth: 30, max estimators 1500\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 90 : Message : slug_knn: Starting training for trials:10, neighbors  50\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 108 : Message : slug_knn: Number of trials: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 110 : Message : Best trial:3\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 112 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 114 : Message :     n_neighbors 5\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 114 : Message :     weights uniform\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 114 : Message :     algorithm ball_tree\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 129 : Message :   test r2 score: 0.5401046443169623\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_knn : __discover_model__ : 134 : Message : slug_knn: Model saved at /tmp/covid_autolearn/slug_knn/saved/slug_knn_3.pickle\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 106 : Message : slug_xgb: Starting training for trials:10, boosted rounds: 50, max depth: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 120 : Message : slug_xgb: Number of trials: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 122 : Message : Best trial:2\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 124 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     lambda 0.014510120792821603\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     alpha 0.7008020438305472\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     eta 0.17862897933519536\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     gamma 0.01454053313818586\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     grow_policy depthwise\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     max_depth 3\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     colsample_bytree 0.0033225247167443708\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     colsample_bylevel 0.5767781122715965\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     colsample_bynode 0.006791319285598064\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 126 : Message :     max_bin 128\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 146 : Message :   test r2 score: -0.6666532672303094\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : __discover_model__ : 151 : Message : slug_xgb: Model saved at /tmp/covid_autolearn/slug_xgb/saved/slug_xgb_2.pickle\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:07PST : INFO : slug_xgboost : load_score : 202 : Message : slug_xgb: scores loaded: [-0.36896820977009215, -0.6666532672303094]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2022-11-23 04:53:08,779 E 74 74] (raylet) worker_pool.cc:1108: Failed to send exit request: GrpcUnavailable: RPC Error message: Connection reset by peer; RPC Error details: \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2022-11-23 04:53:09,480 E 74 74] (raylet) worker_pool.cc:1108: Failed to send exit request: GrpcUnavailable: RPC Error message: Connection reset by peer; RPC Error details: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:09PST : INFO : brisk_bagging : __discover_model__ : 94 : Message : brisk_bagging: Starting training for trials:10, n_estimators  50\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:10PST : INFO : slug_ann : __discover_model__ : 229 : Message : slug_ann: Number of trials: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:10PST : INFO : slug_ann : __discover_model__ : 231 : Message : Best trial: 0\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:10PST : INFO : slug_ann : __discover_model__ : 238 : Message : Sequential(\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (0): Linear(in_features=40, out_features=152, bias=True)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (1): ReLU()\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (2): Dropout(p=0.4263207577559208, inplace=False)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (3): Linear(in_features=152, out_features=10, bias=True)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (4): ReLU()\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (5): Dropout(p=0.4263207577559208, inplace=False)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (6): Linear(in_features=10, out_features=19, bias=True)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (7): ReLU()\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (8): Dropout(p=0.4263207577559208, inplace=False)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (9): Linear(in_features=19, out_features=73, bias=True)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (10): ReLU()\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (11): Dropout(p=0.4263207577559208, inplace=False)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (12): Linear(in_features=73, out_features=1, bias=True)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   (13): ReLU()\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m )\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m /tmp/ray/session_2022-11-23_00-55-48_777969_8/runtime_resources/working_dir_files/_ray_pkg_da0458f1947282cd/utils/helper.py:35: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m   return torch.from_numpy(df.values).float()\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:10PST : INFO : slug_ann : __discover_model__ : 245 : Message :   test r2 score: 0.16147673240819727\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:10PST : INFO : slug_ann : __discover_model__ : 248 : Message : slug_ann: Model saved at /tmp/covid_autolearn/slug_ann/saved/tmp/covid_autolearn/slug_ann/tmp/slug_ann_0.pickle\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:53:10PST : INFO : slug_ann : load_score : 298 : Message : slug_ann: scores loaded: [0.5712783142765323, 0.16147673240819727]\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:10PST : INFO : brisk_bagging : __discover_model__ : 112 : Message : brisk_bagging: Number of trials: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:10PST : INFO : brisk_bagging : __discover_model__ : 114 : Message : Best trial:1\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:10PST : INFO : brisk_bagging : __discover_model__ : 116 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:10PST : INFO : brisk_bagging : __discover_model__ : 118 : Message :     n_estimators 41\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:10PST : INFO : brisk_bagging : __discover_model__ : 132 : Message :   test r2 score: 0.5390826970012106\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:10PST : INFO : brisk_bagging : __discover_model__ : 137 : Message : brisk_bagging: Model saved at /tmp/covid_autolearn/brisk_bagging/saved/brisk_bagging_1.pickle\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 114 : Message : slug_rf: Number of trials: 10\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 116 : Message : Best trial:3\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 118 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 120 : Message :     n_estimators 1059\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 120 : Message :     max_depth 23\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 120 : Message :     min_samples_split 28\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 120 : Message :     min_samples_leaf 15\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 134 : Message :   test r2 score: 0.4251536230476787\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:53:12PST : INFO : slug_rf : __discover_model__ : 139 : Message : slug_rf: Model saved at /tmp/covid_autolearn/slug_rf/saved/slug_rf_3.pickle\n",
      "2022-11-23T06:53:13CST : INFO : ensemble_v2 : fetch_models : 122 : Message : base model training completed\n",
      "2022-11-23T06:53:13CST : INFO : ensemble_v2 : fetch_models : 131 : Message : Ensemble: base model scores loaded, access via 'base_model_scores'\n",
      "2022-11-23T06:53:13CST : INFO : ensemble_v2 : fit : 172 : Message : Ensemble: fiting ensemble on 6 models\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m 2022-11-23T04:53:16PST : INFO : brisk_bagging : __discover_model__ : 94 : Message : ensemble_brisk_bagging: Starting training for trials:3, n_estimators  50\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m /tmp/ray/session_2022-11-23_00-55-48_777969_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/optuna/_optimize.py:93: UserWarning: The default storage cannot be shared by multiple processes. Please use an RDB (RDBStorage) when you use joblib for multi-processing. The usage of RDBStorage can be found in https://optuna.readthedocs.io/en/stable/tutorial/rdb.html.\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m 2022-11-23T04:53:16PST : INFO : brisk_bagging : __discover_model__ : 112 : Message : ensemble_brisk_bagging: Number of trials: 3\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m 2022-11-23T04:53:16PST : INFO : brisk_bagging : __discover_model__ : 114 : Message : Best trial:1\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m 2022-11-23T04:53:16PST : INFO : brisk_bagging : __discover_model__ : 116 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=7113)\u001b[0m 2022-11-23T04:53:16PST : INFO : brisk_bagging : __discover_model__ : 118 : Message :     n_estimators 25\n",
      "2022-11-23T06:53:16CST : INFO : ensemble_v2 : fetch_models : 136 : Message : Ensemble: Cleanning storage\n"
     ]
    }
   ],
   "source": [
    "ensemble_set.fetch_models(X_train_scalar, X_test_scalar, y_train, y_test, threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.780242599582226,\n",
       "  -0.8618234540916516,\n",
       "  <ml.models.base.v2.brisk_xgboost.BriskXGBoost at 0x7f7d580b4340>],\n",
       " [-0.36896820977009215,\n",
       "  -0.6666532672303094,\n",
       "  <ml.models.base.v2.slug_xgboost.SlugXGBoost at 0x7f7d3ebb5460>],\n",
       " [0.5712783142765323,\n",
       "  0.16147673240819727,\n",
       "  <ml.models.base.v2.slug_ann.SlugANN at 0x7f7d3ebb5730>],\n",
       " [0.6471896784078507,\n",
       "  0.4251536230476787,\n",
       "  <ml.models.base.v2.slug_rf.SlugRF at 0x7f7d580b4f40>],\n",
       " [0.6695206594539054,\n",
       "  0.5401046443169623,\n",
       "  <ml.models.base.v2.slug_knn.SlugKNN at 0x7f7d3e83ad90>],\n",
       " [0.9506921261413173,\n",
       "  0.5390826970012106,\n",
       "  <ml.models.base.v2.brisk_bagging.BriskBagging at 0x7f7d3e7d0070>]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_set.base_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_algos = ['IG', 'SHAP', 'GradientSHAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23T06:55:12CST : INFO : explainable : get_attr : 148 : Message : attribution methods  ['ig', 'shap', 'gradientshap']\n",
      "2022-11-23T06:55:12CST : INFO : explainable : get_attr : 151 : Message : calculating variable importance on  brisk_xgb\n",
      "2022-11-23T06:55:13CST : INFO : explainable : get_attr : 151 : Message : calculating variable importance on  slug_xgb\n",
      "2022-11-23T06:55:13CST : INFO : explainable : get_attr : 151 : Message : calculating variable importance on  slug_ann\n",
      "2022-11-23T06:55:13CST : INFO : explainable : get_attr : 151 : Message : calculating variable importance on  slug_rf\n",
      "2022-11-23T06:55:13CST : INFO : explainable : get_attr : 151 : Message : calculating variable importance on  slug_knn\n",
      "2022-11-23T06:55:13CST : INFO : explainable : get_attr : 151 : Message : calculating variable importance on  brisk_bagging\n",
      "\u001b[2m\u001b[36m(__get_ig_attr__ pid=581, ip=10.10.48.229)\u001b[0m IPython could not be loaded!\n",
      "\u001b[2m\u001b[36m(__get_gs_attr__ pid=526, ip=10.10.105.191)\u001b[0m /tmp/ray/session_2022-11-23_00-55-48_777969_8/runtime_resources/working_dir_files/_ray_pkg_da0458f1947282cd/utils/helper.py:35: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "\u001b[2m\u001b[36m(__get_gs_attr__ pid=526, ip=10.10.105.191)\u001b[0m   return torch.from_numpy(df.values).float()\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=614, ip=10.10.48.229)\u001b[0m IPython could not be loaded!\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "  1%|          | 1/191 [00:00<00:19,  9.92it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -63.45799337   0.         -66.02647578 131.85735388\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           6.70792483   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -4.24733795  -4.31771736   0.           8.83120527\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -9.34695951   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.        ]\n",
      "  2%|▏         | 3/191 [00:00<00:13, 13.78it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 605 : Message : phi = [150.13475357 353.98716015   5.14262936 348.59238198 -23.20506468\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.          10.4714355    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           5.59970412   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "  3%|▎         | 5/191 [00:00<00:12, 15.04it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         187.72353768   0.         190.58988464 -24.45162232\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 605 : Message : phi = [ -4.4548001  -71.53464906  -3.31985948 -74.84732491 141.28470938\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    5.73277211   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           5.21488235   0.          10.76682422  -2.21989946\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.          -4.9678103   -4.30761857   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    6.97527487   0.           0.          -7.20852362   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.          -3.61727902   6.5033016    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "  4%|▎         | 7/191 [00:00<00:12, 14.69it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:14PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [  0.       0.       0.       0.     424.2802   0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.    ]\n",
      "  5%|▍         | 9/191 [00:00<00:12, 14.63it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_gs_attr__ pid=526, ip=10.10.105.191)\u001b[0m IPython could not be loaded!\n",
      "\u001b[2m\u001b[36m(__run_discoveries__ pid=530, ip=10.10.105.191)\u001b[0m IPython could not be loaded!\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "  6%|▌         | 11/191 [00:00<00:12, 14.99it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_torch_attr__ pid=530, ip=10.10.105.191)\u001b[0m The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "\u001b[2m\u001b[36m(__get_shapley_torch_attr__ pid=530, ip=10.10.105.191)\u001b[0m Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [   6.15764892   68.65708756    0.           65.63253647 -148.34006878\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     5.24321482   -4.01522095    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -8.33886906    0.            2.12483994    0.            5.59409642\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     6.27819356    3.63149408    0.           -7.5249866     0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            5.41198737    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     3.24602401    7.12907433    3.7877097     3.88678297    3.43511288\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -7.64257269    2.13978896    0.          -10.32019117\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -6.17368273]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "  1%|          | 2/191 [00:00<00:12, 15.17it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "  7%|▋         | 13/191 [00:00<00:11, 15.01it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "  2%|▏         | 4/191 [00:00<00:13, 14.27it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [ 92.00951448 159.67180674   0.         158.97714604 -49.91026954\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           6.79305565   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    3.04374502   0.          -4.38727026   4.38722406   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -6.03902664   0.           0.          -6.33337356   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           5.99295234  -3.75226057\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -6.83676802   0.          13.4832545   -7.13187548  -6.10605474\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "  8%|▊         | 15/191 [00:01<00:12, 14.10it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.04353659\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "  9%|▉         | 17/191 [00:01<00:12, 14.34it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "  3%|▎         | 6/191 [00:00<00:13, 13.87it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [   0.           73.13361155   -2.85765659   66.50506274 -138.95361039\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            4.13247913    0.            4.65478248\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     4.18073746   -4.93794095    3.67291656   -7.20709919    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -5.67739869    6.05553778    5.04467936    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            8.13552545   -8.58879594    4.03341314\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -3.07104556    0.           -4.44377886    8.24441746    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -5.50458176   -3.38775105    0.           -5.9582872     2.79478304\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "  4%|▍         | 8/191 [00:00<00:13, 13.72it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 10%|▉         | 19/191 [00:01<00:11, 14.53it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [-40.22977495 339.5023625    0.         340.53245975 -54.36187561\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           7.85002831   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "  5%|▌         | 10/191 [00:00<00:12, 14.83it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 11%|█         | 21/191 [00:01<00:11, 15.18it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "  6%|▋         | 12/191 [00:00<00:11, 15.55it/s]p=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 12%|█▏        | 23/191 [00:01<00:10, 15.58it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:15PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.14607317  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -66.92671125  -3.14313105 -67.79132495 142.49163539\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -4.02991183   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -4.23746578   0.           0.           0.          -4.04247697\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          10.78210623   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -3.10271978   0.        ]\n",
      " 13%|█▎        | 25/191 [00:01<00:10, 15.57it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "  7%|▋         | 14/191 [00:00<00:11, 15.97it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [   0.           71.16564937    7.27018607   75.15181706 -154.42712388\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.           -8.66292501    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            8.49452983    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     3.52222746    0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            4.64115979    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            3.66281418   -7.37288802    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            4.82388716    0.            0.           -8.269334\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 14%|█▍        | 27/191 [00:01<00:10, 15.92it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -91.95985366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      "  8%|▊         | 16/191 [00:01<00:10, 16.27it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "  9%|▉         | 18/191 [00:01<00:10, 16.58it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 15%|█▌        | 29/191 [00:01<00:10, 15.91it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 10%|█         | 20/191 [00:01<00:10, 16.51it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 16%|█▌        | 31/191 [00:02<00:09, 16.40it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [   0.         -147.87407163    0.         -144.85096559  286.81154062\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     8.5981462     0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            8.67542136\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     6.25797028    0.            0.            0.           -6.71680326\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     5.94733795    0.           -8.50259623    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -8.3459797     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 12%|█▏        | 22/191 [00:01<00:10, 16.51it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 17%|█▋        | 33/191 [00:02<00:10, 15.50it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 13%|█▎        | 24/191 [00:01<00:10, 16.59it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 18%|█▊        | 35/191 [00:02<00:09, 15.78it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      " 14%|█▎        | 26/191 [00:01<00:09, 16.80it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -10.16936585   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.49295122\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -67.02021515   0.         -71.61131824 141.58517363\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -5.81500992   0.           0.          -2.836181    -2.71533674\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -4.47901264   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -4.43852611   6.39542578   3.10023072  -6.77659079\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    7.99222621   0.           4.5171046    3.5893206   -3.63141316\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.          -2.9454257\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           5.08954792   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.        ]\n",
      " 19%|█▉        | 37/191 [00:02<00:09, 15.47it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 15%|█▍        | 28/191 [00:01<00:09, 16.97it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.04353659\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 20%|██        | 39/191 [00:02<00:09, 15.24it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:16PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 16%|█▌        | 30/191 [00:01<00:09, 16.94it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.04353659\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [-165.73714642  146.88958325  -10.47289868  145.53156083 -131.97471033\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            5.75493916    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -6.6955099     0.            0.            3.62184394\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            8.7925855    -6.88140446\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            8.73744185    5.52478566    0.            7.62640865\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    11.92731265    3.84760935    7.01863785    4.48403036    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     8.57940986  -15.96677466    0.          -14.99366343    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -15.61404105]\n",
      " 21%|██▏       | 41/191 [00:02<00:09, 15.35it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 17%|█▋        | 32/191 [00:01<00:09, 16.87it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 23%|██▎       | 43/191 [00:02<00:09, 15.87it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 18%|█▊        | 34/191 [00:02<00:09, 16.78it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 19%|█▉        | 36/191 [00:02<00:09, 16.89it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 24%|██▎       | 45/191 [00:02<00:09, 15.98it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 20%|█▉        | 38/191 [00:02<00:09, 16.78it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 25%|██▍       | 47/191 [00:03<00:08, 16.01it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 26%|██▌       | 49/191 [00:03<00:08, 16.10it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 21%|██        | 40/191 [00:02<00:08, 17.00it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         389.84643413   0.         388.63981763  40.59688529\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    5.07246295   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 27%|██▋       | 51/191 [00:03<00:09, 15.53it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 22%|██▏       | 42/191 [00:02<00:08, 16.96it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 23%|██▎       | 44/191 [00:02<00:08, 16.87it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 28%|██▊       | 53/191 [00:03<00:08, 15.91it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 24%|██▍       | 46/191 [00:02<00:08, 16.96it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 29%|██▉       | 55/191 [00:03<00:08, 15.86it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:17PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 25%|██▌       | 48/191 [00:02<00:08, 17.09it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 30%|██▉       | 57/191 [00:03<00:08, 16.07it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.          -4.82290244 108.10270732   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 26%|██▌       | 50/191 [00:03<00:08, 17.01it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 31%|███       | 59/191 [00:03<00:08, 16.21it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 27%|██▋       | 52/191 [00:03<00:08, 16.98it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 32%|███▏      | 61/191 [00:03<00:07, 16.48it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.         108.10270732   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 28%|██▊       | 54/191 [00:03<00:08, 16.93it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 33%|███▎      | 63/191 [00:04<00:08, 15.76it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 29%|██▉       | 56/191 [00:03<00:07, 16.90it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 34%|███▍      | 65/191 [00:04<00:08, 14.85it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(pid=7167)\u001b[0m IPython could not be loaded!\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 30%|███       | 58/191 [00:03<00:07, 16.95it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 35%|███▌      | 67/191 [00:04<00:08, 15.48it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 31%|███▏      | 60/191 [00:03<00:07, 17.07it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 17.10065441 223.78963827   0.         214.9337083   51.12247427\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -5.76839956   6.2216685    0.          -4.40967459\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.         -20.66622498 -15.05351156   4.65406237   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    5.55099844   0.           0.          36.73677927   9.63164288\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.          -8.72009785\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -4.17797667   6.81412395   0.         -12.33787684   6.88100643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  -10.12444437   0.          -4.40306958   9.76296095   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -5.42284205]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 32%|███▏      | 62/191 [00:03<00:07, 17.22it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [134.86966943 325.87457661   2.79560024 321.2326888   21.5212971\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           3.73122561   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    3.81308967   6.59059008   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    2.68396907   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           1.0428934 ]\n",
      " 36%|███▌      | 69/191 [00:04<00:08, 15.07it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:18PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -91.95985366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 34%|███▎      | 64/191 [00:03<00:07, 16.48it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 37%|███▋      | 71/191 [00:04<00:07, 15.47it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         138.32684173   0.         139.85641779 140.67570489\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           1.45808349\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           3.96315211   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.        ]\n",
      " 38%|███▊      | 73/191 [00:04<00:07, 15.69it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 35%|███▍      | 66/191 [00:04<00:07, 16.57it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 39%|███▉      | 75/191 [00:04<00:07, 15.94it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.         41.62182927\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 36%|███▌      | 68/191 [00:04<00:07, 16.83it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         211.55910413   0.         212.72109587   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      " 40%|████      | 77/191 [00:04<00:07, 15.53it/s]p=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.         -0.04353659  0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.        ]\n",
      " 37%|███▋      | 70/191 [00:04<00:07, 17.05it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -66.05674291   0.         -63.60376504 139.38888329\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -2.69544749   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.          -3.63639645\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    6.47974238   0.           0.          -4.52787674  -2.60861484\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.          -5.40897276\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -2.67211908  -4.76689411  10.10820376   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      " 38%|███▊      | 72/191 [00:04<00:06, 17.04it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.000000000000014\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 41%|████▏     | 79/191 [00:05<00:07, 15.79it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 39%|███▊      | 74/191 [00:04<00:06, 16.89it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 42%|████▏     | 81/191 [00:05<00:06, 16.34it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 40%|███▉      | 76/191 [00:04<00:06, 16.75it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 43%|████▎     | 83/191 [00:05<00:06, 16.74it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 41%|████      | 78/191 [00:04<00:06, 16.94it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 45%|████▍     | 85/191 [00:05<00:06, 17.12it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.000000000000014\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 46%|████▌     | 87/191 [00:05<00:06, 16.98it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 42%|████▏     | 80/191 [00:04<00:06, 17.06it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:19PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.14607317  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -71.2497272    0.         -68.85837782 140.81937983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.          -4.47494986   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -4.39802539  -5.65700031   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -7.01255769   7.22611506   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           8.27357226   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.         -11.31427436   0.           0.           7.04114612\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           9.60469936\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 47%|████▋     | 89/191 [00:05<00:05, 17.01it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 43%|████▎     | 82/191 [00:04<00:06, 17.22it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ -85.06675099   96.29516772    0.          105.04733175 -117.88502379\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            7.47373761\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.           -5.6791042     0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -9.42246773   -7.12288867    5.06826623    4.28185635\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -2.89536057    0.            0.            4.40056995\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     8.24730988    0.            5.51388116  -12.82917447    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            4.57264977\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 48%|████▊     | 91/191 [00:05<00:05, 17.07it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 44%|████▍     | 84/191 [00:05<00:06, 17.03it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 49%|████▊     | 93/191 [00:05<00:05, 17.28it/s]p=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 45%|████▌     | 86/191 [00:05<00:06, 16.96it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 46%|████▌     | 88/191 [00:05<00:06, 17.01it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 50%|████▉     | 95/191 [00:06<00:05, 17.40it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 47%|████▋     | 90/191 [00:05<00:05, 17.13it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 51%|█████     | 97/191 [00:06<00:05, 17.23it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 48%|████▊     | 92/191 [00:05<00:05, 17.25it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 52%|█████▏    | 99/191 [00:06<00:05, 17.47it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [  27.03489953   32.024706      0.           31.29380245 -101.99699587\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     2.04418251    0.            0.            0.            3.26774945\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            4.01296529    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            4.36148569    0.           10.34519878\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.           -6.05476691    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.           -6.3332269     0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -91.95985366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 49%|████▉     | 94/191 [00:05<00:05, 17.26it/s]p=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 53%|█████▎    | 101/191 [00:06<00:05, 17.28it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 54%|█████▍    | 103/191 [00:06<00:05, 17.48it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 50%|█████     | 96/191 [00:05<00:05, 17.30it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 605 : Message : phi = [  38.14055744   28.25337174    0.           30.41129066 -119.16815207\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     6.88161062    8.25724796    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     7.34473225    0.            2.89902079    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -4.99578158    0.            0.           -9.65472593\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            1.83819826    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    12.20053239    0.            0.            6.17315934    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -4.29416549    0.            4.7199705     0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -9.00686687]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 55%|█████▍    | 105/191 [00:06<00:05, 17.16it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:20PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 51%|█████▏    | 98/191 [00:05<00:05, 17.26it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -91.95985366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [   0.           67.23151592    5.01551193   75.09162077 -142.63647934\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.          -11.15360009    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            3.22628986    3.03978647    0.           -9.98838642\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     3.55113708    0.            0.            3.25168579    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     3.37091801]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [-225.29889567  169.00269408    0.          156.38911531 -117.38741569\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -9.72715157    0.           10.02103552   11.01202001   -8.65780591\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -7.15176775  -12.82434859    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.           10.17641211    0.          -11.30095016\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           13.48294008    0.            7.64643121    6.12698054\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    16.71208762   -8.22138113    0.            0.            0.        ]\n",
      " 56%|█████▌    | 107/191 [00:06<00:04, 16.99it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 52%|█████▏    | 100/191 [00:05<00:05, 16.99it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 57%|█████▋    | 109/191 [00:06<00:04, 17.13it/s]=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      " 53%|█████▎    | 102/191 [00:06<00:05, 17.01it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.14607317  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      " 54%|█████▍    | 104/191 [00:06<00:05, 16.98it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 58%|█████▊    | 111/191 [00:06<00:04, 16.89it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [138.06861024 399.35634511   0.         403.76845104 -64.6471338\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  -25.82327258   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 55%|█████▌    | 106/191 [00:06<00:05, 16.95it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [  0.     212.1401   0.       0.     212.1401   0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.       0.       0.       0.       0.    ]\n",
      " 59%|█████▉    | 113/191 [00:07<00:04, 16.55it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [127.98639238 115.27118918   0.         130.77518099 -24.21314973\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.          -8.76365785   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           2.41142645   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    3.0839649    0.           0.           0.          -6.82423106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    1.11878172   0.           0.           0.           4.67113808\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           3.1510635    5.19370144   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      " 57%|█████▋    | 108/191 [00:06<00:04, 17.16it/s]=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 60%|██████    | 115/191 [00:07<00:04, 16.57it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         122.64885366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 61%|██████▏   | 117/191 [00:07<00:04, 16.86it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.         108.10270732   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 58%|█████▊    | 110/191 [00:06<00:04, 16.80it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.         -9.0897561\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         134.06279856   0.         141.78112663 138.61596798\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    2.73870918   0.           0.           0.           0.88219712\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           1.62603764   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.83841278\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           2.51396733\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           1.22098279   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17041889 0.11727752 0.09089008 0.07521937 0.06492148 0.05770798\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05243658 0.04847471 0.04544504 0.04310992 0.04131367 0.03995168\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03895289 0.03826951 0.03787086 0.03773982]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 16\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.748018128207665\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 34.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [-220.75746201  170.04502732   11.49534558  188.58110648 -130.25046738\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -10.17758014    0.            0.           -6.19332507    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.          -19.17099188    0.            0.          -13.44400066\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -7.80811533    0.          -11.75623466   19.54335832    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           15.40059754    0.            0.           17.49575598\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -18.10948635   15.10647226    0.            0.        ]\n",
      " 62%|██████▏   | 119/191 [00:07<00:04, 16.59it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.         -7.93504878  0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 59%|█████▊    | 112/191 [00:06<00:04, 16.70it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 63%|██████▎   | 121/191 [00:07<00:04, 16.68it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 60%|█████▉    | 114/191 [00:06<00:04, 16.86it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:21PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.         -4.82290244  0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.04353659\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.        ]\n",
      " 61%|██████    | 116/191 [00:06<00:04, 17.03it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 64%|██████▍   | 123/191 [00:07<00:04, 16.58it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.000000000000014\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 62%|██████▏   | 118/191 [00:07<00:04, 16.58it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17041889 0.11727752 0.09089008 0.07521937 0.06492148 0.05770798\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05243658 0.04847471 0.04544504 0.04310992 0.04131367 0.03995168\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03895289 0.03826951 0.03787086 0.03773982]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 16\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 65%|██████▌   | 125/191 [00:07<00:03, 16.68it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [-281.1382302   205.71956098   25.59740311  216.20252702 -179.96261503\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.           17.99075214    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    13.88329436    0.            0.           20.0182339     0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            9.17779246  -28.12730489    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.          -31.54672828   12.18531444\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.748018128207665\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 34.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [17.80614634  0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.000000000000014\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 66%|██████▋   | 127/191 [00:07<00:03, 16.83it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 63%|██████▎   | 120/191 [00:07<00:04, 16.66it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 68%|██████▊   | 129/191 [00:08<00:03, 17.17it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 64%|██████▍   | 122/191 [00:07<00:04, 16.78it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.17682927e-02\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   1.08124476e+02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 140.22732523  451.49387992    0.          430.65008102 -183.64263996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.           11.99435379\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      " 69%|██████▊   | 131/191 [00:08<00:03, 17.10it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 65%|██████▍   | 124/191 [00:07<00:03, 16.83it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 70%|██████▉   | 133/191 [00:08<00:03, 17.36it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 21.92048174   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.          -4.84321757 112.17795534   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 66%|██████▌   | 126/191 [00:07<00:03, 16.40it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 71%|███████   | 135/191 [00:08<00:03, 17.40it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.14607317  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.         -4.82290244  0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 67%|██████▋   | 128/191 [00:07<00:03, 16.58it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 72%|███████▏  | 137/191 [00:08<00:03, 17.64it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.14607317  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 68%|██████▊   | 130/191 [00:07<00:03, 16.81it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 73%|███████▎  | 139/191 [00:08<00:02, 17.62it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.          -4.82290244 122.64885366   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:22PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 74%|███████▍  | 141/191 [00:08<00:02, 17.84it/s]=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.09790244\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      " 69%|██████▉   | 132/191 [00:07<00:03, 16.85it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -82.99381716   0.         -81.91401256 174.3376651\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -6.28726174   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.          -3.14257363   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 70%|███████   | 134/191 [00:08<00:03, 16.93it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 75%|███████▍  | 143/191 [00:08<00:02, 17.71it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         392.8624025    0.         385.27275462  34.96191729\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           4.55852954\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           2.83038968   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    3.66960637   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 71%|███████   | 136/191 [00:08<00:03, 16.75it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 93.72073045 152.0805539    0.         154.59128999 -55.25063462\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           2.32735862   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    2.81464579   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           3.57785587]\n",
      " 76%|███████▌  | 145/191 [00:08<00:02, 17.44it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [   0.           73.48632073    0.           71.64091048 -146.05045218\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -6.21528831    2.57370615    2.81101391    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -8.21924877    5.9781417    -4.16017758    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     5.64879653    0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.           -4.35852634   -7.30763656    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     5.81352039    0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     4.77958837    3.57933149    0.            0.            0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 72%|███████▏  | 138/191 [00:08<00:03, 16.77it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 18.97504978 408.97715823   0.         406.56360405  12.70748858\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           3.49969936   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      " 77%|███████▋  | 147/191 [00:09<00:02, 17.27it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.14607317  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      " 73%|███████▎  | 140/191 [00:08<00:03, 16.86it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 78%|███████▊  | 149/191 [00:09<00:02, 17.56it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -91.95985366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 74%|███████▍  | 142/191 [00:08<00:02, 17.14it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 95.23576201 280.85645283   0.         279.87802906 -62.6770439\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.        ]\n",
      " 79%|███████▉  | 151/191 [00:09<00:02, 17.64it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.          -4.82290244 108.10270732   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 75%|███████▌  | 144/191 [00:08<00:02, 17.13it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 80%|████████  | 153/191 [00:09<00:02, 17.88it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 76%|███████▋  | 146/191 [00:08<00:02, 17.37it/s]=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 81%|████████  | 155/191 [00:09<00:01, 18.02it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 82%|████████▏ | 157/191 [00:09<00:01, 17.90it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  -0.09790244  0.        ]\n",
      " 77%|███████▋  | 148/191 [00:08<00:02, 17.39it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:23PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 83%|████████▎ | 159/191 [00:09<00:01, 17.96it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.         -91.95985366   0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.        ]\n",
      " 79%|███████▊  | 150/191 [00:08<00:02, 17.19it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 84%|████████▍ | 161/191 [00:09<00:01, 18.16it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 80%|███████▉  | 152/191 [00:09<00:02, 16.69it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 81%|████████  | 154/191 [00:09<00:02, 16.99it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         129.01544972   7.57403413 147.69095112 134.8846106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    1.57539095   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    1.78589437   0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    1.7538691 ]\n",
      " 85%|████████▌ | 163/191 [00:09<00:01, 17.90it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      " 82%|████████▏ | 156/191 [00:09<00:02, 17.01it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 86%|████████▋ | 165/191 [00:10<00:01, 17.77it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 83%|████████▎ | 158/191 [00:09<00:01, 17.04it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 87%|████████▋ | 167/191 [00:10<00:01, 17.21it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.999999999999986\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 84%|████████▍ | 160/191 [00:09<00:01, 17.16it/s]=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 88%|████████▊ | 169/191 [00:10<00:01, 16.79it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 90%|████████▉ | 171/191 [00:10<00:01, 16.48it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 85%|████████▍ | 162/191 [00:09<00:01, 17.19it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [-308.55403401  226.18791825   26.73354702  224.39896437 -184.23646002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           22.90263162  -10.01499175    7.48391678    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.          -21.77618566    5.48211645    0.            9.97221209\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    18.42842546  -10.80426753   12.56276116    7.01464037    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.          -15.69314202    9.41981883\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    13.61694026  -20.80205974  -28.60677742  -11.66936513   -6.64883862\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           17.63662267    0.            8.05509335    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     8.91051323]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 86%|████████▌ | 164/191 [00:09<00:01, 17.33it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : solve : 605 : Message : phi = [ -86.69909425  100.15848421    0.          104.22481523 -113.46596885\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     5.30444358    0.            0.           12.03343097    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -8.22034793    0.           -6.84158101   -9.70457064\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.           -4.52069357    0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            7.73108226    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      " 91%|█████████ | 173/191 [00:10<00:01, 15.97it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:24PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999997\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 87%|████████▋ | 166/191 [00:09<00:01, 17.42it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 92%|█████████▏| 175/191 [00:10<00:01, 15.94it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      " 88%|████████▊ | 168/191 [00:09<00:01, 17.30it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 93%|█████████▎| 177/191 [00:10<00:00, 16.60it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 89%|████████▉ | 170/191 [00:10<00:01, 17.24it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [-235.53368177  191.88196635    0.          166.16927134 -130.4558609\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           16.83454743    0.            0.          -15.88443076\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           13.64709834    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.           12.75508071  -19.41399074    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 94%|█████████▎| 179/191 [00:10<00:00, 16.79it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -0.04353659  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.000000000000014\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [ 2.19112141e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  -1.14895483e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00 -4.79971163e+00  1.26714628e+02\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00 -5.59422172e-02  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " 90%|█████████ | 172/191 [00:10<00:01, 17.09it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 95%|█████████▍| 181/191 [00:11<00:00, 16.87it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 91%|█████████ | 174/191 [00:10<00:00, 17.07it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [  0.         -68.75181649   0.         -75.7576116  140.55603705\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.          -5.45310151   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m   -7.4571567    0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           7.02123157\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           9.84241768   0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    0.        ]\n",
      " 96%|█████████▌| 183/191 [00:11<00:00, 16.97it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 97%|█████████▋| 185/191 [00:11<00:00, 17.07it/s]=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 92%|█████████▏| 176/191 [00:10<00:00, 17.00it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [17.80614634  0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [   0.           74.2402053    -5.4927287    69.60435745 -137.53527922\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -4.15242606    0.            0.           -9.53459077   -3.67914672\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            5.00429898    0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.            0.            0.            0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m    -3.90114506    8.8731734     3.80773725    7.81903578    3.66623981\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.           -4.15446255    0.          -11.32382628    2.78940066\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     3.44260581    0.           -7.31062865    7.83717958    0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m     0.            0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [21.87021336  0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.8303949   4.11269374  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      " 93%|█████████▎| 178/191 [00:10<00:00, 16.69it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.04353659  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 98%|█████████▊| 187/191 [00:11<00:00, 16.93it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999996\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [  0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.         -10.16936585   0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.           0.           0.           0.           0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m    0.49295122   0.        ]\n",
      " 94%|█████████▍| 180/191 [00:10<00:00, 16.72it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.14607317  0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -0.04353659  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.         -0.09790244  0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 38.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999998\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      " 99%|█████████▉| 189/191 [00:11<00:00, 16.55it/s]X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 95%|█████████▌| 182/191 [00:10<00:00, 16.93it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:25PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=581, ip=10.10.48.229)\u001b[0m invalid value encountered in divide\n",
      "100%|██████████| 191/191 [00:11<00:00, 16.42it/s]=10.10.48.229)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.17168588 0.11803404 0.09138119 0.07554179 0.06512223 0.05781259\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05245957 0.04842422 0.04532507 0.04292147 0.04105532 0.03961982\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03854173 0.03777089 0.03727391 0.03703029]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7500341733194282\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 35.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 96%|█████████▋| 184/191 [00:10<00:00, 16.83it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.         -4.82290244  0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.        ]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16797208 0.11527496 0.0890761  0.07348779 0.0632153  0.05599069\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05068123 0.04665891 0.04354832 0.04111205 0.03919349 0.03768604\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03651567 0.03563044 0.03499418 0.03458249 0.03438025]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7537996877450106\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.         -4.82290244  0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.        ]\n",
      " 97%|█████████▋| 186/191 [00:11<00:00, 16.74it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16680872 0.11457569 0.08861713 0.0731806  0.06301663 0.05587681\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.05063836 0.04667898 0.0436269  0.04124725 0.03938539 0.03793643\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0368279  0.0360095  0.03544685 0.03511763 0.03500924]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 17\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.751959091970831\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 36.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      " 98%|█████████▊| 188/191 [00:11<00:00, 17.01it/s]=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16354093 0.11214235 0.08658049 0.07136331 0.06132785 0.05426243\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.04906228 0.04511474 0.04205338 0.03964629 0.03774021 0.03623061\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03504448 0.03413028 0.03345155 0.03298304 0.03270819 0.03261758]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 18\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7555620729132942\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 37.99999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 0.9999999999999999\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m divide by zero encountered in log\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brisk_xgb_shap</th>\n",
       "      <th>slug_xgb_shap</th>\n",
       "      <th>slug_ann_ig</th>\n",
       "      <th>slug_ann_shap</th>\n",
       "      <th>slug_ann_gradientshap</th>\n",
       "      <th>slug_rf_shap</th>\n",
       "      <th>slug_knn_shap</th>\n",
       "      <th>brisk_bagging_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new_cases_per_million</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.579548e-02</td>\n",
       "      <td>3.759912e+06</td>\n",
       "      <td>1.884617e+06</td>\n",
       "      <td>3.051007e+06</td>\n",
       "      <td>763.946640</td>\n",
       "      <td>14.309589</td>\n",
       "      <td>0.530441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_cov</th>\n",
       "      <td>0.000273</td>\n",
       "      <td>5.284828e-01</td>\n",
       "      <td>3.619563e+08</td>\n",
       "      <td>3.937101e+08</td>\n",
       "      <td>5.367331e+08</td>\n",
       "      <td>5.718554</td>\n",
       "      <td>39.301761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life_expectancy_cov</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.200456e+02</td>\n",
       "      <td>3.072453e+01</td>\n",
       "      <td>4.508412e+01</td>\n",
       "      <td>1.469238</td>\n",
       "      <td>0.612097</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.901932e-01</td>\n",
       "      <td>4.727798e+08</td>\n",
       "      <td>5.155930e+08</td>\n",
       "      <td>7.027543e+08</td>\n",
       "      <td>12.663485</td>\n",
       "      <td>38.241803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_km2</th>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.583993e-03</td>\n",
       "      <td>3.285954e+06</td>\n",
       "      <td>3.684905e+06</td>\n",
       "      <td>5.693634e+06</td>\n",
       "      <td>1.066764</td>\n",
       "      <td>28.207985</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density_km2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.061057e-03</td>\n",
       "      <td>2.110041e+04</td>\n",
       "      <td>8.469975e+03</td>\n",
       "      <td>6.852935e+03</td>\n",
       "      <td>3.000385</td>\n",
       "      <td>0.478778</td>\n",
       "      <td>0.217915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_x</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.499756e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.092911e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meningitis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.777460e-02</td>\n",
       "      <td>4.144062e-02</td>\n",
       "      <td>7.853202e-01</td>\n",
       "      <td>1.300893</td>\n",
       "      <td>0.412961</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neoplasms</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.472476e-01</td>\n",
       "      <td>1.947015e-01</td>\n",
       "      <td>3.114214e-01</td>\n",
       "      <td>18.083464</td>\n",
       "      <td>0.255938</td>\n",
       "      <td>0.041545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fire, heat, and hot substances</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.031880e-03</td>\n",
       "      <td>1.955676e-02</td>\n",
       "      <td>8.841133e-03</td>\n",
       "      <td>5.811997e-01</td>\n",
       "      <td>0.348636</td>\n",
       "      <td>0.304805</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malaria</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.725290e-09</td>\n",
       "      <td>1.637358e-01</td>\n",
       "      <td>2.556226e-01</td>\n",
       "      <td>1.137365e+00</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drowning</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.053597e-09</td>\n",
       "      <td>4.235708e-02</td>\n",
       "      <td>1.756525e-02</td>\n",
       "      <td>6.030206e-01</td>\n",
       "      <td>1.759573</td>\n",
       "      <td>0.246406</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal violence</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.192763e-01</td>\n",
       "      <td>1.008274e-01</td>\n",
       "      <td>1.090395e+00</td>\n",
       "      <td>0.666105</td>\n",
       "      <td>0.345752</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.483429e-02</td>\n",
       "      <td>7.258049e-02</td>\n",
       "      <td>2.411356e-01</td>\n",
       "      <td>0.372653</td>\n",
       "      <td>0.571845</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug use disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.354265e-02</td>\n",
       "      <td>5.445220e-03</td>\n",
       "      <td>4.314972e-03</td>\n",
       "      <td>3.589146e-01</td>\n",
       "      <td>3.885825</td>\n",
       "      <td>0.334351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuberculosis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.836706e-03</td>\n",
       "      <td>7.412192e-02</td>\n",
       "      <td>7.916742e-02</td>\n",
       "      <td>4.388602e-01</td>\n",
       "      <td>0.168143</td>\n",
       "      <td>0.229569</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Road injuries</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.328306e-09</td>\n",
       "      <td>1.168419e-01</td>\n",
       "      <td>5.488226e-02</td>\n",
       "      <td>6.078232e-01</td>\n",
       "      <td>1.370934</td>\n",
       "      <td>0.221051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternal disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.339502e-01</td>\n",
       "      <td>2.916596e-02</td>\n",
       "      <td>3.264093e-02</td>\n",
       "      <td>6.761382e-01</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0.343092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower respiratory infections</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000568e-03</td>\n",
       "      <td>2.128088e-01</td>\n",
       "      <td>5.426019e-02</td>\n",
       "      <td>1.822360e-01</td>\n",
       "      <td>2.313544</td>\n",
       "      <td>0.500470</td>\n",
       "      <td>0.005955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neonatal disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.862645e-09</td>\n",
       "      <td>1.984956e-01</td>\n",
       "      <td>1.835832e-01</td>\n",
       "      <td>6.895162e-01</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.246068</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol use disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.248445e-03</td>\n",
       "      <td>4.239668e-02</td>\n",
       "      <td>3.591148e-02</td>\n",
       "      <td>8.808536e-01</td>\n",
       "      <td>5.053179</td>\n",
       "      <td>0.585469</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exposure to forces of nature</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.110860e-04</td>\n",
       "      <td>6.355961e-04</td>\n",
       "      <td>2.979933e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diarrheal diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.768666e-03</td>\n",
       "      <td>1.281314e-01</td>\n",
       "      <td>1.358054e-01</td>\n",
       "      <td>5.965900e-01</td>\n",
       "      <td>7.210351</td>\n",
       "      <td>0.489824</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environmental heat and cold exposure</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.603593e-03</td>\n",
       "      <td>9.175064e-03</td>\n",
       "      <td>7.808540e-01</td>\n",
       "      <td>5.701359</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nutritional deficiencies</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.381903e-09</td>\n",
       "      <td>8.133803e-03</td>\n",
       "      <td>5.345594e-03</td>\n",
       "      <td>1.243096e-01</td>\n",
       "      <td>6.142014</td>\n",
       "      <td>0.196254</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-harm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028241e-03</td>\n",
       "      <td>8.055637e-02</td>\n",
       "      <td>3.688081e-02</td>\n",
       "      <td>4.257520e-01</td>\n",
       "      <td>0.542290</td>\n",
       "      <td>0.471847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conflict and terrorism</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.329439e-02</td>\n",
       "      <td>3.330289e-02</td>\n",
       "      <td>8.911145e-01</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes mellitus</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.114493e-01</td>\n",
       "      <td>2.445943e-01</td>\n",
       "      <td>8.759073e-01</td>\n",
       "      <td>3.057217</td>\n",
       "      <td>0.692676</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poisonings</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.099336e-03</td>\n",
       "      <td>1.682698e-03</td>\n",
       "      <td>1.835730e-01</td>\n",
       "      <td>78.390893</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein-energy malnutrition</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.201619e-03</td>\n",
       "      <td>1.476112e-02</td>\n",
       "      <td>1.289030e-02</td>\n",
       "      <td>2.484685e-01</td>\n",
       "      <td>1.823979</td>\n",
       "      <td>0.469145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.744492e+00</td>\n",
       "      <td>2.788355e-01</td>\n",
       "      <td>3.993266e-01</td>\n",
       "      <td>15.065207</td>\n",
       "      <td>0.383414</td>\n",
       "      <td>4.166981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronic kidney disease</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.218482e-02</td>\n",
       "      <td>3.467353e-02</td>\n",
       "      <td>2.660116e-01</td>\n",
       "      <td>2.298957</td>\n",
       "      <td>0.628193</td>\n",
       "      <td>5.386588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronic respiratory diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.878691e-01</td>\n",
       "      <td>1.481704e-01</td>\n",
       "      <td>6.857814e-01</td>\n",
       "      <td>0.571618</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cirrhosis and other chronic liver diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.834677e-03</td>\n",
       "      <td>1.841953e-01</td>\n",
       "      <td>4.837235e-02</td>\n",
       "      <td>4.008258e-01</td>\n",
       "      <td>20.187364</td>\n",
       "      <td>0.222210</td>\n",
       "      <td>0.047590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digestive diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.837886e-01</td>\n",
       "      <td>5.989331e-02</td>\n",
       "      <td>3.979172e-01</td>\n",
       "      <td>38.649723</td>\n",
       "      <td>0.317943</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acute hepatitis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534748e-02</td>\n",
       "      <td>7.930660e-03</td>\n",
       "      <td>8.744609e-03</td>\n",
       "      <td>9.016767e-01</td>\n",
       "      <td>1.273661</td>\n",
       "      <td>0.518044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alzheimer's disease and other dementias</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.349317e-01</td>\n",
       "      <td>9.928570e-02</td>\n",
       "      <td>4.664685e-01</td>\n",
       "      <td>18.375947</td>\n",
       "      <td>0.338504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parkinson's disease</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.353821e-02</td>\n",
       "      <td>7.871905e-03</td>\n",
       "      <td>2.237565e-01</td>\n",
       "      <td>16.131918</td>\n",
       "      <td>0.695967</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.385893e-04</td>\n",
       "      <td>2.825689e+00</td>\n",
       "      <td>1.712060e-01</td>\n",
       "      <td>2.649262e-01</td>\n",
       "      <td>15.878807</td>\n",
       "      <td>0.359516</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_polution</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.549680e+02</td>\n",
       "      <td>6.999293e+01</td>\n",
       "      <td>1.034409e+02</td>\n",
       "      <td>5.636775</td>\n",
       "      <td>0.268563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            brisk_xgb_shap  slug_xgb_shap  \\\n",
       "new_cases_per_million                             0.000000   8.579548e-02   \n",
       "population_cov                                    0.000273   5.284828e-01   \n",
       "life_expectancy_cov                               0.000000   0.000000e+00   \n",
       "Population                                        0.000000   1.901932e-01   \n",
       "Area_km2                                          0.000253   1.583993e-03   \n",
       "Density_km2                                       0.000000   1.061057e-03   \n",
       "Year_x                                            0.000000   0.000000e+00   \n",
       "Meningitis                                        0.000000   0.000000e+00   \n",
       "Neoplasms                                         0.000000   0.000000e+00   \n",
       "Fire, heat, and hot substances                    0.000000   1.031880e-03   \n",
       "Malaria                                           0.000000   3.725290e-09   \n",
       "Drowning                                          0.000000   6.053597e-09   \n",
       "Interpersonal violence                            0.000000   0.000000e+00   \n",
       "HIV/AIDS                                          0.000000   0.000000e+00   \n",
       "Drug use disorders                                0.000000   1.354265e-02   \n",
       "Tuberculosis                                      0.000000   2.836706e-03   \n",
       "Road injuries                                     0.000000   2.328306e-09   \n",
       "Maternal disorders                                0.000000   1.339502e-01   \n",
       "Lower respiratory infections                      0.000000   6.000568e-03   \n",
       "Neonatal disorders                                0.000000   1.862645e-09   \n",
       "Alcohol use disorders                             0.000000   2.248445e-03   \n",
       "Exposure to forces of nature                      0.000000   0.000000e+00   \n",
       "Diarrheal diseases                                0.000000   4.768666e-03   \n",
       "Environmental heat and cold exposure              0.000000   0.000000e+00   \n",
       "Nutritional deficiencies                          0.000000   8.381903e-09   \n",
       "Self-harm                                         0.000000   1.028241e-03   \n",
       "Conflict and terrorism                            0.000000   0.000000e+00   \n",
       "Diabetes mellitus                                 0.000000   0.000000e+00   \n",
       "Poisonings                                        0.000000   0.000000e+00   \n",
       "Protein-energy malnutrition                       0.000000   1.201619e-03   \n",
       "Cardiovascular diseases                           0.000000   0.000000e+00   \n",
       "Chronic kidney disease                            0.000000   0.000000e+00   \n",
       "Chronic respiratory diseases                      0.000000   0.000000e+00   \n",
       "Cirrhosis and other chronic liver diseases        0.000000   2.834677e-03   \n",
       "Digestive diseases                                0.000000   0.000000e+00   \n",
       "Acute hepatitis                                   0.000000   1.534748e-02   \n",
       "Alzheimer's disease and other dementias           0.000000   0.000000e+00   \n",
       "Parkinson's disease                               0.000000   0.000000e+00   \n",
       "Total                                             0.000000   6.385893e-04   \n",
       "air_polution                                      0.000000   0.000000e+00   \n",
       "\n",
       "                                             slug_ann_ig  slug_ann_shap  \\\n",
       "new_cases_per_million                       3.759912e+06   1.884617e+06   \n",
       "population_cov                              3.619563e+08   3.937101e+08   \n",
       "life_expectancy_cov                         4.200456e+02   3.072453e+01   \n",
       "Population                                  4.727798e+08   5.155930e+08   \n",
       "Area_km2                                    3.285954e+06   3.684905e+06   \n",
       "Density_km2                                 2.110041e+04   8.469975e+03   \n",
       "Year_x                                      1.499756e+03   0.000000e+00   \n",
       "Meningitis                                  3.777460e-02   4.144062e-02   \n",
       "Neoplasms                                   8.472476e-01   1.947015e-01   \n",
       "Fire, heat, and hot substances              1.955676e-02   8.841133e-03   \n",
       "Malaria                                     1.637358e-01   2.556226e-01   \n",
       "Drowning                                    4.235708e-02   1.756525e-02   \n",
       "Interpersonal violence                      1.192763e-01   1.008274e-01   \n",
       "HIV/AIDS                                    7.483429e-02   7.258049e-02   \n",
       "Drug use disorders                          5.445220e-03   4.314972e-03   \n",
       "Tuberculosis                                7.412192e-02   7.916742e-02   \n",
       "Road injuries                               1.168419e-01   5.488226e-02   \n",
       "Maternal disorders                          2.916596e-02   3.264093e-02   \n",
       "Lower respiratory infections                2.128088e-01   5.426019e-02   \n",
       "Neonatal disorders                          1.984956e-01   1.835832e-01   \n",
       "Alcohol use disorders                       4.239668e-02   3.591148e-02   \n",
       "Exposure to forces of nature                6.110860e-04   6.355961e-04   \n",
       "Diarrheal diseases                          1.281314e-01   1.358054e-01   \n",
       "Environmental heat and cold exposure        7.603593e-03   9.175064e-03   \n",
       "Nutritional deficiencies                    8.133803e-03   5.345594e-03   \n",
       "Self-harm                                   8.055637e-02   3.688081e-02   \n",
       "Conflict and terrorism                      1.329439e-02   3.330289e-02   \n",
       "Diabetes mellitus                           4.114493e-01   2.445943e-01   \n",
       "Poisonings                                  2.099336e-03   1.682698e-03   \n",
       "Protein-energy malnutrition                 1.476112e-02   1.289030e-02   \n",
       "Cardiovascular diseases                     1.744492e+00   2.788355e-01   \n",
       "Chronic kidney disease                      7.218482e-02   3.467353e-02   \n",
       "Chronic respiratory diseases                3.878691e-01   1.481704e-01   \n",
       "Cirrhosis and other chronic liver diseases  1.841953e-01   4.837235e-02   \n",
       "Digestive diseases                          2.837886e-01   5.989331e-02   \n",
       "Acute hepatitis                             7.930660e-03   8.744609e-03   \n",
       "Alzheimer's disease and other dementias     1.349317e-01   9.928570e-02   \n",
       "Parkinson's disease                         2.353821e-02   7.871905e-03   \n",
       "Total                                       2.825689e+00   1.712060e-01   \n",
       "air_polution                                1.549680e+02   6.999293e+01   \n",
       "\n",
       "                                            slug_ann_gradientshap  \\\n",
       "new_cases_per_million                                3.051007e+06   \n",
       "population_cov                                       5.367331e+08   \n",
       "life_expectancy_cov                                  4.508412e+01   \n",
       "Population                                           7.027543e+08   \n",
       "Area_km2                                             5.693634e+06   \n",
       "Density_km2                                          6.852935e+03   \n",
       "Year_x                                               3.092911e-02   \n",
       "Meningitis                                           7.853202e-01   \n",
       "Neoplasms                                            3.114214e-01   \n",
       "Fire, heat, and hot substances                       5.811997e-01   \n",
       "Malaria                                              1.137365e+00   \n",
       "Drowning                                             6.030206e-01   \n",
       "Interpersonal violence                               1.090395e+00   \n",
       "HIV/AIDS                                             2.411356e-01   \n",
       "Drug use disorders                                   3.589146e-01   \n",
       "Tuberculosis                                         4.388602e-01   \n",
       "Road injuries                                        6.078232e-01   \n",
       "Maternal disorders                                   6.761382e-01   \n",
       "Lower respiratory infections                         1.822360e-01   \n",
       "Neonatal disorders                                   6.895162e-01   \n",
       "Alcohol use disorders                                8.808536e-01   \n",
       "Exposure to forces of nature                         2.979933e-01   \n",
       "Diarrheal diseases                                   5.965900e-01   \n",
       "Environmental heat and cold exposure                 7.808540e-01   \n",
       "Nutritional deficiencies                             1.243096e-01   \n",
       "Self-harm                                            4.257520e-01   \n",
       "Conflict and terrorism                               8.911145e-01   \n",
       "Diabetes mellitus                                    8.759073e-01   \n",
       "Poisonings                                           1.835730e-01   \n",
       "Protein-energy malnutrition                          2.484685e-01   \n",
       "Cardiovascular diseases                              3.993266e-01   \n",
       "Chronic kidney disease                               2.660116e-01   \n",
       "Chronic respiratory diseases                         6.857814e-01   \n",
       "Cirrhosis and other chronic liver diseases           4.008258e-01   \n",
       "Digestive diseases                                   3.979172e-01   \n",
       "Acute hepatitis                                      9.016767e-01   \n",
       "Alzheimer's disease and other dementias              4.664685e-01   \n",
       "Parkinson's disease                                  2.237565e-01   \n",
       "Total                                                2.649262e-01   \n",
       "air_polution                                         1.034409e+02   \n",
       "\n",
       "                                            slug_rf_shap  slug_knn_shap  \\\n",
       "new_cases_per_million                         763.946640      14.309589   \n",
       "population_cov                                  5.718554      39.301761   \n",
       "life_expectancy_cov                             1.469238       0.612097   \n",
       "Population                                     12.663485      38.241803   \n",
       "Area_km2                                        1.066764      28.207985   \n",
       "Density_km2                                     3.000385       0.478778   \n",
       "Year_x                                          0.000000       0.000000   \n",
       "Meningitis                                      1.300893       0.412961   \n",
       "Neoplasms                                      18.083464       0.255938   \n",
       "Fire, heat, and hot substances                  0.348636       0.304805   \n",
       "Malaria                                         0.013338       0.023881   \n",
       "Drowning                                        1.759573       0.246406   \n",
       "Interpersonal violence                          0.666105       0.345752   \n",
       "HIV/AIDS                                        0.372653       0.571845   \n",
       "Drug use disorders                              3.885825       0.334351   \n",
       "Tuberculosis                                    0.168143       0.229569   \n",
       "Road injuries                                   1.370934       0.221051   \n",
       "Maternal disorders                              0.021719       0.343092   \n",
       "Lower respiratory infections                    2.313544       0.500470   \n",
       "Neonatal disorders                              0.770380       0.246068   \n",
       "Alcohol use disorders                           5.053179       0.585469   \n",
       "Exposure to forces of nature                    0.000000       0.072240   \n",
       "Diarrheal diseases                              7.210351       0.489824   \n",
       "Environmental heat and cold exposure            5.701359       0.212698   \n",
       "Nutritional deficiencies                        6.142014       0.196254   \n",
       "Self-harm                                       0.542290       0.471847   \n",
       "Conflict and terrorism                          0.006869       0.051531   \n",
       "Diabetes mellitus                               3.057217       0.692676   \n",
       "Poisonings                                     78.390893       0.382756   \n",
       "Protein-energy malnutrition                     1.823979       0.469145   \n",
       "Cardiovascular diseases                        15.065207       0.383414   \n",
       "Chronic kidney disease                          2.298957       0.628193   \n",
       "Chronic respiratory diseases                    0.571618       0.573561   \n",
       "Cirrhosis and other chronic liver diseases     20.187364       0.222210   \n",
       "Digestive diseases                             38.649723       0.317943   \n",
       "Acute hepatitis                                 1.273661       0.518044   \n",
       "Alzheimer's disease and other dementias        18.375947       0.338504   \n",
       "Parkinson's disease                            16.131918       0.695967   \n",
       "Total                                          15.878807       0.359516   \n",
       "air_polution                                    5.636775       0.268563   \n",
       "\n",
       "                                            brisk_bagging_shap  \n",
       "new_cases_per_million                                 0.530441  \n",
       "population_cov                                        0.000000  \n",
       "life_expectancy_cov                                   0.000000  \n",
       "Population                                            0.000000  \n",
       "Area_km2                                              0.000000  \n",
       "Density_km2                                           0.217915  \n",
       "Year_x                                                0.000000  \n",
       "Meningitis                                            0.000000  \n",
       "Neoplasms                                             0.041545  \n",
       "Fire, heat, and hot substances                        0.000000  \n",
       "Malaria                                               0.000000  \n",
       "Drowning                                              0.000000  \n",
       "Interpersonal violence                                0.000000  \n",
       "HIV/AIDS                                              0.000000  \n",
       "Drug use disorders                                    0.000000  \n",
       "Tuberculosis                                          0.000000  \n",
       "Road injuries                                         0.000000  \n",
       "Maternal disorders                                    0.000000  \n",
       "Lower respiratory infections                          0.005955  \n",
       "Neonatal disorders                                    0.000000  \n",
       "Alcohol use disorders                                 0.000000  \n",
       "Exposure to forces of nature                          0.000000  \n",
       "Diarrheal diseases                                    0.000000  \n",
       "Environmental heat and cold exposure                  0.000000  \n",
       "Nutritional deficiencies                              0.000000  \n",
       "Self-harm                                             0.000000  \n",
       "Conflict and terrorism                                0.000000  \n",
       "Diabetes mellitus                                     0.000000  \n",
       "Poisonings                                            0.000000  \n",
       "Protein-energy malnutrition                           0.000000  \n",
       "Cardiovascular diseases                               4.166981  \n",
       "Chronic kidney disease                                5.386588  \n",
       "Chronic respiratory diseases                          0.000000  \n",
       "Cirrhosis and other chronic liver diseases            0.047590  \n",
       "Digestive diseases                                    0.000293  \n",
       "Acute hepatitis                                       0.000000  \n",
       "Alzheimer's disease and other dementias               0.000000  \n",
       "Parkinson's disease                                   0.000000  \n",
       "Total                                                 0.010800  \n",
       "air_polution                                          0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.000000000000014\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000004\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.04353659\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.        ]\n",
      " 99%|█████████▉| 190/191 [00:11<00:00, 16.93it/s]X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.16461435 0.11279131 0.08701044 0.07165566 0.06152253 0.05438153\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.0491188  0.04511652 0.04200504 0.0395502  0.0375971  0.03603983\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m  0.03480418 0.03383739 0.0331018  0.03257075 0.03222609 0.03205648]\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 19\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7572517560136776\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 39.00000000000001\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m from sklearn.pipeline import make_pipeline\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m model.fit(X, y, **kwargs)\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m 2022-11-23T04:55:26PST : INFO : _kernel : solve : 605 : Message : phi = [ 0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.         -0.04353659\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.          0.          0.          0.\n",
      "\u001b[2m\u001b[36m(__get_shapley_kernel_attr__ pid=526, ip=10.10.105.191)\u001b[0m   0.          0.          0.        ]\n",
      "100%|██████████| 191/191 [00:11<00:00, 16.81it/s]=10.10.105.191)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "ex = Explainable(ensemble_set, df_X)\n",
    "ex.get_attr(attr_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brisk_xgb_shap</th>\n",
       "      <th>slug_xgb_shap</th>\n",
       "      <th>slug_ann_ig</th>\n",
       "      <th>slug_ann_shap</th>\n",
       "      <th>slug_ann_gradientshap</th>\n",
       "      <th>slug_rf_shap</th>\n",
       "      <th>slug_knn_shap</th>\n",
       "      <th>brisk_bagging_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new_cases_per_million</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.579548e-02</td>\n",
       "      <td>3.759912e+06</td>\n",
       "      <td>1.884617e+06</td>\n",
       "      <td>3.051007e+06</td>\n",
       "      <td>763.946640</td>\n",
       "      <td>14.309589</td>\n",
       "      <td>0.530441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_cov</th>\n",
       "      <td>0.000273</td>\n",
       "      <td>5.284828e-01</td>\n",
       "      <td>3.619563e+08</td>\n",
       "      <td>3.937101e+08</td>\n",
       "      <td>5.367331e+08</td>\n",
       "      <td>5.718554</td>\n",
       "      <td>39.301761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life_expectancy_cov</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.200456e+02</td>\n",
       "      <td>3.072453e+01</td>\n",
       "      <td>4.508412e+01</td>\n",
       "      <td>1.469238</td>\n",
       "      <td>0.612097</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.901932e-01</td>\n",
       "      <td>4.727798e+08</td>\n",
       "      <td>5.155930e+08</td>\n",
       "      <td>7.027543e+08</td>\n",
       "      <td>12.663485</td>\n",
       "      <td>38.241803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_km2</th>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.583993e-03</td>\n",
       "      <td>3.285954e+06</td>\n",
       "      <td>3.684905e+06</td>\n",
       "      <td>5.693634e+06</td>\n",
       "      <td>1.066764</td>\n",
       "      <td>28.207985</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density_km2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.061057e-03</td>\n",
       "      <td>2.110041e+04</td>\n",
       "      <td>8.469975e+03</td>\n",
       "      <td>6.852935e+03</td>\n",
       "      <td>3.000385</td>\n",
       "      <td>0.478778</td>\n",
       "      <td>0.217915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_x</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.499756e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.092911e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meningitis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.777460e-02</td>\n",
       "      <td>4.144062e-02</td>\n",
       "      <td>7.853202e-01</td>\n",
       "      <td>1.300893</td>\n",
       "      <td>0.412961</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neoplasms</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.472476e-01</td>\n",
       "      <td>1.947015e-01</td>\n",
       "      <td>3.114214e-01</td>\n",
       "      <td>18.083464</td>\n",
       "      <td>0.255938</td>\n",
       "      <td>0.041545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fire, heat, and hot substances</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.031880e-03</td>\n",
       "      <td>1.955676e-02</td>\n",
       "      <td>8.841133e-03</td>\n",
       "      <td>5.811997e-01</td>\n",
       "      <td>0.348636</td>\n",
       "      <td>0.304805</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malaria</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.725290e-09</td>\n",
       "      <td>1.637358e-01</td>\n",
       "      <td>2.556226e-01</td>\n",
       "      <td>1.137365e+00</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drowning</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.053597e-09</td>\n",
       "      <td>4.235708e-02</td>\n",
       "      <td>1.756525e-02</td>\n",
       "      <td>6.030206e-01</td>\n",
       "      <td>1.759573</td>\n",
       "      <td>0.246406</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal violence</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.192763e-01</td>\n",
       "      <td>1.008274e-01</td>\n",
       "      <td>1.090395e+00</td>\n",
       "      <td>0.666105</td>\n",
       "      <td>0.345752</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.483429e-02</td>\n",
       "      <td>7.258049e-02</td>\n",
       "      <td>2.411356e-01</td>\n",
       "      <td>0.372653</td>\n",
       "      <td>0.571845</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug use disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.354265e-02</td>\n",
       "      <td>5.445220e-03</td>\n",
       "      <td>4.314972e-03</td>\n",
       "      <td>3.589146e-01</td>\n",
       "      <td>3.885825</td>\n",
       "      <td>0.334351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuberculosis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.836706e-03</td>\n",
       "      <td>7.412192e-02</td>\n",
       "      <td>7.916742e-02</td>\n",
       "      <td>4.388602e-01</td>\n",
       "      <td>0.168143</td>\n",
       "      <td>0.229569</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Road injuries</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.328306e-09</td>\n",
       "      <td>1.168419e-01</td>\n",
       "      <td>5.488226e-02</td>\n",
       "      <td>6.078232e-01</td>\n",
       "      <td>1.370934</td>\n",
       "      <td>0.221051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternal disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.339502e-01</td>\n",
       "      <td>2.916596e-02</td>\n",
       "      <td>3.264093e-02</td>\n",
       "      <td>6.761382e-01</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0.343092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower respiratory infections</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000568e-03</td>\n",
       "      <td>2.128088e-01</td>\n",
       "      <td>5.426019e-02</td>\n",
       "      <td>1.822360e-01</td>\n",
       "      <td>2.313544</td>\n",
       "      <td>0.500470</td>\n",
       "      <td>0.005955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neonatal disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.862645e-09</td>\n",
       "      <td>1.984956e-01</td>\n",
       "      <td>1.835832e-01</td>\n",
       "      <td>6.895162e-01</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.246068</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol use disorders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.248445e-03</td>\n",
       "      <td>4.239668e-02</td>\n",
       "      <td>3.591148e-02</td>\n",
       "      <td>8.808536e-01</td>\n",
       "      <td>5.053179</td>\n",
       "      <td>0.585469</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exposure to forces of nature</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.110860e-04</td>\n",
       "      <td>6.355961e-04</td>\n",
       "      <td>2.979933e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diarrheal diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.768666e-03</td>\n",
       "      <td>1.281314e-01</td>\n",
       "      <td>1.358054e-01</td>\n",
       "      <td>5.965900e-01</td>\n",
       "      <td>7.210351</td>\n",
       "      <td>0.489824</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environmental heat and cold exposure</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.603593e-03</td>\n",
       "      <td>9.175064e-03</td>\n",
       "      <td>7.808540e-01</td>\n",
       "      <td>5.701359</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nutritional deficiencies</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.381903e-09</td>\n",
       "      <td>8.133803e-03</td>\n",
       "      <td>5.345594e-03</td>\n",
       "      <td>1.243096e-01</td>\n",
       "      <td>6.142014</td>\n",
       "      <td>0.196254</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-harm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028241e-03</td>\n",
       "      <td>8.055637e-02</td>\n",
       "      <td>3.688081e-02</td>\n",
       "      <td>4.257520e-01</td>\n",
       "      <td>0.542290</td>\n",
       "      <td>0.471847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conflict and terrorism</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.329439e-02</td>\n",
       "      <td>3.330289e-02</td>\n",
       "      <td>8.911145e-01</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes mellitus</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.114493e-01</td>\n",
       "      <td>2.445943e-01</td>\n",
       "      <td>8.759073e-01</td>\n",
       "      <td>3.057217</td>\n",
       "      <td>0.692676</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poisonings</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.099336e-03</td>\n",
       "      <td>1.682698e-03</td>\n",
       "      <td>1.835730e-01</td>\n",
       "      <td>78.390893</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein-energy malnutrition</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.201619e-03</td>\n",
       "      <td>1.476112e-02</td>\n",
       "      <td>1.289030e-02</td>\n",
       "      <td>2.484685e-01</td>\n",
       "      <td>1.823979</td>\n",
       "      <td>0.469145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.744492e+00</td>\n",
       "      <td>2.788355e-01</td>\n",
       "      <td>3.993266e-01</td>\n",
       "      <td>15.065207</td>\n",
       "      <td>0.383414</td>\n",
       "      <td>4.166981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronic kidney disease</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.218482e-02</td>\n",
       "      <td>3.467353e-02</td>\n",
       "      <td>2.660116e-01</td>\n",
       "      <td>2.298957</td>\n",
       "      <td>0.628193</td>\n",
       "      <td>5.386588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronic respiratory diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.878691e-01</td>\n",
       "      <td>1.481704e-01</td>\n",
       "      <td>6.857814e-01</td>\n",
       "      <td>0.571618</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cirrhosis and other chronic liver diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.834677e-03</td>\n",
       "      <td>1.841953e-01</td>\n",
       "      <td>4.837235e-02</td>\n",
       "      <td>4.008258e-01</td>\n",
       "      <td>20.187364</td>\n",
       "      <td>0.222210</td>\n",
       "      <td>0.047590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digestive diseases</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.837886e-01</td>\n",
       "      <td>5.989331e-02</td>\n",
       "      <td>3.979172e-01</td>\n",
       "      <td>38.649723</td>\n",
       "      <td>0.317943</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acute hepatitis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534748e-02</td>\n",
       "      <td>7.930660e-03</td>\n",
       "      <td>8.744609e-03</td>\n",
       "      <td>9.016767e-01</td>\n",
       "      <td>1.273661</td>\n",
       "      <td>0.518044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alzheimer's disease and other dementias</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.349317e-01</td>\n",
       "      <td>9.928570e-02</td>\n",
       "      <td>4.664685e-01</td>\n",
       "      <td>18.375947</td>\n",
       "      <td>0.338504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parkinson's disease</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.353821e-02</td>\n",
       "      <td>7.871905e-03</td>\n",
       "      <td>2.237565e-01</td>\n",
       "      <td>16.131918</td>\n",
       "      <td>0.695967</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.385893e-04</td>\n",
       "      <td>2.825689e+00</td>\n",
       "      <td>1.712060e-01</td>\n",
       "      <td>2.649262e-01</td>\n",
       "      <td>15.878807</td>\n",
       "      <td>0.359516</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_polution</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.549680e+02</td>\n",
       "      <td>6.999293e+01</td>\n",
       "      <td>1.034409e+02</td>\n",
       "      <td>5.636775</td>\n",
       "      <td>0.268563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            brisk_xgb_shap  slug_xgb_shap  \\\n",
       "new_cases_per_million                             0.000000   8.579548e-02   \n",
       "population_cov                                    0.000273   5.284828e-01   \n",
       "life_expectancy_cov                               0.000000   0.000000e+00   \n",
       "Population                                        0.000000   1.901932e-01   \n",
       "Area_km2                                          0.000253   1.583993e-03   \n",
       "Density_km2                                       0.000000   1.061057e-03   \n",
       "Year_x                                            0.000000   0.000000e+00   \n",
       "Meningitis                                        0.000000   0.000000e+00   \n",
       "Neoplasms                                         0.000000   0.000000e+00   \n",
       "Fire, heat, and hot substances                    0.000000   1.031880e-03   \n",
       "Malaria                                           0.000000   3.725290e-09   \n",
       "Drowning                                          0.000000   6.053597e-09   \n",
       "Interpersonal violence                            0.000000   0.000000e+00   \n",
       "HIV/AIDS                                          0.000000   0.000000e+00   \n",
       "Drug use disorders                                0.000000   1.354265e-02   \n",
       "Tuberculosis                                      0.000000   2.836706e-03   \n",
       "Road injuries                                     0.000000   2.328306e-09   \n",
       "Maternal disorders                                0.000000   1.339502e-01   \n",
       "Lower respiratory infections                      0.000000   6.000568e-03   \n",
       "Neonatal disorders                                0.000000   1.862645e-09   \n",
       "Alcohol use disorders                             0.000000   2.248445e-03   \n",
       "Exposure to forces of nature                      0.000000   0.000000e+00   \n",
       "Diarrheal diseases                                0.000000   4.768666e-03   \n",
       "Environmental heat and cold exposure              0.000000   0.000000e+00   \n",
       "Nutritional deficiencies                          0.000000   8.381903e-09   \n",
       "Self-harm                                         0.000000   1.028241e-03   \n",
       "Conflict and terrorism                            0.000000   0.000000e+00   \n",
       "Diabetes mellitus                                 0.000000   0.000000e+00   \n",
       "Poisonings                                        0.000000   0.000000e+00   \n",
       "Protein-energy malnutrition                       0.000000   1.201619e-03   \n",
       "Cardiovascular diseases                           0.000000   0.000000e+00   \n",
       "Chronic kidney disease                            0.000000   0.000000e+00   \n",
       "Chronic respiratory diseases                      0.000000   0.000000e+00   \n",
       "Cirrhosis and other chronic liver diseases        0.000000   2.834677e-03   \n",
       "Digestive diseases                                0.000000   0.000000e+00   \n",
       "Acute hepatitis                                   0.000000   1.534748e-02   \n",
       "Alzheimer's disease and other dementias           0.000000   0.000000e+00   \n",
       "Parkinson's disease                               0.000000   0.000000e+00   \n",
       "Total                                             0.000000   6.385893e-04   \n",
       "air_polution                                      0.000000   0.000000e+00   \n",
       "\n",
       "                                             slug_ann_ig  slug_ann_shap  \\\n",
       "new_cases_per_million                       3.759912e+06   1.884617e+06   \n",
       "population_cov                              3.619563e+08   3.937101e+08   \n",
       "life_expectancy_cov                         4.200456e+02   3.072453e+01   \n",
       "Population                                  4.727798e+08   5.155930e+08   \n",
       "Area_km2                                    3.285954e+06   3.684905e+06   \n",
       "Density_km2                                 2.110041e+04   8.469975e+03   \n",
       "Year_x                                      1.499756e+03   0.000000e+00   \n",
       "Meningitis                                  3.777460e-02   4.144062e-02   \n",
       "Neoplasms                                   8.472476e-01   1.947015e-01   \n",
       "Fire, heat, and hot substances              1.955676e-02   8.841133e-03   \n",
       "Malaria                                     1.637358e-01   2.556226e-01   \n",
       "Drowning                                    4.235708e-02   1.756525e-02   \n",
       "Interpersonal violence                      1.192763e-01   1.008274e-01   \n",
       "HIV/AIDS                                    7.483429e-02   7.258049e-02   \n",
       "Drug use disorders                          5.445220e-03   4.314972e-03   \n",
       "Tuberculosis                                7.412192e-02   7.916742e-02   \n",
       "Road injuries                               1.168419e-01   5.488226e-02   \n",
       "Maternal disorders                          2.916596e-02   3.264093e-02   \n",
       "Lower respiratory infections                2.128088e-01   5.426019e-02   \n",
       "Neonatal disorders                          1.984956e-01   1.835832e-01   \n",
       "Alcohol use disorders                       4.239668e-02   3.591148e-02   \n",
       "Exposure to forces of nature                6.110860e-04   6.355961e-04   \n",
       "Diarrheal diseases                          1.281314e-01   1.358054e-01   \n",
       "Environmental heat and cold exposure        7.603593e-03   9.175064e-03   \n",
       "Nutritional deficiencies                    8.133803e-03   5.345594e-03   \n",
       "Self-harm                                   8.055637e-02   3.688081e-02   \n",
       "Conflict and terrorism                      1.329439e-02   3.330289e-02   \n",
       "Diabetes mellitus                           4.114493e-01   2.445943e-01   \n",
       "Poisonings                                  2.099336e-03   1.682698e-03   \n",
       "Protein-energy malnutrition                 1.476112e-02   1.289030e-02   \n",
       "Cardiovascular diseases                     1.744492e+00   2.788355e-01   \n",
       "Chronic kidney disease                      7.218482e-02   3.467353e-02   \n",
       "Chronic respiratory diseases                3.878691e-01   1.481704e-01   \n",
       "Cirrhosis and other chronic liver diseases  1.841953e-01   4.837235e-02   \n",
       "Digestive diseases                          2.837886e-01   5.989331e-02   \n",
       "Acute hepatitis                             7.930660e-03   8.744609e-03   \n",
       "Alzheimer's disease and other dementias     1.349317e-01   9.928570e-02   \n",
       "Parkinson's disease                         2.353821e-02   7.871905e-03   \n",
       "Total                                       2.825689e+00   1.712060e-01   \n",
       "air_polution                                1.549680e+02   6.999293e+01   \n",
       "\n",
       "                                            slug_ann_gradientshap  \\\n",
       "new_cases_per_million                                3.051007e+06   \n",
       "population_cov                                       5.367331e+08   \n",
       "life_expectancy_cov                                  4.508412e+01   \n",
       "Population                                           7.027543e+08   \n",
       "Area_km2                                             5.693634e+06   \n",
       "Density_km2                                          6.852935e+03   \n",
       "Year_x                                               3.092911e-02   \n",
       "Meningitis                                           7.853202e-01   \n",
       "Neoplasms                                            3.114214e-01   \n",
       "Fire, heat, and hot substances                       5.811997e-01   \n",
       "Malaria                                              1.137365e+00   \n",
       "Drowning                                             6.030206e-01   \n",
       "Interpersonal violence                               1.090395e+00   \n",
       "HIV/AIDS                                             2.411356e-01   \n",
       "Drug use disorders                                   3.589146e-01   \n",
       "Tuberculosis                                         4.388602e-01   \n",
       "Road injuries                                        6.078232e-01   \n",
       "Maternal disorders                                   6.761382e-01   \n",
       "Lower respiratory infections                         1.822360e-01   \n",
       "Neonatal disorders                                   6.895162e-01   \n",
       "Alcohol use disorders                                8.808536e-01   \n",
       "Exposure to forces of nature                         2.979933e-01   \n",
       "Diarrheal diseases                                   5.965900e-01   \n",
       "Environmental heat and cold exposure                 7.808540e-01   \n",
       "Nutritional deficiencies                             1.243096e-01   \n",
       "Self-harm                                            4.257520e-01   \n",
       "Conflict and terrorism                               8.911145e-01   \n",
       "Diabetes mellitus                                    8.759073e-01   \n",
       "Poisonings                                           1.835730e-01   \n",
       "Protein-energy malnutrition                          2.484685e-01   \n",
       "Cardiovascular diseases                              3.993266e-01   \n",
       "Chronic kidney disease                               2.660116e-01   \n",
       "Chronic respiratory diseases                         6.857814e-01   \n",
       "Cirrhosis and other chronic liver diseases           4.008258e-01   \n",
       "Digestive diseases                                   3.979172e-01   \n",
       "Acute hepatitis                                      9.016767e-01   \n",
       "Alzheimer's disease and other dementias              4.664685e-01   \n",
       "Parkinson's disease                                  2.237565e-01   \n",
       "Total                                                2.649262e-01   \n",
       "air_polution                                         1.034409e+02   \n",
       "\n",
       "                                            slug_rf_shap  slug_knn_shap  \\\n",
       "new_cases_per_million                         763.946640      14.309589   \n",
       "population_cov                                  5.718554      39.301761   \n",
       "life_expectancy_cov                             1.469238       0.612097   \n",
       "Population                                     12.663485      38.241803   \n",
       "Area_km2                                        1.066764      28.207985   \n",
       "Density_km2                                     3.000385       0.478778   \n",
       "Year_x                                          0.000000       0.000000   \n",
       "Meningitis                                      1.300893       0.412961   \n",
       "Neoplasms                                      18.083464       0.255938   \n",
       "Fire, heat, and hot substances                  0.348636       0.304805   \n",
       "Malaria                                         0.013338       0.023881   \n",
       "Drowning                                        1.759573       0.246406   \n",
       "Interpersonal violence                          0.666105       0.345752   \n",
       "HIV/AIDS                                        0.372653       0.571845   \n",
       "Drug use disorders                              3.885825       0.334351   \n",
       "Tuberculosis                                    0.168143       0.229569   \n",
       "Road injuries                                   1.370934       0.221051   \n",
       "Maternal disorders                              0.021719       0.343092   \n",
       "Lower respiratory infections                    2.313544       0.500470   \n",
       "Neonatal disorders                              0.770380       0.246068   \n",
       "Alcohol use disorders                           5.053179       0.585469   \n",
       "Exposure to forces of nature                    0.000000       0.072240   \n",
       "Diarrheal diseases                              7.210351       0.489824   \n",
       "Environmental heat and cold exposure            5.701359       0.212698   \n",
       "Nutritional deficiencies                        6.142014       0.196254   \n",
       "Self-harm                                       0.542290       0.471847   \n",
       "Conflict and terrorism                          0.006869       0.051531   \n",
       "Diabetes mellitus                               3.057217       0.692676   \n",
       "Poisonings                                     78.390893       0.382756   \n",
       "Protein-energy malnutrition                     1.823979       0.469145   \n",
       "Cardiovascular diseases                        15.065207       0.383414   \n",
       "Chronic kidney disease                          2.298957       0.628193   \n",
       "Chronic respiratory diseases                    0.571618       0.573561   \n",
       "Cirrhosis and other chronic liver diseases     20.187364       0.222210   \n",
       "Digestive diseases                             38.649723       0.317943   \n",
       "Acute hepatitis                                 1.273661       0.518044   \n",
       "Alzheimer's disease and other dementias        18.375947       0.338504   \n",
       "Parkinson's disease                            16.131918       0.695967   \n",
       "Total                                          15.878807       0.359516   \n",
       "air_polution                                    5.636775       0.268563   \n",
       "\n",
       "                                            brisk_bagging_shap  \n",
       "new_cases_per_million                                 0.530441  \n",
       "population_cov                                        0.000000  \n",
       "life_expectancy_cov                                   0.000000  \n",
       "Population                                            0.000000  \n",
       "Area_km2                                              0.000000  \n",
       "Density_km2                                           0.217915  \n",
       "Year_x                                                0.000000  \n",
       "Meningitis                                            0.000000  \n",
       "Neoplasms                                             0.041545  \n",
       "Fire, heat, and hot substances                        0.000000  \n",
       "Malaria                                               0.000000  \n",
       "Drowning                                              0.000000  \n",
       "Interpersonal violence                                0.000000  \n",
       "HIV/AIDS                                              0.000000  \n",
       "Drug use disorders                                    0.000000  \n",
       "Tuberculosis                                          0.000000  \n",
       "Road injuries                                         0.000000  \n",
       "Maternal disorders                                    0.000000  \n",
       "Lower respiratory infections                          0.005955  \n",
       "Neonatal disorders                                    0.000000  \n",
       "Alcohol use disorders                                 0.000000  \n",
       "Exposure to forces of nature                          0.000000  \n",
       "Diarrheal diseases                                    0.000000  \n",
       "Environmental heat and cold exposure                  0.000000  \n",
       "Nutritional deficiencies                              0.000000  \n",
       "Self-harm                                             0.000000  \n",
       "Conflict and terrorism                                0.000000  \n",
       "Diabetes mellitus                                     0.000000  \n",
       "Poisonings                                            0.000000  \n",
       "Protein-energy malnutrition                           0.000000  \n",
       "Cardiovascular diseases                               4.166981  \n",
       "Chronic kidney disease                                5.386588  \n",
       "Chronic respiratory diseases                          0.000000  \n",
       "Cirrhosis and other chronic liver diseases            0.047590  \n",
       "Digestive diseases                                    0.000293  \n",
       "Acute hepatitis                                       0.000000  \n",
       "Alzheimer's disease and other dementias               0.000000  \n",
       "Parkinson's disease                                   0.000000  \n",
       "Total                                                 0.010800  \n",
       "air_polution                                          0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.df_scores['cols'] = ex.df_scores.index\n",
    "ex.df_scores.to_csv('df_scores_3.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_scores_3.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_ranked = pd.DataFrame()\n",
    "\n",
    "for col in df:\n",
    "    if col != 'cols':\n",
    "        df_scores_ranked[col] = df[col].rank(na_option = 'bottom', ascending=True, method='max', pct=False)\n",
    "        # df_scores_ranked\n",
    "        df_scores_ranked.replace(to_replace = df_scores_ranked.min(), value = 0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_scores_ranked = df_scores_ranked.mode(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_ranked['cols'] = df['cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brisk_xgb_shap</th>\n",
       "      <th>slug_xgb_shap</th>\n",
       "      <th>slug_ann_ig</th>\n",
       "      <th>slug_ann_shap</th>\n",
       "      <th>slug_ann_gradientshap</th>\n",
       "      <th>slug_rf_shap</th>\n",
       "      <th>slug_knn_shap</th>\n",
       "      <th>brisk_bagging_shap</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>new_cases_per_million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>population_cov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>life_expectancy_cov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Area_km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Density_km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Year_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Meningitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Neoplasms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fire, heat, and hot substances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Drowning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interpersonal violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HIV/AIDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Drug use disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Road injuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maternal disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Lower respiratory infections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neonatal disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alcohol use disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Exposure to forces of nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Diarrheal diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Environmental heat and cold exposure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nutritional deficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Self-harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Conflict and terrorism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Poisonings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Protein-energy malnutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Cardiovascular diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Chronic kidney disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chronic respiratory diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Cirrhosis and other chronic liver diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Digestive diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Acute hepatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alzheimer's disease and other dementias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Parkinson's disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>air_polution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brisk_xgb_shap  slug_xgb_shap  slug_ann_ig  slug_ann_shap  \\\n",
       "0              0.0           37.0         38.0           37.0   \n",
       "1             40.0           40.0         39.0           39.0   \n",
       "2              0.0            0.0         34.0           34.0   \n",
       "3              0.0           39.0         40.0           40.0   \n",
       "4             39.0           29.0         37.0           38.0   \n",
       "5              0.0           27.0         36.0           36.0   \n",
       "6              0.0            0.0         35.0            0.0   \n",
       "7              0.0            0.0         12.0           17.0   \n",
       "8              0.0            0.0         30.0           30.0   \n",
       "9              0.0           26.0          9.0            8.0   \n",
       "10             0.0           21.0         23.0           32.0   \n",
       "11             0.0           22.0         13.0           11.0   \n",
       "12             0.0            0.0         20.0           25.0   \n",
       "13             0.0            0.0         17.0           22.0   \n",
       "14             0.0           35.0          3.0            4.0   \n",
       "15             0.0           32.0         16.0           23.0   \n",
       "16             0.0           20.0         19.0           20.0   \n",
       "17             0.0           38.0         11.0           12.0   \n",
       "18             0.0           34.0         26.0           19.0   \n",
       "19             0.0           19.0         25.0           29.0   \n",
       "20             0.0           30.0         14.0           15.0   \n",
       "21             0.0            0.0          0.0            2.0   \n",
       "22             0.0           33.0         21.0           26.0   \n",
       "23             0.0            0.0          4.0            9.0   \n",
       "24             0.0           23.0          6.0            5.0   \n",
       "25             0.0           25.0         18.0           16.0   \n",
       "26             0.0            0.0          7.0           13.0   \n",
       "27             0.0            0.0         29.0           31.0   \n",
       "28             0.0            0.0          2.0            3.0   \n",
       "29             0.0           28.0          8.0           10.0   \n",
       "30             0.0            0.0         31.0           33.0   \n",
       "31             0.0            0.0         15.0           14.0   \n",
       "32             0.0            0.0         28.0           27.0   \n",
       "33             0.0           31.0         24.0           18.0   \n",
       "34             0.0            0.0         27.0           21.0   \n",
       "35             0.0           36.0          5.0            7.0   \n",
       "36             0.0            0.0         22.0           24.0   \n",
       "37             0.0            0.0         10.0            6.0   \n",
       "38             0.0           24.0         32.0           28.0   \n",
       "39             0.0            0.0         33.0           35.0   \n",
       "\n",
       "    slug_ann_gradientshap  slug_rf_shap  slug_knn_shap  brisk_bagging_shap  \\\n",
       "0                    37.0          40.0           37.0                38.0   \n",
       "1                    39.0          28.0           40.0                 0.0   \n",
       "2                    34.0          17.0           33.0                 0.0   \n",
       "3                    40.0          31.0           39.0                 0.0   \n",
       "4                    38.0          13.0           38.0                 0.0   \n",
       "5                    36.0          22.0           26.0                37.0   \n",
       "6                     0.0           0.0            0.0                 0.0   \n",
       "7                    27.0          15.0           23.0                 0.0   \n",
       "8                    11.0          35.0           12.0                35.0   \n",
       "9                    19.0           7.0           14.0                 0.0   \n",
       "10                   33.0           4.0            2.0                 0.0   \n",
       "11                   21.0          18.0           11.0                 0.0   \n",
       "12                   32.0          11.0           19.0                 0.0   \n",
       "13                    6.0           8.0           30.0                 0.0   \n",
       "14                   12.0          24.0           16.0                 0.0   \n",
       "15                   17.0           6.0            9.0                 0.0   \n",
       "16                   22.0          16.0            7.0                 0.0   \n",
       "17                   23.0           5.0           18.0                 0.0   \n",
       "18                    3.0          21.0           28.0                33.0   \n",
       "19                   25.0          12.0           10.0                 0.0   \n",
       "20                   29.0          25.0           32.0                 0.0   \n",
       "21                   10.0           0.0            4.0                 0.0   \n",
       "22                   20.0          30.0           27.0                 0.0   \n",
       "23                   26.0          27.0            6.0                 0.0   \n",
       "24                    2.0          29.0            5.0                 0.0   \n",
       "25                   16.0           9.0           25.0                 0.0   \n",
       "26                   30.0           3.0            3.0                 0.0   \n",
       "27                   28.0          23.0           35.0                 0.0   \n",
       "28                    4.0          39.0           21.0                 0.0   \n",
       "29                    7.0          19.0           24.0                 0.0   \n",
       "30                   14.0          32.0           22.0                39.0   \n",
       "31                    9.0          20.0           34.0                40.0   \n",
       "32                   24.0          10.0           31.0                 0.0   \n",
       "33                   15.0          37.0            8.0                36.0   \n",
       "34                   13.0          38.0           15.0                32.0   \n",
       "35                   31.0          14.0           29.0                 0.0   \n",
       "36                   18.0          36.0           17.0                 0.0   \n",
       "37                    5.0          34.0           36.0                 0.0   \n",
       "38                    8.0          33.0           20.0                34.0   \n",
       "39                   35.0          26.0           13.0                 0.0   \n",
       "\n",
       "                                          cols  \n",
       "0                        new_cases_per_million  \n",
       "1                               population_cov  \n",
       "2                          life_expectancy_cov  \n",
       "3                                   Population  \n",
       "4                                     Area_km2  \n",
       "5                                  Density_km2  \n",
       "6                                       Year_x  \n",
       "7                                   Meningitis  \n",
       "8                                    Neoplasms  \n",
       "9               Fire, heat, and hot substances  \n",
       "10                                     Malaria  \n",
       "11                                    Drowning  \n",
       "12                      Interpersonal violence  \n",
       "13                                    HIV/AIDS  \n",
       "14                          Drug use disorders  \n",
       "15                                Tuberculosis  \n",
       "16                               Road injuries  \n",
       "17                          Maternal disorders  \n",
       "18                Lower respiratory infections  \n",
       "19                          Neonatal disorders  \n",
       "20                       Alcohol use disorders  \n",
       "21                Exposure to forces of nature  \n",
       "22                          Diarrheal diseases  \n",
       "23        Environmental heat and cold exposure  \n",
       "24                    Nutritional deficiencies  \n",
       "25                                   Self-harm  \n",
       "26                      Conflict and terrorism  \n",
       "27                           Diabetes mellitus  \n",
       "28                                  Poisonings  \n",
       "29                 Protein-energy malnutrition  \n",
       "30                     Cardiovascular diseases  \n",
       "31                      Chronic kidney disease  \n",
       "32                Chronic respiratory diseases  \n",
       "33  Cirrhosis and other chronic liver diseases  \n",
       "34                          Digestive diseases  \n",
       "35                             Acute hepatitis  \n",
       "36     Alzheimer's disease and other dementias  \n",
       "37                         Parkinson's disease  \n",
       "38                                       Total  \n",
       "39                                air_polution  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_scores_ranked.mode(axis=1, numeric_only=True).mean(axis=1)\n",
    "res.index = df_scores_ranked['cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cols\n",
       "Population                                    40.000000\n",
       "population_cov                                39.500000\n",
       "Area_km2                                      38.000000\n",
       "new_cases_per_million                         37.000000\n",
       "Density_km2                                   36.000000\n",
       "Total                                         22.375000\n",
       "Neoplasms                                     21.666667\n",
       "Cirrhosis and other chronic liver diseases    21.125000\n",
       "Lower respiratory infections                  20.500000\n",
       "life_expectancy_cov                           17.000000\n",
       "Self-harm                                     13.666667\n",
       "Neonatal disorders                            12.500000\n",
       "Road injuries                                 10.000000\n",
       "Drowning                                       5.500000\n",
       "Nutritional deficiencies                       2.500000\n",
       "Diabetes mellitus                              0.000000\n",
       "Poisonings                                     0.000000\n",
       "Protein-energy malnutrition                    0.000000\n",
       "Parkinson's disease                            0.000000\n",
       "Alzheimer's disease and other dementias        0.000000\n",
       "Chronic kidney disease                         0.000000\n",
       "Chronic respiratory diseases                   0.000000\n",
       "Conflict and terrorism                         0.000000\n",
       "Digestive diseases                             0.000000\n",
       "Acute hepatitis                                0.000000\n",
       "Cardiovascular diseases                        0.000000\n",
       "Alcohol use disorders                          0.000000\n",
       "Environmental heat and cold exposure           0.000000\n",
       "Diarrheal diseases                             0.000000\n",
       "Exposure to forces of nature                   0.000000\n",
       "Maternal disorders                             0.000000\n",
       "Tuberculosis                                   0.000000\n",
       "Drug use disorders                             0.000000\n",
       "HIV/AIDS                                       0.000000\n",
       "Interpersonal violence                         0.000000\n",
       "Malaria                                        0.000000\n",
       "Fire, heat, and hot substances                 0.000000\n",
       "Meningitis                                     0.000000\n",
       "Year_x                                         0.000000\n",
       "air_polution                                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admin-admin-wasif-dev-ray",
   "language": "python",
   "name": "conda-env-admin-admin-wasif-dev-ray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a94c6c960097f54adba02dc541c5971cf8d1c3cc945e5d727fdc1dc3c601326"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
