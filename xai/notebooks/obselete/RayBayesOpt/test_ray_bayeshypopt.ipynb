{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085d62fd-57dc-4567-9085-d2665ac27b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '../..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316285f9-1822-44ce-9dea-057f52465954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import helper, config, rayer, kaggle_dataset_helper\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "from ml.models import common\n",
    "import ray\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a000b6b1-6a42-4674-a316-212c14e9cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c463762-530c-4d04-9bb0-d0151ff8c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 12:54:17,405\tINFO packaging.py:527 -- Creating a file package for local directory '/home/wasif/python-asd/xai/'.\n",
      "2022-11-24 12:54:18,741\tINFO packaging.py:354 -- Pushing file package 'gcs://_ray_pkg_5a19cfc0b27118b9.zip' (64.19MiB) to Ray cluster...\n",
      "2022-11-24 12:54:19,737\tINFO packaging.py:367 -- Successfully pushed file package 'gcs://_ray_pkg_5a19cfc0b27118b9.zip'.\n"
     ]
    }
   ],
   "source": [
    "rayer.get_global_cluster(num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb54084e-3231-4754-8e3b-f15f7571247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2022-11-24 12:56:35.476387 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Healthy:\n",
      " 1 head-group\n",
      " 6 small-group\n",
      "Pending:\n",
      " IP not yet assigned: small-group, waiting\n",
      " IP not yet assigned: small-group, waiting\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Usage:\n",
      " 0.0/25.0 CPU\n",
      " 0.00/91.270 GiB memory\n",
      " 0.00/26.996 GiB object_store_memory\n",
      "\n",
      "Demands:\n",
      " {'CPU': 1}: 4+ from request_resources()\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray status --address='raycluster-autoscaler-head-svc.dev.svc.cluster.local:6379'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976f058e-3f0e-40df-870e-9fd602f19175",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = kaggle_dataset_helper.get_transaction_predictions_dataset()\n",
    "ds_train = common.label_encode(ds_train)\n",
    "ds_test = common.label_encode(ds_test)\n",
    "\n",
    "ds_train = ds_train.fillna(-1)\n",
    "ds_test = ds_test.fillna(-1)\n",
    "\n",
    "df_X = ds_train.loc[:, ds_train.columns != 'target']\n",
    "df_y = ds_train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=config.rand_state)\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scalar = pd.DataFrame(ss.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test_scalar = pd.DataFrame(ss.fit_transform(X_test), columns = X_test.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d06d54bd-f787-4c53-9f8c-4f4503f89418",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = helper.get_covid_dataset()\n",
    "X = X.drop(['location'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scalar = pd.DataFrame(ss.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test_scalar = pd.DataFrame(ss.fit_transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8816b303-3282-4b3a-886d-92ac565c4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.values.reshape(y_train.shape[0], -1)\n",
    "# y_test = y_test.values.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28951ff1-692a-48a4-b57a-981db4d006b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_id = ray.put(X_train_scalar)\n",
    "y_train_id = ray.put(y_train)\n",
    "X_test_id = ray.put(X_test_scalar)\n",
    "y_test_id = ray.put(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "960a7695-1450-437f-8b7e-608c556950ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@ray.remote(num_returns=1)\n",
    "def worker(base_model, X_train, X_test, y_train, y_test):\n",
    "    base_model.fetch_model(X_train, X_test, y_train, y_test)\n",
    "    return base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4e553ad-7ab9-48f8-8972-f10186f5b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __objective_xgb__(params, X_train_ref, X_test_ref, y_train_ref, y_test_ref, pred_class):\n",
    "\n",
    "    # criterion = “gini” [“gini”, “entropy”, “log_loss”]\n",
    "\n",
    "    X_train = ray.get(X_train_ref)\n",
    "    X_test = ray.get(X_test_ref)\n",
    "    y_train = ray.get(y_train_ref)\n",
    "    y_test = ray.get(y_test_ref)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    model = xgb.train(params, dtrain, num_boost_round = 10, verbose_eval = 1)\n",
    "\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    err_test = score_func(y_test, pred_test)\n",
    "    err_train = score_func(y_train, pred_train)\n",
    "        \n",
    "    #metirc_score_train, metirc_score_test, weighted_score = self.__get_model_score__(pred_train, pred_test, y_train, y_test, self.score_func)\n",
    "    weighted_score = common.get_weighted_score(err_train, err_test, pred_class, score_func)\n",
    "\n",
    "    tune.report(weighted_score=weighted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e424b948-3544-4dcf-ad18-6c6974f6c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __objective__(params, X_train_ref, X_test_ref, y_train_ref, y_test_ref, pred_class):\n",
    "\n",
    "    # criterion = “gini” [“gini”, “entropy”, “log_loss”]\n",
    "\n",
    "    X_train = ray.get(X_train_ref)\n",
    "    X_test = ray.get(X_test_ref)\n",
    "    y_train = ray.get(y_train_ref)\n",
    "    y_test = ray.get(y_test_ref)\n",
    "\n",
    "    print(X_train.head())\n",
    "    n_estimators = int(params['n_estimators'])\n",
    "\n",
    "    if pred_class == 'regression':\n",
    "        # cv = KFold(n_splits=self.cv_splits, shuffle=True, random_state=config.rand_state)\n",
    "        score_func = mean_squared_error\n",
    "        model = BaggingRegressor(n_estimators=n_estimators)\n",
    "\n",
    "    else:\n",
    "        # cv = StratifiedKFold(n_splits=self.cv_splits, shuffle=True, random_state=config.rand_state)\n",
    "        score_func = f1_score\n",
    "        model =  BaggingClassifier(n_estimators=n_estimators)\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    err_test = score_func(y_test, pred_test)\n",
    "    err_train = score_func(y_train, pred_train)\n",
    "        \n",
    "    #metirc_score_train, metirc_score_test, weighted_score = self.__get_model_score__(pred_train, pred_test, y_train, y_test, self.score_func)\n",
    "    weighted_score = common.get_weighted_score(err_train, err_test, pred_class, score_func)\n",
    "\n",
    "    tune.report(weighted_score=weighted_score)\n",
    "\n",
    "    return weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e46458-f0c8-474c-b479-64826a389c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m 2022-11-24 10:57:05,439\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:12 (running for 00:00:05.11)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:17 (running for 00:00:10.12)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:22 (running for 00:00:15.12)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:27 (running for 00:00:20.12)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:32 (running for 00:00:25.12)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:37 (running for 00:00:30.13)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:42 (running for 00:00:35.13)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.4/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 PENDING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc   |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+-------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | PENDING  |       |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+-------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m 2022-11-24 10:57:43,579\tINFO bayesopt_search.py:285 -- Skipping duplicated config: {'n_estimators': 10.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m     ID_code     var_0     var_1  ...   var_197   var_198   var_199\n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m 0  1.618663  0.069886 -0.069362  ...  1.171622 -1.032898 -1.519634\n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m 1 -0.840236 -0.546904 -1.815322  ...  1.426842 -0.007856  1.407947\n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m 2 -1.674995  2.238896 -1.192382  ... -1.543569  0.199438 -0.591753\n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m 3  1.176809 -1.535047 -0.672862  ... -0.889209 -0.267786 -1.491646\n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m 4  1.360586  0.844579  0.246573  ... -1.017957 -0.025623  1.408816\n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m \n",
      "\u001b[2m\u001b[36m(<lambda> pid=164, ip=10.10.89.158)\u001b[0m [5 rows x 201 columns]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:48 (running for 00:00:41.25)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.6/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m 2022-11-24 10:57:48,584\tINFO bayesopt_search.py:285 -- Skipping duplicated config: {'n_estimators': 10.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:53 (running for 00:00:46.26)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m 2022-11-24 10:57:53,587\tINFO bayesopt_search.py:285 -- Skipping duplicated config: {'n_estimators': 10.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:57:58 (running for 00:00:51.26)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m 2022-11-24 10:57:58,593\tINFO bayesopt_search.py:285 -- Skipping duplicated config: {'n_estimators': 10.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:03 (running for 00:00:56.27)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:08 (running for 00:01:01.27)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:13 (running for 00:01:06.27)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:18 (running for 00:01:11.27)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:23 (running for 00:01:16.28)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:28 (running for 00:01:21.28)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:33 (running for 00:01:26.28)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:38 (running for 00:01:31.29)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:43 (running for 00:01:36.29)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:48 (running for 00:01:41.29)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:53 (running for 00:01:46.30)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:58:58 (running for 00:01:51.30)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:03 (running for 00:01:56.30)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:08 (running for 00:02:01.30)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:13 (running for 00:02:06.31)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:18 (running for 00:02:11.31)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:23 (running for 00:02:16.31)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/15 CPUs, 0/0 GPUs, 0.0/54.02 GiB heap, 0.0/15.95 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:28 (running for 00:02:21.31)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/15 CPUs, 0/0 GPUs, 0.0/54.02 GiB heap, 0.0/15.95 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:33 (running for 00:02:26.32)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:38 (running for 00:02:31.32)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:43 (running for 00:02:36.32)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:48 (running for 00:02:41.32)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:53 (running for 00:02:46.33)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 10:59:58 (running for 00:02:51.33)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:03 (running for 00:02:56.34)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:08 (running for 00:03:01.34)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:13 (running for 00:03:06.34)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:18 (running for 00:03:11.34)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:23 (running for 00:03:16.35)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:28 (running for 00:03:21.35)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:33 (running for 00:03:26.35)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:38 (running for 00:03:31.35)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:43 (running for 00:03:36.36)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/15 CPUs, 0/0 GPUs, 0.0/54.02 GiB heap, 0.0/15.95 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:48 (running for 00:03:41.36)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/15 CPUs, 0/0 GPUs, 0.0/54.02 GiB heap, 0.0/15.95 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:53 (running for 00:03:46.36)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:00:58 (running for 00:03:51.36)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:03 (running for 00:03:56.37)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:08 (running for 00:04:01.37)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.4/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:13 (running for 00:04:06.37)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:18 (running for 00:04:11.37)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:23 (running for 00:04:16.38)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:28 (running for 00:04:21.38)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:33 (running for 00:04:26.39)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:38 (running for 00:04:31.39)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:43 (running for 00:04:36.39)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:48 (running for 00:04:41.39)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:53 (running for 00:04:46.40)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:01:58 (running for 00:04:51.40)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.9/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:03 (running for 00:04:56.41)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:08 (running for 00:05:01.41)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:13 (running for 00:05:06.41)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:18 (running for 00:05:11.41)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.6/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:23 (running for 00:05:16.42)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:28 (running for 00:05:21.42)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:33 (running for 00:05:26.42)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:38 (running for 00:05:31.42)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:43 (running for 00:05:36.43)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:48 (running for 00:05:41.43)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.5/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/17 CPUs, 0/0 GPUs, 0.0/61.47 GiB heap, 0.0/18.16 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:53 (running for 00:05:46.43)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:02:58 (running for 00:05:51.44)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:03 (running for 00:05:56.44)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:08 (running for 00:06:01.44)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:13 (running for 00:06:06.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:18 (running for 00:06:11.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:23 (running for 00:06:16.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:28 (running for 00:06:21.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:33 (running for 00:06:26.46)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:38 (running for 00:06:31.46)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:43 (running for 00:06:36.46)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:48 (running for 00:06:41.47)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:53 (running for 00:06:46.47)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:03:58 (running for 00:06:51.47)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.6/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 1.0/21 CPUs, 0/0 GPUs, 0.0/76.37 GiB heap, 0.0/22.58 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status   | loc              |   n_estimators |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+----------+------------------+----------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | RUNNING  | 10.10.89.158:164 |             10 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+----------+------------------+----------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result for lambda_cafb410a:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   date: 2022-11-24_11-04-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   experiment_id: b84906b3047f407ebb6e0636c5909ac8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   hostname: raycluster-autoscaler-worker-small-group-gsk7l\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   node_ip: 10.10.89.158\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   pid: 164\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   time_since_restore: 375.8033149242401\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   time_this_iter_s: 375.8033149242401\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   time_total_s: 375.8033149242401\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   timestamp: 1669316640\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   trial_id: cafb410a\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   warmup_time: 0.00478053092956543\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   weighted_score: 0.384302714385211\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result for lambda_cafb410a:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   date: 2022-11-24_11-04-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   experiment_id: b84906b3047f407ebb6e0636c5909ac8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   experiment_tag: 1_n_estimators=10.0000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   hostname: raycluster-autoscaler-worker-small-group-gsk7l\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   node_ip: 10.10.89.158\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   pid: 164\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   time_since_restore: 375.8033149242401\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   time_this_iter_s: 375.8033149242401\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   time_total_s: 375.8033149242401\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   timestamp: 1669316640\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   trial_id: cafb410a\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   warmup_time: 0.00478053092956543\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   weighted_score: 0.384302714385211\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:04:05 (running for 00:06:58.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.6/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+------------+------------------+----------------+--------+------------------+------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status     | loc              |   n_estimators |   iter |   total time (s) |   weighted_score |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+------------+------------------+----------------+--------+------------------+------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | TERMINATED | 10.10.89.158:164 |             10 |      1 |          375.803 |         0.384303 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+------------+------------------+----------------+--------+------------------+------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Current time: 2022-11-24 11:04:05 (running for 00:06:58.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Memory usage on this node: 2.6/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Resources requested: 0/19 CPUs, 0/0 GPUs, 0.0/68.92 GiB heap, 0.0/20.37 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Result logdir: /home/ray/ray_results/lambda_2022-11-24_10-57-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m Number of trials: 1/10 (1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+------------+------------------+----------------+--------+------------------+------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | Trial name      | status     | loc              |   n_estimators |   iter |   total time (s) |   weighted_score |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m |-----------------+------------+------------------+----------------+--------+------------------+------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m | lambda_cafb410a | TERMINATED | 10.10.89.158:164 |             10 |      1 |          375.803 |         0.384303 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m +-----------------+------------+------------------+----------------+--------+------------------+------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m \n",
      "############################\n",
      "Best hyperparameters:  Result(metrics={'weighted_score': 0.384302714385211, 'done': True, 'trial_id': 'cafb410a', 'experiment_tag': '1_n_estimators=10.0000'}, error=None, log_dir=PosixPath('/home/ray/ray_results/lambda_2022-11-24_10-57-05/lambda_cafb410a_1_n_estimators=10.0000_2022-11-24_10-57-43'))\n",
      "Best hyperparameters:  {'n_estimators': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=344)\u001b[0m 2022-11-24 11:04:05,927\tINFO tune.py:777 -- Total run time: 420.49 seconds (418.45 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m [2022-11-24 11:33:06,612 C 18 65] (raylet) node_manager.cc:173: This node has beem marked as dead.\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x49beda) [0x56097e180eda] ray::operator<<()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x49d9b2) [0x56097e1829b2] ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x49dcc7) [0x56097e182cc7] ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x241d74) [0x56097df26d74] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x375bd4) [0x56097e05abd4] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x3cabe0) [0x56097e0afbe0] ray::rpc::GcsRpcClient::ReportHeartbeat()::{lambda()#2}::operator()()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x373a42) [0x56097e058a42] ray::rpc::ClientCallImpl<>::OnReplyReceived()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x228285) [0x56097df0d285] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x47fcf6) [0x56097e164cf6] EventTracker::RecordExecution()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x42031e) [0x56097e10531e] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x420796) [0x56097e105796] boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x9adbcb) [0x56097e692bcb] boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x9af391) [0x56097e694391] boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x9af5c0) [0x56097e6945c0] boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet(+0x9fe2d0) [0x56097e6e32d0] execute_native_thread_routine\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7f8feca4d609] start_thread\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m /lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7f8fec61c133] __clone\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.10.84.51)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "n_estimators = 10\n",
    "n_trials = 10\n",
    "\n",
    "baye_space = {\n",
    "    # 'base_estimator': DecisionTreeRegressor\n",
    "    'n_estimators': (10, n_estimators),\n",
    "}\n",
    "\n",
    "xgb_space = {\n",
    "        \"objective\": 'count:poisson',\n",
    "        \"booster\": ([\"gbtree\", \"dart\"]),\n",
    "#        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 1.0, log=True),\n",
    "#        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "obj_func = lambda params: __objective__(params, X_train_id, X_test_id, y_train_id, y_test_id, 'regression')\n",
    "\n",
    "# algo = OptunaSearch(space=params, metric=\"mean_loss\", mode=\"min\")\n",
    "bayesopt = BayesOptSearch(space=baye_space, metric=\"weighted_score\", mode=\"min\",  random_state=config.rand_state)\n",
    "# algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    obj_func,\n",
    "    run_config=air.RunConfig(\n",
    "      name=config.create_study_name(),\n",
    "      #stop={\"training_iteration\": 1 if args.smoke_test else 10},\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=bayesopt,\n",
    "        num_samples=n_trials,\n",
    "        #checkpoint_dir=None,\n",
    "    ),\n",
    "#            param_space=params,\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "best_result = results.get_best_result()\n",
    "\n",
    "print('############################')\n",
    "print(\"Best hyperparameters: \", best_result)\n",
    "print(\"Best hyperparameters: \", best_result.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd0179e1-ba58-4d43-9b82-ec3effa3aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-24 12:36:35</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:16.21        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.0/15.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/7.15 GiB heap, 0.0/3.57 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 10<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name     </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_e2d4d7ee</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e2d4d7ee_1_lambda=0.5493_2022-11-24_12-36-18/error.txt </td></tr>\n",
       "<tr><td>lambda_e42bd41c</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e42bd41c_2_lambda=0.7155_2022-11-24_12-36-21/error.txt </td></tr>\n",
       "<tr><td>lambda_e432e428</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e432e428_3_lambda=0.6032_2022-11-24_12-36-21/error.txt </td></tr>\n",
       "<tr><td>lambda_e43a1db0</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e43a1db0_4_lambda=0.5453_2022-11-24_12-36-21/error.txt </td></tr>\n",
       "<tr><td>lambda_e4419180</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e4419180_5_lambda=0.4242_2022-11-24_12-36-22/error.txt </td></tr>\n",
       "<tr><td>lambda_e4d4e502</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e4d4e502_6_lambda=0.6462_2022-11-24_12-36-26/error.txt </td></tr>\n",
       "<tr><td>lambda_e7a7dec4</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e7a7dec4_7_lambda=0.4381_2022-11-24_12-36-26/error.txt </td></tr>\n",
       "<tr><td>lambda_e7af0712</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e7af0712_8_lambda=0.8919_2022-11-24_12-36-26/error.txt </td></tr>\n",
       "<tr><td>lambda_e7b63fe6</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e7b63fe6_9_lambda=0.9637_2022-11-24_12-36-27/error.txt </td></tr>\n",
       "<tr><td>lambda_e7bdc09a</td><td style=\"text-align: right;\">           1</td><td>/home/wasif/ray_results/lambda_2022-11-24_12-36-18/lambda_e7bdc09a_10_lambda=0.3841_2022-11-24_12-36-32/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  lambda</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_e2d4d7ee</td><td>ERROR   </td><td>10.10.100.184:25353</td><td style=\"text-align: right;\">0.549265</td></tr>\n",
       "<tr><td>lambda_e42bd41c</td><td>ERROR   </td><td>10.10.100.184:25381</td><td style=\"text-align: right;\">0.715474</td></tr>\n",
       "<tr><td>lambda_e432e428</td><td>ERROR   </td><td>10.10.100.184:25383</td><td style=\"text-align: right;\">0.603161</td></tr>\n",
       "<tr><td>lambda_e43a1db0</td><td>ERROR   </td><td>10.10.100.184:25385</td><td style=\"text-align: right;\">0.545338</td></tr>\n",
       "<tr><td>lambda_e4419180</td><td>ERROR   </td><td>10.10.100.184:25396</td><td style=\"text-align: right;\">0.424231</td></tr>\n",
       "<tr><td>lambda_e4d4e502</td><td>ERROR   </td><td>10.10.100.184:25529</td><td style=\"text-align: right;\">0.646248</td></tr>\n",
       "<tr><td>lambda_e7a7dec4</td><td>ERROR   </td><td>10.10.100.184:25531</td><td style=\"text-align: right;\">0.43815 </td></tr>\n",
       "<tr><td>lambda_e7af0712</td><td>ERROR   </td><td>10.10.100.184:25535</td><td style=\"text-align: right;\">0.891881</td></tr>\n",
       "<tr><td>lambda_e7b63fe6</td><td>ERROR   </td><td>10.10.100.184:25537</td><td style=\"text-align: right;\">0.963699</td></tr>\n",
       "<tr><td>lambda_e7bdc09a</td><td>ERROR   </td><td>10.10.100.184:25678</td><td style=\"text-align: right;\">0.384058</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 12:36:21,302\tERROR trial_runner.py:993 -- Trial lambda_e2d4d7ee: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25353, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name     </th><th>date               </th><th>experiment_id                   </th><th>hostname     </th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_e2d4d7ee</td><td>2022-11-24_12-36-21</td><td>0cd72475d6574d8192088d5d66bdb59d</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25353</td><td style=\"text-align: right;\"> 1669314981</td><td>e2d4d7ee  </td></tr>\n",
       "<tr><td>lambda_e42bd41c</td><td>2022-11-24_12-36-24</td><td>346218f28c3a4a9ab0c4e1b6f9fecdd1</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25381</td><td style=\"text-align: right;\"> 1669314984</td><td>e42bd41c  </td></tr>\n",
       "<tr><td>lambda_e432e428</td><td>2022-11-24_12-36-24</td><td>36e672763b7747be8653ba13188fbce7</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25383</td><td style=\"text-align: right;\"> 1669314984</td><td>e432e428  </td></tr>\n",
       "<tr><td>lambda_e43a1db0</td><td>2022-11-24_12-36-24</td><td>834b488085b04058acc9b80f32689386</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25385</td><td style=\"text-align: right;\"> 1669314984</td><td>e43a1db0  </td></tr>\n",
       "<tr><td>lambda_e4419180</td><td>2022-11-24_12-36-24</td><td>9d7d1a58609f4b458a32611c656b5540</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25396</td><td style=\"text-align: right;\"> 1669314984</td><td>e4419180  </td></tr>\n",
       "<tr><td>lambda_e4d4e502</td><td>2022-11-24_12-36-30</td><td>9489826951944ff49e10fd829137442b</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25529</td><td style=\"text-align: right;\"> 1669314990</td><td>e4d4e502  </td></tr>\n",
       "<tr><td>lambda_e7a7dec4</td><td>2022-11-24_12-36-30</td><td>36886f1488a34d22b1905396d7aadf08</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25531</td><td style=\"text-align: right;\"> 1669314990</td><td>e7a7dec4  </td></tr>\n",
       "<tr><td>lambda_e7af0712</td><td>2022-11-24_12-36-30</td><td>c466d8c6561d4fec9eaf2093a8f8600f</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25535</td><td style=\"text-align: right;\"> 1669314990</td><td>e7af0712  </td></tr>\n",
       "<tr><td>lambda_e7b63fe6</td><td>2022-11-24_12-36-30</td><td>48c50e3321e3468482365ff6c3acd1c5</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25537</td><td style=\"text-align: right;\"> 1669314990</td><td>e7b63fe6  </td></tr>\n",
       "<tr><td>lambda_e7bdc09a</td><td>2022-11-24_12-36-34</td><td>35edf671c24947a1a2336c6a408a2d0a</td><td>jupyter-wasif</td><td>10.10.100.184</td><td style=\"text-align: right;\">25678</td><td style=\"text-align: right;\"> 1669314994</td><td>e7bdc09a  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 12:36:24,213\tERROR trial_runner.py:993 -- Trial lambda_e42bd41c: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25381, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:24,850\tERROR trial_runner.py:993 -- Trial lambda_e432e428: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25383, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:24,876\tERROR trial_runner.py:993 -- Trial lambda_e43a1db0: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25385, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:25,051\tERROR trial_runner.py:993 -- Trial lambda_e4419180: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25396, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:30,713\tERROR trial_runner.py:993 -- Trial lambda_e7af0712: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25535, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:30,797\tERROR trial_runner.py:993 -- Trial lambda_e4d4e502: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25529, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:30,824\tERROR trial_runner.py:993 -- Trial lambda_e7b63fe6: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25537, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:30,855\tERROR trial_runner.py:993 -- Trial lambda_e7a7dec4: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25531, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:34,992\tERROR trial_runner.py:993 -- Trial lambda_e7bdc09a: Error processing event.\n",
      "ray.exceptions.RayTaskError(NameError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25678, ip=10.10.100.184, repr=<lambda>)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_23266/969626250.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_23266/2380396921.py\", line 13, in __objective_xgb__\n",
      "NameError: name 'param' is not defined\n",
      "2022-11-24 12:36:35,168\tERROR tune.py:773 -- Trials did not complete: [lambda_e2d4d7ee, lambda_e42bd41c, lambda_e432e428, lambda_e43a1db0, lambda_e4419180, lambda_e4d4e502, lambda_e7a7dec4, lambda_e7af0712, lambda_e7b63fe6, lambda_e7bdc09a]\n",
      "2022-11-24 12:36:35,168\tINFO tune.py:777 -- Total run time: 16.33 seconds (16.17 seconds for the tuning loop).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No metric is provided. Either pass in a `metric` arg to `get_best_result` or specify a metric in the `TuneConfig` of your `Tuner`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [63], line 30\u001b[0m\n\u001b[1;32m     15\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[1;32m     16\u001b[0m     obj_func,\n\u001b[1;32m     17\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mair\u001b[38;5;241m.\u001b[39mRunConfig(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#            param_space=params,\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m---> 30\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m############################\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, best_result)\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/tune/result_grid.py:120\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mtrials[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo metric is provided. Either pass in a `metric` arg to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`get_best_result` or specify a metric in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`TuneConfig` of your `Tuner`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_mode:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo mode is provided. Either pass in a `mode` arg to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`get_best_result` or specify a mode in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`TuneConfig` of your `Tuner`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No metric is provided. Either pass in a `metric` arg to `get_best_result` or specify a metric in the `TuneConfig` of your `Tuner`."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb_space = {\n",
    "        # \"objective\": 'count:poisson',\n",
    "        #\"booster\": (\"gbtree\", \"dart\"),\n",
    "        \"lambda\": (1e-3, 1.0),\n",
    "#        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "obj_func = lambda params: __objective_xgb__(params, X_train_id, X_test_id, y_train_id, y_test_id, 'regression')\n",
    "\n",
    "# algo = OptunaSearch(space=params, metric=\"mean_loss\", mode=\"min\")\n",
    "bayesopt = BayesOptSearch(space=xgb_space, metric=\"weighted_score\", mode=\"min\",  random_state=config.rand_state)\n",
    "# algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    obj_func,\n",
    "    run_config=air.RunConfig(\n",
    "      name=config.create_study_name(),\n",
    "      #stop={\"training_iteration\": 1 if args.smoke_test else 10},\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=bayesopt,\n",
    "        num_samples=n_trials,\n",
    "        #checkpoint_dir=None,\n",
    "    ),\n",
    "#            param_space=params,\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "best_result = results.get_best_result()\n",
    "\n",
    "print('############################')\n",
    "print(\"Best hyperparameters: \", best_result)\n",
    "print(\"Best hyperparameters: \", best_result.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd925d43-98d7-47ae-b1d6-381aaeeabb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc402ee3-c45d-42f1-a594-1e77b258754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m 2022-11-24 07:25:40,942\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Current time: 2022-11-24 07:25:46 (running for 00:00:02.08)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Resources requested: 1.0/5 CPUs, 0/0 GPUs, 0.0/16.76 GiB heap, 0.0/4.91 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result logdir: /home/ray/ray_results/objective_2022-11-24_07-25-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Number of trials: 4/4 (3 PENDING, 1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m +-----------------------+----------+-----------------+-------+-----+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | Trial name            | status   | loc             |     a |   b |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m |-----------------------+----------+-----------------+-------+-----|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00000 | RUNNING  | 10.10.20.33:398 | 0.001 |   2 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00001 | PENDING  |                 | 0.01  |   3 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00002 | PENDING  |                 | 0.1   |   1 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00003 | PENDING  |                 | 1     |   3 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m +-----------------------+----------+-----------------+-------+-----+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 2.000001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 0.0001266002655029297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 0.0001266002655029297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 0.0001266002655029297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_tag: 0_a=0.0010,b=2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 2.000001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 0.0001266002655029297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 0.0001266002655029297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 0.0001266002655029297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 3.0001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 9.083747863769531e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 9.083747863769531e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 9.083747863769531e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_tag: 1_a=0.0100,b=3\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 3.0001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 9.083747863769531e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 9.083747863769531e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 9.083747863769531e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 1.01\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 7.295608520507812e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 7.295608520507812e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 7.295608520507812e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_tag: 2_a=0.1000,b=1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 1.01\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 7.295608520507812e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 7.295608520507812e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 7.295608520507812e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 4.0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 0.00011372566223144531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 0.00011372566223144531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 0.00011372566223144531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result for objective_414eb_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   date: 2022-11-24_07-25-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_id: 2a92ed4aaf8a4ba38e5648576c78640e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   experiment_tag: 3_a=1.0000,b=3\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   hostname: raycluster-autoscaler-head-zkhfp\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   node_ip: 10.10.20.33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   pid: 398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   score: 4.0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_since_restore: 0.00011372566223144531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_this_iter_s: 0.00011372566223144531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   time_total_s: 0.00011372566223144531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timestamp: 1669303546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   trial_id: 414eb_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   warmup_time: 0.020821571350097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Current time: 2022-11-24 07:25:46 (running for 00:00:02.24)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Memory usage on this node: 2.7/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Resources requested: 0/5 CPUs, 0/0 GPUs, 0.0/16.76 GiB heap, 0.0/4.91 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Result logdir: /home/ray/ray_results/objective_2022-11-24_07-25-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m Number of trials: 4/4 (4 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m +-----------------------+------------+-----------------+-------+-----+--------+------------------+---------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | Trial name            | status     | loc             |     a |   b |   iter |   total time (s) |   score |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m |-----------------------+------------+-----------------+-------+-----+--------+------------------+---------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00000 | TERMINATED | 10.10.20.33:398 | 0.001 |   2 |      1 |      0.0001266   |  2      |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00001 | TERMINATED | 10.10.20.33:398 | 0.01  |   3 |      1 |      9.08375e-05 |  3.0001 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00002 | TERMINATED | 10.10.20.33:398 | 0.1   |   1 |      1 |      7.29561e-05 |  1.01   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m | objective_414eb_00003 | TERMINATED | 10.10.20.33:398 | 1     |   3 |      1 |      0.000113726 |  4      |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m +-----------------------+------------+-----------------+-------+-----+--------+------------------+---------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m \n",
      "{'a': 0.1, 'b': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=363)\u001b[0m 2022-11-24 07:25:46,471\tINFO tune.py:777 -- Total run time: 5.53 seconds (2.23 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m /tmp/ray/session_2022-11-24_07-21-18_572881_8/runtime_resources/working_dir_files/_ray_pkg_e69997be12e85035/ml/models/base/OptunaRay/brisk_bagging.py:17: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m   from ray.tune.suggest.optuna import OptunaSearch\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m 2022-11-24T07:25:52PST : INFO : font_manager : _load_fontmanager : 1633 : Message : generated new fontManager\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m /tmp/ray/session_2022-11-24_07-21-18_572881_8/runtime_resources/working_dir_files/_ray_pkg_e69997be12e85035/ml/models/base/OptunaRay/brisk_bagging.py:17: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m   from ray.tune.suggest.optuna import OptunaSearch\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m 2022-11-24T07:25:52PST : INFO : brisk_bagging : __discover_model__ : 86 : Message : brisk_xgb2: Starting training for trials:300, n_estimators  100\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m 2022-11-24 07:25:52,632\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "\u001b[2m\u001b[36m(worker pid=138, ip=10.10.63.163)\u001b[0m \u001b[32m[I 2022-11-24 07:25:52,635]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "# 1. Define an objective function.\n",
    "def objective(config):\n",
    "    score = config[\"a\"] ** 2 + config[\"b\"]\n",
    "    return {\"score\": score}\n",
    "\n",
    "\n",
    "# 2. Define a search space.\n",
    "search_space = {\n",
    "    \"a\": tune.grid_search([0.001, 0.01, 0.1, 1.0]),\n",
    "    \"b\": tune.choice([1, 2, 3]),\n",
    "}\n",
    "\n",
    "# 3. Start a Tune run and print the best result.\n",
    "tuner = tune.Tuner(objective, param_space=search_space)\n",
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"score\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aeb6c92-f9bf-4bf4-965f-6ddd9f2826c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m 2022-11-24 07:27:52,092\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Current time: 2022-11-24 07:27:54 (running for 00:00:01.37)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Resources requested: 1.0/5 CPUs, 0/0 GPUs, 0.0/16.76 GiB heap, 0.0/4.91 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Result logdir: /home/ray/ray_results/objective_2022-11-24_07-27-52\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m +--------------------+----------+------------------+----------+---------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m | Trial name         | status   | loc              |   height |   width |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m |--------------------+----------+------------------+----------+---------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m | objective_901d919a | RUNNING  | 10.10.63.163:198 |  -25.092 | 19.0143 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m +--------------------+----------+------------------+----------+---------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Result for objective_901d919a:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   date: 2022-11-24_07-27-54\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   experiment_id: 1270e4eb0c0b4074a1e26ccf0fa93f81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   hostname: raycluster-autoscaler-worker-small-group-dsm5q\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   node_ip: 10.10.63.163\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   pid: 198\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   timestamp: 1669303674\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   trial_id: 901d919a\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Current time: 2022-11-24 07:27:54 (running for 00:00:01.38)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Memory usage on this node: 2.8/15.4 GiB \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Resources requested: 0/5 CPUs, 0/0 GPUs, 0.0/16.76 GiB heap, 0.0/4.91 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Result logdir: /home/ray/ray_results/objective_2022-11-24_07-27-52\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Number of trials: 1/1 (1 ERROR)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m +--------------------+----------+------------------+----------+---------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m | Trial name         | status   | loc              |   height |   width |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m |--------------------+----------+------------------+----------+---------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m | objective_901d919a | ERROR    | 10.10.63.163:198 |  -25.092 | 19.0143 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m +--------------------+----------+------------------+----------+---------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m Number of errored trials: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m +--------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m | Trial name         |   # failures | error file                                                                                                                           |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m |--------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m | objective_901d919a |            1 | /home/ray/ray_results/objective_2022-11-24_07-27-52/objective_901d919a_1_height=-25.0920,width=19.0143_2022-11-24_07-27-53/error.txt |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m +--------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m 2022-11-24 07:27:54,535\tERROR trial_runner.py:993 -- Trial objective_901d919a: Error processing event.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=198, ip=10.10.63.163, repr=objective)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m     raise skipped from exception_cause(skipped)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m   File \"/tmp/ipykernel_20344/2397527074.py\", line 5, in objective\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m KeyError: 'a'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x7fbdc0e57c40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m 2022-11-24 07:27:54,643\tERROR tune.py:773 -- Trials did not complete: [objective_901d919a]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=482)\u001b[0m 2022-11-24 07:27:54,643\tINFO tune.py:777 -- Total run time: 2.55 seconds (1.38 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "\n",
    "space = {\n",
    "    'width': (0, 20),\n",
    "    'height': (-100, 100),\n",
    "}\n",
    "bayesopt = BayesOptSearch(space, metric=\"mean_loss\", mode=\"min\")\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=bayesopt,\n",
    "    ),\n",
    ")\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf87a98-8874-40b3-9a5c-6fba6365bb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
