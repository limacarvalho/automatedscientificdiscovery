{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '../..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "from utils import helper, config, rayer, kaggle_dataset_helper\n",
    "from ml.models.base.brisk_xgboost import BriskXGBoost\n",
    "from ml.models.base.slug_xgboost import SlugXGBoost\n",
    "from ml.models.base.slug_ann import SlugANN\n",
    "from ml.models.base.slug_rf import SlugRF\n",
    "from ml.models.base.slug_knn import SlugKNN\n",
    "from ml.models.base.brisk_bagging import BriskBagging\n",
    "\n",
    "\n",
    "from ml.models import common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rayer.get_global_cluster(num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(scheduler +2s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[36m(scheduler +2s)\u001b[0m Adding 1 node(s) of type small-group.\n",
      "======== Autoscaler status: 2022-11-16 07:23:49.752126 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Healthy:\n",
      " 1 head-group\n",
      " 1 small-group\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Usage:\n",
      " 0.0/3.0 CPU\n",
      " 0.00/9.313 GiB memory\n",
      " 0.00/2.697 GiB object_store_memory\n",
      "\n",
      "Demands:\n",
      " {}: 1+ pending tasks/actors\n",
      " {'CPU': 1}: 4+ from request_resources()\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray status --address='raycluster-autoscaler-head-svc.dev.svc.cluster.local:6379'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@ray.remote\n",
    "def worker(base_model):     \n",
    "    base_model.fetch_model()\n",
    "    return base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(scheduler +8s)\u001b[0m Resized to 5 CPUs.\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_test = kaggle_dataset_helper.get_house_prices_dataset()\n",
    "ds_train = common.label_encode(ds_train)\n",
    "ds_test = common.label_encode(ds_test)\n",
    "\n",
    "ds_train = ds_train.fillna(-1)\n",
    "ds_test = ds_test.fillna(-1)\n",
    "\n",
    "\n",
    "df_X = ds_train.loc[:, ds_train.columns != 'SalePrice']\n",
    "df_y = ds_train['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=config.rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "brisk_xgb1 = BriskXGBoost('brisk_xgb1', X_train, X_test, y_train, y_test)\n",
    "brisk_xgb1.boosted_round = 10\n",
    "brisk_xgb1.n_trials = 10\n",
    "\n",
    "brisk_xgb2 = BriskXGBoost('brisk_xgb2', X_train, X_test, y_train, y_test)\n",
    "brisk_xgb2.boosted_round = 10\n",
    "brisk_xgb2.n_trials = 10\n",
    "\n",
    "base_models = [brisk_xgb1, brisk_xgb2]\n",
    "\n",
    "slug_xgb1 = SlugXGBoost('slug_xgb1', X_train, X_test, y_train, y_test)\n",
    "slug_xgb1.boosted_round = 10\n",
    "slug_xgb1.n_trials = 10\n",
    "\n",
    "slug_xgb2 = SlugXGBoost('slug_xgb2', X_train, X_test, y_train, y_test)\n",
    "slug_xgb2.boosted_round = 10\n",
    "slug_xgb2.n_trials = 10\n",
    "\n",
    "base_models_slug = [slug_xgb1, slug_xgb2]\n",
    "\n",
    "slug_ann_1 = SlugANN('slug_ann_1', X_train, X_test, y_train, y_test)\n",
    "slug_ann_1.epochs = 50\n",
    "slug_ann_1.n_trials = 50\n",
    "\n",
    "slug_ann_2 = SlugANN('slug_ann_2', X_train, X_test, y_train, y_test)\n",
    "slug_ann_2.epochs = 50\n",
    "slug_ann_2.n_trials = 50\n",
    "\n",
    "base_models_ann = [slug_ann_1, slug_ann_2]\n",
    "\n",
    "\n",
    "slug_rf_1 = SlugRF('slug_rf_1', X_train, X_test, y_train, y_test)\n",
    "slug_rf_1.max_n_estimators = 150\n",
    "slug_rf_1.n_trials = 50\n",
    "\n",
    "slug_rf_2 = SlugRF('slug_rf_2', X_train, X_test, y_train, y_test)\n",
    "slug_rf_2.max_n_estimators = 100\n",
    "slug_rf_2.n_trials = 50\n",
    "\n",
    "base_models_rf = [slug_rf_1, slug_rf_2]\n",
    "\n",
    "\n",
    "slug_knn_1 = SlugKNN('slug_knn_1', X_train, X_test, y_train, y_test)\n",
    "slug_knn_1.n_neighbors = 50\n",
    "slug_knn_1.n_trials = 1000\n",
    "\n",
    "slug_knn_2 = SlugKNN('slug_knn_2', X_train, X_test, y_train, y_test)\n",
    "slug_knn_2.n_neighbors = 40\n",
    "slug_knn_2.n_trials = 1000\n",
    "\n",
    "base_models_knn = [slug_knn_1, slug_knn_2]\n",
    "\n",
    "\n",
    "bagging_1 = BriskBagging('bagging_1', X_train, X_test, y_train, y_test)\n",
    "bagging_1.n_estimators = 50\n",
    "bagging_1.n_trials = 100\n",
    "\n",
    "bagging_2 = BriskBagging('bagging_2', X_train, X_test, y_train, y_test)\n",
    "bagging_2.n_estimators = 40\n",
    "bagging_2.n_trials = 200\n",
    "\n",
    "base_models_bagging = [bagging_1, bagging_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:10PST : INFO : slug_knn : __discover_model__ : 94 : Message : slug_knn_2: Starting training for trials:1000, neighbors  40\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:45:10PST : INFO : slug_knn : __discover_model__ : 94 : Message : slug_knn_1: Starting training for trials:1000, neighbors  50\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m The default storage cannot be shared by multiple processes. Please use an RDB (RDBStorage) when you use joblib for multi-processing. The usage of RDBStorage can be found in https://optuna.readthedocs.io/en/stable/tutorial/rdb.html.\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 111 : Message : slug_knn_2: Number of trials: 1000\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 113 : Message : Best trial:22\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 115 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 117 : Message :     n_neighbors 35\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 117 : Message :     weights uniform\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 117 : Message :     algorithm auto\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 131 : Message :   test r2 score: 0.5730445525998091\n",
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m 2022-11-16T06:45:38PST : INFO : slug_knn : __discover_model__ : 136 : Message : slug_knn_2: Model saved at /tmp/covid_autolearn/slug_knn_2/saved/slug_knn_2_22.pickle\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 111 : Message : slug_knn_1: Number of trials: 1000\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 113 : Message : Best trial:26\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 115 : Message :   Params: \n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 117 : Message :     n_neighbors 43\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 117 : Message :     weights uniform\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 117 : Message :     algorithm kd_tree\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 131 : Message :   test r2 score: 0.5455059174020009\n",
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m 2022-11-16T06:46:23PST : INFO : slug_knn : __discover_model__ : 136 : Message : slug_knn_1: Model saved at /tmp/covid_autolearn/slug_knn_1/saved/slug_knn_1_26.pickle\n"
     ]
    }
   ],
   "source": [
    "model_results = ray.get([worker.remote(base_model) for base_model in base_models_knn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KNeighborsRegressor(algorithm='kd_tree', n_neighbors=43),\n",
       " KNeighborsRegressor(n_neighbors=35)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [model.best_fit for model in model_results]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models[0].attr\n",
    "\n",
    "# import json\n",
    "# js = json.loads(models[0].save_config())\n",
    "# js\n",
    "# js['learner']['gradient_booster']['name']\n",
    "# json.loads(models[0].save_config())['learner']['gradient_booster']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(algorithm=&#x27;kd_tree&#x27;, n_neighbors=43)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(algorithm=&#x27;kd_tree&#x27;, n_neighbors=43)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(algorithm='kd_tree', n_neighbors=43)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "@ray.remote\n",
    "def __get_shapley_ensemble_attr__(model, df_X):\n",
    "    #df_X = ray.get(df_X_id)\n",
    "    print(type(df_X))\n",
    "    \n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer(df_X)\n",
    "    df_shapley_sores = pd.DataFrame(shap_values.values, columns=df_X.columns)\n",
    "    df_shapley_sores_list = df_shapley_sores.abs().mean().values #sort_values(ascending=False).values\n",
    "    return df_shapley_sores_list\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def __get_shapley_kernel_attr__(model, df_X,  n_background):\n",
    "    df_background = df_X.sample(n = n_background)\n",
    "    kernel_explainer = shap.KernelExplainer(model.predict, df_background)\n",
    "    kernel_shap_values = kernel_explainer.shap_values(X=X_train)# , ranked_outputs=True, check_additivity=False)    \n",
    "    df_shapley_sores = pd.DataFrame(kernel_shap_values.values, columns=df_X.columns)\n",
    "    df_shapley_sores_list = df_shapley_sores.abs().mean().values #sort_values(ascending=False).values\n",
    "    return df_shapley_sores_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@ray.remote\n",
    "def __get_shapley_torch_attr__(model, df_X, n_background):\n",
    "    \n",
    "    df_background = df_X.sample(n = n_background)\n",
    "    df_tensor_background = helper.df_to_tensor(df_background)\n",
    "    df_X_tensor = helper.df_to_tensor(df_X)                \n",
    "\n",
    "    explainer_shap = shap.DeepExplainer(model=model, data=df_tensor_background)\n",
    "\n",
    "    shap_values = explainer_shap.explainer.shap_values(X=df_X_tensor, ranked_outputs=True, check_additivity=False)\n",
    "\n",
    "\n",
    "    df_shapley_sores = pd.DataFrame(shap_values, columns=df_X.columns)\n",
    "    df_shapley_sores_list = df_shapley_sores.abs().mean().values #sort_values(ascending=False).values\n",
    "\n",
    "    return df_shapley_sores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(__get_shapley_ensemble_attr__ pid=130, ip=10.10.72.10)\u001b[0m <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(worker pid=130, ip=10.10.72.10)\u001b[0m IPython could not be loaded!\n"
     ]
    },
    {
     "ename": "RayTaskError(AssertionError)",
     "evalue": "\u001b[36mray::__get_shapley_ensemble_attr__()\u001b[39m (pid=130, ip=10.10.72.10)\n  File \"/tmp/ipykernel_356/878023724.py\", line 9, in __get_shapley_ensemble_attr__\n  File \"/tmp/ray/session_2022-11-16_05-22-01_174349_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/shap/explainers/_tree.py\", line 149, in __init__\n    self.model = TreeEnsemble(model, self.data, self.data_missing, model_output)\n  File \"/tmp/ray/session_2022-11-16_05-22-01_174349_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/shap/explainers/_tree.py\", line 824, in __init__\n    xgb_loader = XGBTreeModelLoader(self.original_model)\n  File \"/tmp/ray/session_2022-11-16_05-22-01_174349_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/shap/explainers/_tree.py\", line 1455, in __init__\n    assert self.name_gbm == \"gbtree\", \"Only the 'gbtree' model type is supported, not '%s'!\" % self.name_gbm\nAssertionError: Only the 'gbtree' model type is supported, not 'dart'!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(AssertionError)\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_id \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(X_train)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m__get_shapley_ensemble_attr__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:104\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_mode_should_convert(auto_init\u001b[38;5;241m=\u001b[39mauto_init):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Legacy code\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# we only convert init function if RAY_CLIENT_MODE=1\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m--> 104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/util/client/api.py:42\u001b[0m, in \u001b[0;36m_ClientAPI.get\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, vals, \u001b[38;5;241m*\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124;03m\"\"\"get is the hook stub passed on to replace `ray.get`\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        vals: [Client]ObjectRef or list of these refs to retrieve.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        timeout: Optional timeout in milliseconds\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/util/client/worker.py:434\u001b[0m, in \u001b[0;36mWorker.get\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m     op_timeout \u001b[38;5;241m=\u001b[39m max_blocking_operation_time\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_get\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GetTimeoutError:\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/ray/util/client/worker.py:462\u001b[0m, in \u001b[0;36mWorker._get\u001b[0;34m(self, ref, timeout)\u001b[0m\n\u001b[1;32m    460\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to deserialize \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(chunk\u001b[38;5;241m.\u001b[39merror))\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mtotal_size \u001b[38;5;241m>\u001b[39m OBJECT_TRANSFER_WARNING_SIZE \u001b[38;5;129;01mand\u001b[39;00m log_once(\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_object_transfer_size_warning\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m ):\n\u001b[1;32m    466\u001b[0m     size_gb \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtotal_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m\n",
      "\u001b[0;31mRayTaskError(AssertionError)\u001b[0m: \u001b[36mray::__get_shapley_ensemble_attr__()\u001b[39m (pid=130, ip=10.10.72.10)\n  File \"/tmp/ipykernel_356/878023724.py\", line 9, in __get_shapley_ensemble_attr__\n  File \"/tmp/ray/session_2022-11-16_05-22-01_174349_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/shap/explainers/_tree.py\", line 149, in __init__\n    self.model = TreeEnsemble(model, self.data, self.data_missing, model_output)\n  File \"/tmp/ray/session_2022-11-16_05-22-01_174349_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/shap/explainers/_tree.py\", line 824, in __init__\n    xgb_loader = XGBTreeModelLoader(self.original_model)\n  File \"/tmp/ray/session_2022-11-16_05-22-01_174349_8/runtime_resources/pip/6359c2ba15c7e71f0e73b7159cb8c36699f062e1/virtualenv/lib/python3.9/site-packages/shap/explainers/_tree.py\", line 1455, in __init__\n    assert self.name_gbm == \"gbtree\", \"Only the 'gbtree' model type is supported, not '%s'!\" % self.name_gbm\nAssertionError: Only the 'gbtree' model type is supported, not 'dart'!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(__get_shapley_ensemble_attr__ pid=288)\u001b[0m <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(worker pid=288)\u001b[0m IPython could not be loaded!\n"
     ]
    }
   ],
   "source": [
    "X_train_id = ray.put(X_train)\n",
    "results = ray.get([__get_shapley_ensemble_attr__.remote(model, X_train_id) for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([    0.        ,     0.        ,     0.        ,     0.        ,\n",
       "          121.9312086 ,     0.        ,     0.        ,   128.50971113,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        , 43238.73968161,     0.        ,  1973.06564969,\n",
       "          178.13057451,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,    66.02973515,\n",
       "            0.        ,     0.        ,   100.61496257,     0.        ,\n",
       "            0.        ,   232.05212035,   758.44243174,     0.        ,\n",
       "            0.        ,     0.        ,  2787.93408754,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,  1139.44870454,\n",
       "            0.        ,     0.        , 13245.8969563 ,     0.        ,\n",
       "            0.        ,   394.21993647,     0.        ,     0.        ,\n",
       "            0.        ,   241.16066089,     0.        ,     0.        ,\n",
       "          103.52311782,    91.69755771,   177.11493627,   492.25090954,\n",
       "          464.37921643,  3192.08645905,  2553.57840875,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,    72.26544637,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ]),\n",
       " array([    0.        ,     0.        ,     0.        ,     0.        ,\n",
       "          215.25921326,     0.        ,     0.        ,    99.23766086,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        , 42755.78808383,     0.        ,  2024.41056317,\n",
       "          152.07813509,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,    99.77826645,\n",
       "            0.        ,     0.        ,    50.31854352,     0.        ,\n",
       "            0.        ,   225.88686095,   687.78920841,     0.        ,\n",
       "            0.        ,     0.        ,  2775.28835918,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,  1260.71097793,\n",
       "            0.        ,     0.        , 13378.76759744,     0.        ,\n",
       "            0.        ,   589.59128687,     0.        ,     0.        ,\n",
       "            0.        ,   114.21191503,     0.        ,     0.        ,\n",
       "          156.43493359,    45.08544492,   211.30309919,   561.21454804,\n",
       "          530.09628775,  3283.48190568,  2196.83152015,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,    68.23659318,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ,\n",
       "            0.        ,     0.        ,     0.        ,     0.        ])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHAPLEY arguments\n",
    "shapley_background_size = 0.3 # 30% of actual dataset\n",
    "shapley_n_background = int(X_train.shape[0]*shapley_background_size)\n",
    "df_background = X_train.sample(n = shapley_n_background)\n",
    "dtrain = xgb.DMatrix(X_train)\n",
    "ddf_background = xgb.DMatrix(df_background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "2022-11-16T08:48:36CST : WARNING : _kernel : __init__ : 79 : Message : Using 293 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db0682160df4d2aada33be1263c84bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "2022-11-16T08:48:37CST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "2022-11-16T08:48:37CST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.13061412 0.08822182 0.06704858 0.05436371 0.04592368 0.03990987\n",
      " 0.03541298 0.0319279  0.02915156 0.02689114 0.02501813 0.02344356\n",
      " 0.02210393 0.02095268 0.01995493 0.01908404 0.01831928 0.01764436\n",
      " 0.01704625 0.01651443 0.01604033 0.01561691 0.01523831 0.01489968\n",
      " 0.01459693 0.01432662 0.01408584 0.01387212 0.01368338 0.01351786\n",
      " 0.01337405 0.01325071 0.01314678 0.01306141 0.01299391 0.01294374\n",
      " 0.01291051 0.01289396]\n",
      "2022-11-16T08:48:37CST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 39\n",
      "2022-11-16T08:48:37CST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7949889283823913\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "2022-11-16T08:49:02CST : INFO : _kernel : solve : 549 : Message : np.sum(w_aug) = 79.00000000000003\n",
      "2022-11-16T08:49:02CST : INFO : _kernel : solve : 550 : Message : np.sum(self.kernelWeights) = 1.0000000000000002\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "2022-11-16T08:49:02CST : INFO : _kernel : solve : 605 : Message : phi = [    0.             0.             0.             0.\n",
      " 50902.77499394     0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.          -472.06767276     0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.         16574.03511139     0.           240.73704147\n",
      " -1947.14604002  9275.65987168     0.             0.\n",
      "     0.             0.          5150.27052657 -3173.11316408\n",
      "     0.          -897.5817139      0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.           527.30930247     0.\n",
      "     0.          1522.93509148     0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.           259.37158707     0.\n",
      "     0.             0.             0.        ]\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "2022-11-16T08:49:02CST : INFO : _kernel : explain : 327 : Message : num_full_subsets = 1\n",
      "2022-11-16T08:49:02CST : INFO : _kernel : explain : 338 : Message : remaining_weight_vector = [0.13061412 0.08822182 0.06704858 0.05436371 0.04592368 0.03990987\n",
      " 0.03541298 0.0319279  0.02915156 0.02689114 0.02501813 0.02344356\n",
      " 0.02210393 0.02095268 0.01995493 0.01908404 0.01831928 0.01764436\n",
      " 0.01704625 0.01651443 0.01604033 0.01561691 0.01523831 0.01489968\n",
      " 0.01459693 0.01432662 0.01408584 0.01387212 0.01368338 0.01351786\n",
      " 0.01337405 0.01325071 0.01314678 0.01306141 0.01299391 0.01294374\n",
      " 0.01291051 0.01289396]\n",
      "2022-11-16T08:49:02CST : INFO : _kernel : explain : 339 : Message : num_paired_subset_sizes = 39\n",
      "2022-11-16T08:49:02CST : INFO : _kernel : explain : 378 : Message : weight_left = 0.7949889283823913\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [110], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### for bagging and knn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m kernel_explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mKernelExplainer(models[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict, df_background)\n\u001b[0;32m----> 3\u001b[0m kernel_shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_explainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# , ranked_outputs=True, check_additivity=False)\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/shap/explainers/_kernel.py:190\u001b[0m, in \u001b[0;36mKernel.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[1;32m    189\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[0;32m--> 190\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/shap/explainers/_kernel.py:382\u001b[0m, in \u001b[0;36mKernel.explain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights[nfixed_samples:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m weight_left \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights[nfixed_samples:]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[1;32m    385\u001b[0m phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgroups_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD))\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/shap/explainers/_kernel.py:530\u001b[0m, in \u001b[0;36mKernel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m eyVal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN):\n\u001b[0;32m--> 530\u001b[0m     eyVal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mey[i, :] \u001b[38;5;241m=\u001b[39m eyVal\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsamplesRun \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### for bagging and knn\n",
    "kernel_explainer = shap.KernelExplainer(models[0].predict, df_background)\n",
    "kernel_shap_values = kernel_explainer.shap_values(X=X_train) # , ranked_outputs=True, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidModelError",
     "evalue": "Model type not yet supported by TreeExplainer: <class 'method'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidModelError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tree_explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTreeExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_background\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tree_shap_values \u001b[38;5;241m=\u001b[39m tree_explainer\u001b[38;5;241m.\u001b[39mshap_values(X\u001b[38;5;241m=\u001b[39mX_train)\u001b[38;5;66;03m# , ranked_outputs=True, check_additivity=False)\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/shap/explainers/_tree.py:149\u001b[0m, in \u001b[0;36mTree.__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_perturbation \u001b[38;5;241m=\u001b[39m feature_perturbation\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTreeEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/admin/807c952d1ebb2e498414dc4b80a90b96c80ef2ef433f07c7a7381b5e38e2b5fa-20221110-224801-275852-64-wasif-dev-ray/lib/python3.9/site-packages/shap/explainers/_tree.py:993\u001b[0m, in \u001b[0;36mTreeEnsemble.__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_offset \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit_params[param_idx]\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidModelError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type not yet supported by TreeExplainer: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)))\n\u001b[1;32m    995\u001b[0m \u001b[38;5;66;03m# build a dense numpy version of all the tree objects\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees:\n",
      "\u001b[0;31mInvalidModelError\u001b[0m: Model type not yet supported by TreeExplainer: <class 'method'>"
     ]
    }
   ],
   "source": [
    "tree_explainer = shap.TreeExplainer(model.predict, df_background)\n",
    "tree_shap_values = tree_explainer.shap_values(X=X_train)# , ranked_outputs=True, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shap.explainers._kernel.Kernel at 0x7f7d80c5e910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shapley_sores = pd.DataFrame(shap_values.values, columns=X_train.columns)\n",
    "df_shapley_sores_list = df_shapley_sores.abs().mean().values #sort_values(ascending=False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.xai.model.explainable import Explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Explainable(X_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_algos = ['SHAP']\n",
    "#ex.get_attr(attr_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex.df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admin-admin-wasif-dev-ray",
   "language": "python",
   "name": "conda-env-admin-admin-wasif-dev-ray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6ff7914d2bc405bfa61a835d0564ba294eb5f3f9b4c24865f45d9397593b123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
