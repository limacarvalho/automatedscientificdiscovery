{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beb47ae-e15e-46a2-96d8-73e9974bd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da84152-5b10-4138-a1fd-f3e8f762780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ffe868-35f6-4e13-9e13-50ab16982661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dask.base import is_dask_collection\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37843295-df4c-450c-9d52-3e7fc00d21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72124114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fc3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from utils import dasker, logging, config\n",
    "from dask.dataframe import from_pandas\n",
    "import xgboost as xgb\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f6e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dasker, config as util_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc7cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 17:09:50,768 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlz45mj9', purging\n",
      "2022-09-07 17:09:50,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cecv0jk5', purging\n",
      "2022-09-07 17:09:50,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gxvoh7zh', purging\n",
      "2022-09-07 17:09:50,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wph58ycw', purging\n",
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[17:09:52] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[17:09:52] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[17:09:52] task [xgboost.dask-2]:tcp://127.0.0.1:43763 got new rank 2\n",
      "[17:09:52] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 3\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/data/simple_dmatrix.cc:102: Generating new Gradient Index.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/data/simple_dmatrix.cc:102: Generating new Gradient Index.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/data/simple_dmatrix.cc:102: Generating new Gradient Index.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/data/simple_dmatrix.cc:102: Generating new Gradient Index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28911\n",
      "[1]\ttrain-rmse:0.28879\n",
      "[2]\ttrain-rmse:0.28847\n",
      "[3]\ttrain-rmse:0.28815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n",
      "[17:09:52] INFO: /mnt/c/Users/rwmas/xgboost/src/gbm/gbtree.cc:178: Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = dasker.get_dask_client()\n",
    "\n",
    "\n",
    "# X and y must be Dask dataframes or arrays\n",
    "num_obs = 1e5\n",
    "num_features = 20\n",
    "X = da.random.random(size=(num_obs, num_features), chunks=(1000, num_features))\n",
    "y = da.random.random(size=(num_obs, 1), chunks=(1000, 1))\n",
    "\n",
    "dtrain = xgb.dask.DaskDMatrix(client, X, y)\n",
    "\n",
    "output = xgb.dask.train(\n",
    "    client,\n",
    "    {\"verbosity\": 2, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\"},\n",
    "    dtrain,\n",
    "    num_boost_round=4,\n",
    "    evals=[(dtrain, \"train\")],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9024e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a10c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ef2e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[11:11:02] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[11:11:02] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[11:11:02] task [xgboost.dask-2]:tcp://127.0.0.1:43763 got new rank 2\n",
      "[11:11:02] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28931\n",
      "[1]\ttrain-rmse:0.28920\n",
      "[2]\ttrain-rmse:0.28907\n",
      "[3]\ttrain-rmse:0.28897\n",
      "[4]\ttrain-rmse:0.28885\n",
      "[5]\ttrain-rmse:0.28873\n",
      "[6]\ttrain-rmse:0.28862\n",
      "[7]\ttrain-rmse:0.28851\n",
      "[8]\ttrain-rmse:0.28838\n",
      "[9]\ttrain-rmse:0.28828\n",
      "[10]\ttrain-rmse:0.28817\n",
      "[11]\ttrain-rmse:0.28808\n",
      "[12]\ttrain-rmse:0.28794\n",
      "[13]\ttrain-rmse:0.28784\n",
      "[14]\ttrain-rmse:0.28772\n",
      "[15]\ttrain-rmse:0.28761\n",
      "[16]\ttrain-rmse:0.28751\n",
      "[17]\ttrain-rmse:0.28739\n",
      "[18]\ttrain-rmse:0.28729\n",
      "[19]\ttrain-rmse:0.28718\n",
      "[20]\ttrain-rmse:0.28710\n",
      "[21]\ttrain-rmse:0.28699\n",
      "[22]\ttrain-rmse:0.28690\n",
      "[23]\ttrain-rmse:0.28682\n",
      "[24]\ttrain-rmse:0.28671\n",
      "[25]\ttrain-rmse:0.28661\n",
      "[26]\ttrain-rmse:0.28652\n",
      "[27]\ttrain-rmse:0.28642\n",
      "[28]\ttrain-rmse:0.28633\n",
      "[29]\ttrain-rmse:0.28623\n",
      "[30]\ttrain-rmse:0.28611\n",
      "[31]\ttrain-rmse:0.28603\n",
      "[32]\ttrain-rmse:0.28594\n",
      "[33]\ttrain-rmse:0.28582\n",
      "[34]\ttrain-rmse:0.28571\n",
      "[35]\ttrain-rmse:0.28562\n",
      "[36]\ttrain-rmse:0.28551\n",
      "[37]\ttrain-rmse:0.28544\n",
      "[38]\ttrain-rmse:0.28534\n",
      "[39]\ttrain-rmse:0.28524\n",
      "[40]\ttrain-rmse:0.28515\n",
      "[41]\ttrain-rmse:0.28506\n",
      "[42]\ttrain-rmse:0.28498\n",
      "[43]\ttrain-rmse:0.28490\n",
      "[44]\ttrain-rmse:0.28482\n",
      "[45]\ttrain-rmse:0.28473\n",
      "[46]\ttrain-rmse:0.28463\n",
      "[47]\ttrain-rmse:0.28455\n",
      "[48]\ttrain-rmse:0.28443\n",
      "[49]\ttrain-rmse:0.28435\n",
      "[50]\ttrain-rmse:0.28423\n",
      "[51]\ttrain-rmse:0.28415\n",
      "[52]\ttrain-rmse:0.28403\n",
      "[53]\ttrain-rmse:0.28394\n",
      "[54]\ttrain-rmse:0.28386\n",
      "[55]\ttrain-rmse:0.28370\n",
      "[56]\ttrain-rmse:0.28363\n",
      "[57]\ttrain-rmse:0.28348\n",
      "[58]\ttrain-rmse:0.28342\n",
      "[59]\ttrain-rmse:0.28334\n",
      "[60]\ttrain-rmse:0.28319\n",
      "[61]\ttrain-rmse:0.28310\n",
      "[62]\ttrain-rmse:0.28302\n",
      "[63]\ttrain-rmse:0.28288\n",
      "[64]\ttrain-rmse:0.28280\n",
      "[65]\ttrain-rmse:0.28266\n",
      "[66]\ttrain-rmse:0.28258\n",
      "[67]\ttrain-rmse:0.28244\n",
      "[68]\ttrain-rmse:0.28237\n",
      "[69]\ttrain-rmse:0.28219\n",
      "[70]\ttrain-rmse:0.28211\n",
      "[71]\ttrain-rmse:0.28193\n",
      "[72]\ttrain-rmse:0.28184\n",
      "[73]\ttrain-rmse:0.28170\n",
      "[74]\ttrain-rmse:0.28163\n",
      "[75]\ttrain-rmse:0.28145\n",
      "[76]\ttrain-rmse:0.28128\n",
      "[77]\ttrain-rmse:0.28120\n",
      "[78]\ttrain-rmse:0.28106\n",
      "[79]\ttrain-rmse:0.28099\n",
      "[80]\ttrain-rmse:0.28087\n",
      "[81]\ttrain-rmse:0.28077\n",
      "[82]\ttrain-rmse:0.28065\n",
      "[83]\ttrain-rmse:0.28056\n",
      "[84]\ttrain-rmse:0.28047\n",
      "[85]\ttrain-rmse:0.28030\n",
      "[86]\ttrain-rmse:0.28021\n",
      "[87]\ttrain-rmse:0.28012\n",
      "[88]\ttrain-rmse:0.28002\n",
      "[89]\ttrain-rmse:0.27993\n",
      "[90]\ttrain-rmse:0.27985\n",
      "[91]\ttrain-rmse:0.27973\n",
      "[92]\ttrain-rmse:0.27966\n",
      "[93]\ttrain-rmse:0.27957\n",
      "[94]\ttrain-rmse:0.27945\n",
      "[95]\ttrain-rmse:0.27936\n",
      "[96]\ttrain-rmse:0.27928\n",
      "[97]\ttrain-rmse:0.27919\n",
      "[98]\ttrain-rmse:0.27906\n",
      "[99]\ttrain-rmse:0.27897\n",
      "[100]\ttrain-rmse:0.27888\n",
      "[101]\ttrain-rmse:0.27879\n",
      "[102]\ttrain-rmse:0.27867\n",
      "[103]\ttrain-rmse:0.27858\n",
      "[104]\ttrain-rmse:0.27847\n",
      "[105]\ttrain-rmse:0.27839\n",
      "[106]\ttrain-rmse:0.27831\n",
      "[107]\ttrain-rmse:0.27822\n",
      "[108]\ttrain-rmse:0.27814\n",
      "[109]\ttrain-rmse:0.27802\n",
      "[110]\ttrain-rmse:0.27795\n",
      "[111]\ttrain-rmse:0.27784\n",
      "[112]\ttrain-rmse:0.27777\n",
      "[113]\ttrain-rmse:0.27769\n",
      "[114]\ttrain-rmse:0.27757\n",
      "[115]\ttrain-rmse:0.27749\n",
      "[116]\ttrain-rmse:0.27742\n",
      "[117]\ttrain-rmse:0.27733\n",
      "[118]\ttrain-rmse:0.27723\n",
      "[119]\ttrain-rmse:0.27713\n",
      "[120]\ttrain-rmse:0.27706\n",
      "[121]\ttrain-rmse:0.27695\n",
      "[122]\ttrain-rmse:0.27688\n",
      "[123]\ttrain-rmse:0.27680\n",
      "[124]\ttrain-rmse:0.27670\n",
      "[125]\ttrain-rmse:0.27660\n",
      "[126]\ttrain-rmse:0.27650\n",
      "[127]\ttrain-rmse:0.27639\n",
      "[128]\ttrain-rmse:0.27631\n",
      "[129]\ttrain-rmse:0.27623\n",
      "[130]\ttrain-rmse:0.27613\n",
      "[131]\ttrain-rmse:0.27600\n",
      "[132]\ttrain-rmse:0.27594\n",
      "[133]\ttrain-rmse:0.27582\n",
      "[134]\ttrain-rmse:0.27574\n",
      "[135]\ttrain-rmse:0.27566\n",
      "[136]\ttrain-rmse:0.27555\n",
      "[137]\ttrain-rmse:0.27547\n",
      "[138]\ttrain-rmse:0.27536\n",
      "[139]\ttrain-rmse:0.27527\n",
      "[140]\ttrain-rmse:0.27520\n",
      "[141]\ttrain-rmse:0.27510\n",
      "[142]\ttrain-rmse:0.27501\n",
      "[143]\ttrain-rmse:0.27493\n",
      "[144]\ttrain-rmse:0.27486\n",
      "[145]\ttrain-rmse:0.27474\n",
      "[146]\ttrain-rmse:0.27462\n",
      "[147]\ttrain-rmse:0.27455\n",
      "[148]\ttrain-rmse:0.27448\n",
      "[149]\ttrain-rmse:0.27436\n",
      "[150]\ttrain-rmse:0.27426\n",
      "[151]\ttrain-rmse:0.27419\n",
      "[152]\ttrain-rmse:0.27412\n",
      "[153]\ttrain-rmse:0.27404\n",
      "[154]\ttrain-rmse:0.27394\n",
      "[155]\ttrain-rmse:0.27385\n",
      "[156]\ttrain-rmse:0.27376\n",
      "[157]\ttrain-rmse:0.27369\n",
      "[158]\ttrain-rmse:0.27361\n",
      "[159]\ttrain-rmse:0.27351\n",
      "[160]\ttrain-rmse:0.27344\n",
      "[161]\ttrain-rmse:0.27337\n",
      "[162]\ttrain-rmse:0.27329\n",
      "[163]\ttrain-rmse:0.27320\n",
      "[164]\ttrain-rmse:0.27308\n",
      "[165]\ttrain-rmse:0.27297\n",
      "[166]\ttrain-rmse:0.27288\n",
      "[167]\ttrain-rmse:0.27282\n",
      "[168]\ttrain-rmse:0.27275\n",
      "[169]\ttrain-rmse:0.27266\n",
      "[170]\ttrain-rmse:0.27257\n",
      "[171]\ttrain-rmse:0.27251\n",
      "[172]\ttrain-rmse:0.27242\n",
      "[173]\ttrain-rmse:0.27232\n",
      "[174]\ttrain-rmse:0.27222\n",
      "[175]\ttrain-rmse:0.27210\n",
      "[176]\ttrain-rmse:0.27201\n",
      "[177]\ttrain-rmse:0.27195\n",
      "[178]\ttrain-rmse:0.27186\n",
      "[179]\ttrain-rmse:0.27174\n",
      "[180]\ttrain-rmse:0.27169\n",
      "[181]\ttrain-rmse:0.27158\n",
      "[182]\ttrain-rmse:0.27152\n",
      "[183]\ttrain-rmse:0.27143\n",
      "[184]\ttrain-rmse:0.27131\n",
      "[185]\ttrain-rmse:0.27123\n",
      "[186]\ttrain-rmse:0.27114\n",
      "[187]\ttrain-rmse:0.27102\n",
      "[188]\ttrain-rmse:0.27095\n",
      "[189]\ttrain-rmse:0.27087\n",
      "[190]\ttrain-rmse:0.27078\n",
      "[191]\ttrain-rmse:0.27073\n",
      "[192]\ttrain-rmse:0.27065\n",
      "[193]\ttrain-rmse:0.27058\n",
      "[194]\ttrain-rmse:0.27047\n",
      "[195]\ttrain-rmse:0.27039\n",
      "[196]\ttrain-rmse:0.27030\n",
      "[197]\ttrain-rmse:0.27024\n",
      "[198]\ttrain-rmse:0.27018\n",
      "[199]\ttrain-rmse:0.27009\n",
      "[200]\ttrain-rmse:0.27000\n",
      "[201]\ttrain-rmse:0.26989\n",
      "[202]\ttrain-rmse:0.26983\n",
      "[203]\ttrain-rmse:0.26975\n",
      "[204]\ttrain-rmse:0.26969\n",
      "[205]\ttrain-rmse:0.26963\n",
      "[206]\ttrain-rmse:0.26953\n",
      "[207]\ttrain-rmse:0.26945\n",
      "[208]\ttrain-rmse:0.26933\n",
      "[209]\ttrain-rmse:0.26926\n",
      "[210]\ttrain-rmse:0.26921\n",
      "[211]\ttrain-rmse:0.26914\n",
      "[212]\ttrain-rmse:0.26905\n",
      "[213]\ttrain-rmse:0.26900\n",
      "[214]\ttrain-rmse:0.26893\n",
      "[215]\ttrain-rmse:0.26885\n",
      "[216]\ttrain-rmse:0.26874\n",
      "[217]\ttrain-rmse:0.26862\n",
      "[218]\ttrain-rmse:0.26850\n",
      "[219]\ttrain-rmse:0.26845\n",
      "[220]\ttrain-rmse:0.26834\n",
      "[221]\ttrain-rmse:0.26823\n",
      "[222]\ttrain-rmse:0.26817\n",
      "[223]\ttrain-rmse:0.26810\n",
      "[224]\ttrain-rmse:0.26800\n",
      "[225]\ttrain-rmse:0.26792\n",
      "[226]\ttrain-rmse:0.26784\n",
      "[227]\ttrain-rmse:0.26776\n",
      "[228]\ttrain-rmse:0.26765\n",
      "[229]\ttrain-rmse:0.26754\n",
      "[230]\ttrain-rmse:0.26748\n",
      "[231]\ttrain-rmse:0.26740\n",
      "[232]\ttrain-rmse:0.26729\n",
      "[233]\ttrain-rmse:0.26721\n",
      "[234]\ttrain-rmse:0.26710\n",
      "[235]\ttrain-rmse:0.26699\n",
      "[236]\ttrain-rmse:0.26688\n",
      "[237]\ttrain-rmse:0.26676\n",
      "[238]\ttrain-rmse:0.26665\n",
      "[239]\ttrain-rmse:0.26658\n",
      "[240]\ttrain-rmse:0.26650\n",
      "[241]\ttrain-rmse:0.26642\n",
      "[242]\ttrain-rmse:0.26635\n",
      "[243]\ttrain-rmse:0.26624\n",
      "[244]\ttrain-rmse:0.26617\n",
      "[245]\ttrain-rmse:0.26610\n",
      "[246]\ttrain-rmse:0.26598\n",
      "[247]\ttrain-rmse:0.26592\n",
      "[248]\ttrain-rmse:0.26581\n",
      "[249]\ttrain-rmse:0.26573\n",
      "[250]\ttrain-rmse:0.26566\n",
      "[251]\ttrain-rmse:0.26556\n",
      "[252]\ttrain-rmse:0.26550\n",
      "[253]\ttrain-rmse:0.26543\n",
      "[254]\ttrain-rmse:0.26533\n",
      "[255]\ttrain-rmse:0.26526\n",
      "[256]\ttrain-rmse:0.26518\n",
      "[257]\ttrain-rmse:0.26506\n",
      "[258]\ttrain-rmse:0.26498\n",
      "[259]\ttrain-rmse:0.26490\n",
      "[260]\ttrain-rmse:0.26484\n",
      "[261]\ttrain-rmse:0.26473\n",
      "[262]\ttrain-rmse:0.26463\n",
      "[263]\ttrain-rmse:0.26450\n",
      "[264]\ttrain-rmse:0.26435\n",
      "[265]\ttrain-rmse:0.26430\n",
      "[266]\ttrain-rmse:0.26421\n",
      "[267]\ttrain-rmse:0.26414\n",
      "[268]\ttrain-rmse:0.26408\n",
      "[269]\ttrain-rmse:0.26394\n",
      "[270]\ttrain-rmse:0.26386\n",
      "[271]\ttrain-rmse:0.26379\n",
      "[272]\ttrain-rmse:0.26370\n",
      "[273]\ttrain-rmse:0.26357\n",
      "[274]\ttrain-rmse:0.26344\n",
      "[275]\ttrain-rmse:0.26333\n",
      "[276]\ttrain-rmse:0.26324\n",
      "[277]\ttrain-rmse:0.26317\n",
      "[278]\ttrain-rmse:0.26304\n",
      "[279]\ttrain-rmse:0.26294\n",
      "[280]\ttrain-rmse:0.26285\n",
      "[281]\ttrain-rmse:0.26275\n",
      "[282]\ttrain-rmse:0.26271\n",
      "[283]\ttrain-rmse:0.26261\n",
      "[284]\ttrain-rmse:0.26253\n",
      "[285]\ttrain-rmse:0.26244\n",
      "[286]\ttrain-rmse:0.26238\n",
      "[287]\ttrain-rmse:0.26231\n",
      "[288]\ttrain-rmse:0.26225\n",
      "[289]\ttrain-rmse:0.26219\n",
      "[290]\ttrain-rmse:0.26211\n",
      "[291]\ttrain-rmse:0.26204\n",
      "[292]\ttrain-rmse:0.26196\n",
      "[293]\ttrain-rmse:0.26188\n",
      "[294]\ttrain-rmse:0.26182\n",
      "[295]\ttrain-rmse:0.26177\n",
      "[296]\ttrain-rmse:0.26170\n",
      "[297]\ttrain-rmse:0.26158\n",
      "[298]\ttrain-rmse:0.26151\n",
      "[299]\ttrain-rmse:0.26140\n",
      "[300]\ttrain-rmse:0.26133\n",
      "[301]\ttrain-rmse:0.26126\n",
      "[302]\ttrain-rmse:0.26121\n",
      "[303]\ttrain-rmse:0.26110\n",
      "[304]\ttrain-rmse:0.26102\n",
      "[305]\ttrain-rmse:0.26096\n",
      "[306]\ttrain-rmse:0.26089\n",
      "[307]\ttrain-rmse:0.26081\n",
      "[308]\ttrain-rmse:0.26073\n",
      "[309]\ttrain-rmse:0.26067\n",
      "[310]\ttrain-rmse:0.26058\n",
      "[311]\ttrain-rmse:0.26047\n",
      "[312]\ttrain-rmse:0.26039\n",
      "[313]\ttrain-rmse:0.26027\n",
      "[314]\ttrain-rmse:0.26019\n",
      "[315]\ttrain-rmse:0.26014\n",
      "[316]\ttrain-rmse:0.26006\n",
      "[317]\ttrain-rmse:0.26000\n",
      "[318]\ttrain-rmse:0.25993\n",
      "[319]\ttrain-rmse:0.25988\n",
      "[320]\ttrain-rmse:0.25977\n",
      "[321]\ttrain-rmse:0.25970\n",
      "[322]\ttrain-rmse:0.25961\n",
      "[323]\ttrain-rmse:0.25949\n",
      "[324]\ttrain-rmse:0.25943\n",
      "[325]\ttrain-rmse:0.25935\n",
      "[326]\ttrain-rmse:0.25924\n",
      "[327]\ttrain-rmse:0.25911\n",
      "[328]\ttrain-rmse:0.25901\n",
      "[329]\ttrain-rmse:0.25890\n",
      "[330]\ttrain-rmse:0.25877\n",
      "[331]\ttrain-rmse:0.25868\n",
      "[332]\ttrain-rmse:0.25862\n",
      "[333]\ttrain-rmse:0.25854\n",
      "[334]\ttrain-rmse:0.25847\n",
      "[335]\ttrain-rmse:0.25838\n",
      "[336]\ttrain-rmse:0.25832\n",
      "[337]\ttrain-rmse:0.25824\n",
      "[338]\ttrain-rmse:0.25812\n",
      "[339]\ttrain-rmse:0.25807\n",
      "[340]\ttrain-rmse:0.25803\n",
      "[341]\ttrain-rmse:0.25795\n",
      "[342]\ttrain-rmse:0.25788\n",
      "[343]\ttrain-rmse:0.25781\n",
      "[344]\ttrain-rmse:0.25774\n",
      "[345]\ttrain-rmse:0.25766\n",
      "[346]\ttrain-rmse:0.25758\n",
      "[347]\ttrain-rmse:0.25752\n",
      "[348]\ttrain-rmse:0.25746\n",
      "[349]\ttrain-rmse:0.25739\n",
      "[350]\ttrain-rmse:0.25732\n",
      "[351]\ttrain-rmse:0.25726\n",
      "[352]\ttrain-rmse:0.25719\n",
      "[353]\ttrain-rmse:0.25711\n",
      "[354]\ttrain-rmse:0.25707\n",
      "[355]\ttrain-rmse:0.25699\n",
      "[356]\ttrain-rmse:0.25693\n",
      "[357]\ttrain-rmse:0.25683\n",
      "[358]\ttrain-rmse:0.25677\n",
      "[359]\ttrain-rmse:0.25672\n",
      "[360]\ttrain-rmse:0.25668\n",
      "[361]\ttrain-rmse:0.25661\n",
      "[362]\ttrain-rmse:0.25649\n",
      "[363]\ttrain-rmse:0.25642\n",
      "[364]\ttrain-rmse:0.25633\n",
      "[365]\ttrain-rmse:0.25626\n",
      "[366]\ttrain-rmse:0.25614\n",
      "[367]\ttrain-rmse:0.25607\n",
      "[368]\ttrain-rmse:0.25595\n",
      "[369]\ttrain-rmse:0.25591\n",
      "[370]\ttrain-rmse:0.25585\n",
      "[371]\ttrain-rmse:0.25578\n",
      "[372]\ttrain-rmse:0.25570\n",
      "[373]\ttrain-rmse:0.25563\n",
      "[374]\ttrain-rmse:0.25551\n",
      "[375]\ttrain-rmse:0.25544\n",
      "[376]\ttrain-rmse:0.25537\n",
      "[377]\ttrain-rmse:0.25531\n",
      "[378]\ttrain-rmse:0.25519\n",
      "[379]\ttrain-rmse:0.25512\n",
      "[380]\ttrain-rmse:0.25507\n",
      "[381]\ttrain-rmse:0.25495\n",
      "[382]\ttrain-rmse:0.25481\n",
      "[383]\ttrain-rmse:0.25474\n",
      "[384]\ttrain-rmse:0.25465\n",
      "[385]\ttrain-rmse:0.25458\n",
      "[386]\ttrain-rmse:0.25445\n",
      "[387]\ttrain-rmse:0.25435\n",
      "[388]\ttrain-rmse:0.25429\n",
      "[389]\ttrain-rmse:0.25423\n",
      "[390]\ttrain-rmse:0.25416\n",
      "[391]\ttrain-rmse:0.25409\n",
      "[392]\ttrain-rmse:0.25405\n",
      "[393]\ttrain-rmse:0.25392\n",
      "[394]\ttrain-rmse:0.25385\n",
      "[395]\ttrain-rmse:0.25377\n",
      "[396]\ttrain-rmse:0.25370\n",
      "[397]\ttrain-rmse:0.25359\n",
      "[398]\ttrain-rmse:0.25352\n",
      "[399]\ttrain-rmse:0.25340\n",
      "[400]\ttrain-rmse:0.25332\n",
      "[401]\ttrain-rmse:0.25326\n",
      "[402]\ttrain-rmse:0.25319\n",
      "[403]\ttrain-rmse:0.25313\n",
      "[404]\ttrain-rmse:0.25306\n",
      "[405]\ttrain-rmse:0.25295\n",
      "[406]\ttrain-rmse:0.25289\n",
      "[407]\ttrain-rmse:0.25282\n",
      "[408]\ttrain-rmse:0.25274\n",
      "[409]\ttrain-rmse:0.25269\n",
      "[410]\ttrain-rmse:0.25262\n",
      "[411]\ttrain-rmse:0.25255\n",
      "[412]\ttrain-rmse:0.25248\n",
      "[413]\ttrain-rmse:0.25234\n",
      "[414]\ttrain-rmse:0.25227\n",
      "[415]\ttrain-rmse:0.25221\n",
      "[416]\ttrain-rmse:0.25212\n",
      "[417]\ttrain-rmse:0.25205\n",
      "[418]\ttrain-rmse:0.25199\n",
      "[419]\ttrain-rmse:0.25193\n",
      "[420]\ttrain-rmse:0.25187\n",
      "[421]\ttrain-rmse:0.25180\n",
      "[422]\ttrain-rmse:0.25173\n",
      "[423]\ttrain-rmse:0.25166\n",
      "[424]\ttrain-rmse:0.25159\n",
      "[425]\ttrain-rmse:0.25150\n",
      "[426]\ttrain-rmse:0.25144\n",
      "[427]\ttrain-rmse:0.25137\n",
      "[428]\ttrain-rmse:0.25125\n",
      "[429]\ttrain-rmse:0.25112\n",
      "[430]\ttrain-rmse:0.25100\n",
      "[431]\ttrain-rmse:0.25095\n",
      "[432]\ttrain-rmse:0.25088\n",
      "[433]\ttrain-rmse:0.25082\n",
      "[434]\ttrain-rmse:0.25073\n",
      "[435]\ttrain-rmse:0.25067\n",
      "[436]\ttrain-rmse:0.25062\n",
      "[437]\ttrain-rmse:0.25057\n",
      "[438]\ttrain-rmse:0.25051\n",
      "[439]\ttrain-rmse:0.25044\n",
      "[440]\ttrain-rmse:0.25033\n",
      "[441]\ttrain-rmse:0.25026\n",
      "[442]\ttrain-rmse:0.25022\n",
      "[443]\ttrain-rmse:0.25014\n",
      "[444]\ttrain-rmse:0.25008\n",
      "[445]\ttrain-rmse:0.25001\n",
      "[446]\ttrain-rmse:0.24996\n",
      "[447]\ttrain-rmse:0.24989\n",
      "[448]\ttrain-rmse:0.24984\n",
      "[449]\ttrain-rmse:0.24977\n",
      "[450]\ttrain-rmse:0.24968\n",
      "[451]\ttrain-rmse:0.24961\n",
      "[452]\ttrain-rmse:0.24949\n",
      "[453]\ttrain-rmse:0.24941\n",
      "[454]\ttrain-rmse:0.24929\n",
      "[455]\ttrain-rmse:0.24925\n",
      "[456]\ttrain-rmse:0.24919\n",
      "[457]\ttrain-rmse:0.24913\n",
      "[458]\ttrain-rmse:0.24907\n",
      "[459]\ttrain-rmse:0.24897\n",
      "[460]\ttrain-rmse:0.24890\n",
      "[461]\ttrain-rmse:0.24883\n",
      "[462]\ttrain-rmse:0.24875\n",
      "[463]\ttrain-rmse:0.24864\n",
      "[464]\ttrain-rmse:0.24855\n",
      "[465]\ttrain-rmse:0.24850\n",
      "[466]\ttrain-rmse:0.24843\n",
      "[467]\ttrain-rmse:0.24831\n",
      "[468]\ttrain-rmse:0.24822\n",
      "[469]\ttrain-rmse:0.24816\n",
      "[470]\ttrain-rmse:0.24809\n",
      "[471]\ttrain-rmse:0.24796\n",
      "[472]\ttrain-rmse:0.24789\n",
      "[473]\ttrain-rmse:0.24784\n",
      "[474]\ttrain-rmse:0.24775\n",
      "[475]\ttrain-rmse:0.24766\n",
      "[476]\ttrain-rmse:0.24753\n",
      "[477]\ttrain-rmse:0.24746\n",
      "[478]\ttrain-rmse:0.24740\n",
      "[479]\ttrain-rmse:0.24727\n",
      "[480]\ttrain-rmse:0.24721\n",
      "[481]\ttrain-rmse:0.24713\n",
      "[482]\ttrain-rmse:0.24707\n",
      "[483]\ttrain-rmse:0.24698\n",
      "[484]\ttrain-rmse:0.24688\n",
      "[485]\ttrain-rmse:0.24676\n",
      "[486]\ttrain-rmse:0.24670\n",
      "[487]\ttrain-rmse:0.24658\n",
      "[488]\ttrain-rmse:0.24651\n",
      "[489]\ttrain-rmse:0.24641\n",
      "[490]\ttrain-rmse:0.24630\n",
      "[491]\ttrain-rmse:0.24624\n",
      "[492]\ttrain-rmse:0.24614\n",
      "[493]\ttrain-rmse:0.24604\n",
      "[494]\ttrain-rmse:0.24599\n",
      "[495]\ttrain-rmse:0.24593\n",
      "[496]\ttrain-rmse:0.24581\n",
      "[497]\ttrain-rmse:0.24569\n",
      "[498]\ttrain-rmse:0.24560\n",
      "[499]\ttrain-rmse:0.24556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[11:12:33] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[11:12:33] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[11:12:33] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28956\n",
      "[1]\ttrain-rmse:0.28944\n",
      "[2]\ttrain-rmse:0.28933\n",
      "[3]\ttrain-rmse:0.28919\n",
      "[4]\ttrain-rmse:0.28908\n",
      "[5]\ttrain-rmse:0.28898\n",
      "[6]\ttrain-rmse:0.28884\n",
      "[7]\ttrain-rmse:0.28873\n",
      "[8]\ttrain-rmse:0.28860\n",
      "[9]\ttrain-rmse:0.28849\n",
      "[10]\ttrain-rmse:0.28836\n",
      "[11]\ttrain-rmse:0.28826\n",
      "[12]\ttrain-rmse:0.28815\n",
      "[13]\ttrain-rmse:0.28804\n",
      "[14]\ttrain-rmse:0.28793\n",
      "[15]\ttrain-rmse:0.28781\n",
      "[16]\ttrain-rmse:0.28770\n",
      "[17]\ttrain-rmse:0.28758\n",
      "[18]\ttrain-rmse:0.28747\n",
      "[19]\ttrain-rmse:0.28736\n",
      "[20]\ttrain-rmse:0.28727\n",
      "[21]\ttrain-rmse:0.28714\n",
      "[22]\ttrain-rmse:0.28704\n",
      "[23]\ttrain-rmse:0.28694\n",
      "[24]\ttrain-rmse:0.28683\n",
      "[25]\ttrain-rmse:0.28672\n",
      "[26]\ttrain-rmse:0.28661\n",
      "[27]\ttrain-rmse:0.28649\n",
      "[28]\ttrain-rmse:0.28641\n",
      "[29]\ttrain-rmse:0.28630\n",
      "[30]\ttrain-rmse:0.28621\n",
      "[31]\ttrain-rmse:0.28611\n",
      "[32]\ttrain-rmse:0.28602\n",
      "[33]\ttrain-rmse:0.28592\n",
      "[34]\ttrain-rmse:0.28583\n",
      "[35]\ttrain-rmse:0.28574\n",
      "[36]\ttrain-rmse:0.28563\n",
      "[37]\ttrain-rmse:0.28553\n",
      "[38]\ttrain-rmse:0.28543\n",
      "[39]\ttrain-rmse:0.28534\n",
      "[40]\ttrain-rmse:0.28525\n",
      "[41]\ttrain-rmse:0.28516\n",
      "[42]\ttrain-rmse:0.28507\n",
      "[43]\ttrain-rmse:0.28498\n",
      "[44]\ttrain-rmse:0.28491\n",
      "[45]\ttrain-rmse:0.28480\n",
      "[46]\ttrain-rmse:0.28468\n",
      "[47]\ttrain-rmse:0.28459\n",
      "[48]\ttrain-rmse:0.28449\n",
      "[49]\ttrain-rmse:0.28441\n",
      "[50]\ttrain-rmse:0.28432\n",
      "[51]\ttrain-rmse:0.28424\n",
      "[52]\ttrain-rmse:0.28416\n",
      "[53]\ttrain-rmse:0.28403\n",
      "[54]\ttrain-rmse:0.28395\n",
      "[55]\ttrain-rmse:0.28387\n",
      "[56]\ttrain-rmse:0.28379\n",
      "[57]\ttrain-rmse:0.28372\n",
      "[58]\ttrain-rmse:0.28364\n",
      "[59]\ttrain-rmse:0.28354\n",
      "[60]\ttrain-rmse:0.28346\n",
      "[61]\ttrain-rmse:0.28335\n",
      "[62]\ttrain-rmse:0.28325\n",
      "[63]\ttrain-rmse:0.28318\n",
      "[64]\ttrain-rmse:0.28310\n",
      "[65]\ttrain-rmse:0.28298\n",
      "[66]\ttrain-rmse:0.28287\n",
      "[67]\ttrain-rmse:0.28280\n",
      "[68]\ttrain-rmse:0.28269\n",
      "[69]\ttrain-rmse:0.28261\n",
      "[70]\ttrain-rmse:0.28254\n",
      "[71]\ttrain-rmse:0.28247\n",
      "[72]\ttrain-rmse:0.28236\n",
      "[73]\ttrain-rmse:0.28228\n",
      "[74]\ttrain-rmse:0.28218\n",
      "[75]\ttrain-rmse:0.28210\n",
      "[76]\ttrain-rmse:0.28202\n",
      "[77]\ttrain-rmse:0.28194\n",
      "[78]\ttrain-rmse:0.28188\n",
      "[79]\ttrain-rmse:0.28180\n",
      "[80]\ttrain-rmse:0.28171\n",
      "[81]\ttrain-rmse:0.28161\n",
      "[82]\ttrain-rmse:0.28154\n",
      "[83]\ttrain-rmse:0.28146\n",
      "[84]\ttrain-rmse:0.28133\n",
      "[85]\ttrain-rmse:0.28116\n",
      "[86]\ttrain-rmse:0.28105\n",
      "[87]\ttrain-rmse:0.28089\n",
      "[88]\ttrain-rmse:0.28082\n",
      "[89]\ttrain-rmse:0.28074\n",
      "[90]\ttrain-rmse:0.28067\n",
      "[91]\ttrain-rmse:0.28055\n",
      "[92]\ttrain-rmse:0.28037\n",
      "[93]\ttrain-rmse:0.28028\n",
      "[94]\ttrain-rmse:0.28022\n",
      "[95]\ttrain-rmse:0.28015\n",
      "[96]\ttrain-rmse:0.28001\n",
      "[97]\ttrain-rmse:0.27988\n",
      "[98]\ttrain-rmse:0.27980\n",
      "[99]\ttrain-rmse:0.27974\n",
      "[100]\ttrain-rmse:0.27961\n",
      "[101]\ttrain-rmse:0.27948\n",
      "[102]\ttrain-rmse:0.27938\n",
      "[103]\ttrain-rmse:0.27925\n",
      "[104]\ttrain-rmse:0.27913\n",
      "[105]\ttrain-rmse:0.27907\n",
      "[106]\ttrain-rmse:0.27896\n",
      "[107]\ttrain-rmse:0.27887\n",
      "[108]\ttrain-rmse:0.27878\n",
      "[109]\ttrain-rmse:0.27866\n",
      "[110]\ttrain-rmse:0.27859\n",
      "[111]\ttrain-rmse:0.27843\n",
      "[112]\ttrain-rmse:0.27833\n",
      "[113]\ttrain-rmse:0.27822\n",
      "[114]\ttrain-rmse:0.27807\n",
      "[115]\ttrain-rmse:0.27799\n",
      "[116]\ttrain-rmse:0.27785\n",
      "[117]\ttrain-rmse:0.27778\n",
      "[118]\ttrain-rmse:0.27769\n",
      "[119]\ttrain-rmse:0.27762\n",
      "[120]\ttrain-rmse:0.27748\n",
      "[121]\ttrain-rmse:0.27739\n",
      "[122]\ttrain-rmse:0.27732\n",
      "[123]\ttrain-rmse:0.27724\n",
      "[124]\ttrain-rmse:0.27716\n",
      "[125]\ttrain-rmse:0.27701\n",
      "[126]\ttrain-rmse:0.27687\n",
      "[127]\ttrain-rmse:0.27675\n",
      "[128]\ttrain-rmse:0.27662\n",
      "[129]\ttrain-rmse:0.27654\n",
      "[130]\ttrain-rmse:0.27643\n",
      "[131]\ttrain-rmse:0.27626\n",
      "[132]\ttrain-rmse:0.27610\n",
      "[133]\ttrain-rmse:0.27597\n",
      "[134]\ttrain-rmse:0.27591\n",
      "[135]\ttrain-rmse:0.27578\n",
      "[136]\ttrain-rmse:0.27567\n",
      "[137]\ttrain-rmse:0.27559\n",
      "[138]\ttrain-rmse:0.27548\n",
      "[139]\ttrain-rmse:0.27532\n",
      "[140]\ttrain-rmse:0.27527\n",
      "[141]\ttrain-rmse:0.27516\n",
      "[142]\ttrain-rmse:0.27499\n",
      "[143]\ttrain-rmse:0.27489\n",
      "[144]\ttrain-rmse:0.27481\n",
      "[145]\ttrain-rmse:0.27476\n",
      "[146]\ttrain-rmse:0.27470\n",
      "[147]\ttrain-rmse:0.27459\n",
      "[148]\ttrain-rmse:0.27453\n",
      "[149]\ttrain-rmse:0.27447\n",
      "[150]\ttrain-rmse:0.27435\n",
      "[151]\ttrain-rmse:0.27429\n",
      "[152]\ttrain-rmse:0.27423\n",
      "[153]\ttrain-rmse:0.27412\n",
      "[154]\ttrain-rmse:0.27405\n",
      "[155]\ttrain-rmse:0.27395\n",
      "[156]\ttrain-rmse:0.27389\n",
      "[157]\ttrain-rmse:0.27378\n",
      "[158]\ttrain-rmse:0.27371\n",
      "[159]\ttrain-rmse:0.27355\n",
      "[160]\ttrain-rmse:0.27346\n",
      "[161]\ttrain-rmse:0.27330\n",
      "[162]\ttrain-rmse:0.27323\n",
      "[163]\ttrain-rmse:0.27318\n",
      "[164]\ttrain-rmse:0.27311\n",
      "[165]\ttrain-rmse:0.27300\n",
      "[166]\ttrain-rmse:0.27293\n",
      "[167]\ttrain-rmse:0.27286\n",
      "[168]\ttrain-rmse:0.27281\n",
      "[169]\ttrain-rmse:0.27270\n",
      "[170]\ttrain-rmse:0.27262\n",
      "[171]\ttrain-rmse:0.27257\n",
      "[172]\ttrain-rmse:0.27250\n",
      "[173]\ttrain-rmse:0.27241\n",
      "[174]\ttrain-rmse:0.27235\n",
      "[175]\ttrain-rmse:0.27228\n",
      "[176]\ttrain-rmse:0.27221\n",
      "[177]\ttrain-rmse:0.27216\n",
      "[178]\ttrain-rmse:0.27210\n",
      "[179]\ttrain-rmse:0.27199\n",
      "[180]\ttrain-rmse:0.27193\n",
      "[181]\ttrain-rmse:0.27186\n",
      "[182]\ttrain-rmse:0.27175\n",
      "[183]\ttrain-rmse:0.27169\n",
      "[184]\ttrain-rmse:0.27164\n",
      "[185]\ttrain-rmse:0.27157\n",
      "[186]\ttrain-rmse:0.27152\n",
      "[187]\ttrain-rmse:0.27143\n",
      "[188]\ttrain-rmse:0.27136\n",
      "[189]\ttrain-rmse:0.27131\n",
      "[190]\ttrain-rmse:0.27121\n",
      "[191]\ttrain-rmse:0.27113\n",
      "[192]\ttrain-rmse:0.27105\n",
      "[193]\ttrain-rmse:0.27099\n",
      "[194]\ttrain-rmse:0.27088\n",
      "[195]\ttrain-rmse:0.27083\n",
      "[196]\ttrain-rmse:0.27077\n",
      "[197]\ttrain-rmse:0.27069\n",
      "[198]\ttrain-rmse:0.27056\n",
      "[199]\ttrain-rmse:0.27047\n",
      "[200]\ttrain-rmse:0.27042\n",
      "[201]\ttrain-rmse:0.27031\n",
      "[202]\ttrain-rmse:0.27024\n",
      "[203]\ttrain-rmse:0.27016\n",
      "[204]\ttrain-rmse:0.27004\n",
      "[205]\ttrain-rmse:0.26997\n",
      "[206]\ttrain-rmse:0.26987\n",
      "[207]\ttrain-rmse:0.26974\n",
      "[208]\ttrain-rmse:0.26961\n",
      "[209]\ttrain-rmse:0.26953\n",
      "[210]\ttrain-rmse:0.26944\n",
      "[211]\ttrain-rmse:0.26935\n",
      "[212]\ttrain-rmse:0.26922\n",
      "[213]\ttrain-rmse:0.26914\n",
      "[214]\ttrain-rmse:0.26908\n",
      "[215]\ttrain-rmse:0.26901\n",
      "[216]\ttrain-rmse:0.26889\n",
      "[217]\ttrain-rmse:0.26882\n",
      "[218]\ttrain-rmse:0.26874\n",
      "[219]\ttrain-rmse:0.26861\n",
      "[220]\ttrain-rmse:0.26853\n",
      "[221]\ttrain-rmse:0.26847\n",
      "[222]\ttrain-rmse:0.26841\n",
      "[223]\ttrain-rmse:0.26831\n",
      "[224]\ttrain-rmse:0.26819\n",
      "[225]\ttrain-rmse:0.26813\n",
      "[226]\ttrain-rmse:0.26801\n",
      "[227]\ttrain-rmse:0.26796\n",
      "[228]\ttrain-rmse:0.26786\n",
      "[229]\ttrain-rmse:0.26780\n",
      "[230]\ttrain-rmse:0.26774\n",
      "[231]\ttrain-rmse:0.26765\n",
      "[232]\ttrain-rmse:0.26758\n",
      "[233]\ttrain-rmse:0.26750\n",
      "[234]\ttrain-rmse:0.26742\n",
      "[235]\ttrain-rmse:0.26737\n",
      "[236]\ttrain-rmse:0.26728\n",
      "[237]\ttrain-rmse:0.26716\n",
      "[238]\ttrain-rmse:0.26710\n",
      "[239]\ttrain-rmse:0.26701\n",
      "[240]\ttrain-rmse:0.26688\n",
      "[241]\ttrain-rmse:0.26678\n",
      "[242]\ttrain-rmse:0.26672\n",
      "[243]\ttrain-rmse:0.26662\n",
      "[244]\ttrain-rmse:0.26656\n",
      "[245]\ttrain-rmse:0.26648\n",
      "[246]\ttrain-rmse:0.26639\n",
      "[247]\ttrain-rmse:0.26624\n",
      "[248]\ttrain-rmse:0.26615\n",
      "[249]\ttrain-rmse:0.26610\n",
      "[250]\ttrain-rmse:0.26598\n",
      "[251]\ttrain-rmse:0.26592\n",
      "[252]\ttrain-rmse:0.26587\n",
      "[253]\ttrain-rmse:0.26572\n",
      "[254]\ttrain-rmse:0.26559\n",
      "[255]\ttrain-rmse:0.26544\n",
      "[256]\ttrain-rmse:0.26533\n",
      "[257]\ttrain-rmse:0.26525\n",
      "[258]\ttrain-rmse:0.26518\n",
      "[259]\ttrain-rmse:0.26504\n",
      "[260]\ttrain-rmse:0.26498\n",
      "[261]\ttrain-rmse:0.26489\n",
      "[262]\ttrain-rmse:0.26483\n",
      "[263]\ttrain-rmse:0.26476\n",
      "[264]\ttrain-rmse:0.26463\n",
      "[265]\ttrain-rmse:0.26451\n",
      "[266]\ttrain-rmse:0.26446\n",
      "[267]\ttrain-rmse:0.26438\n",
      "[268]\ttrain-rmse:0.26433\n",
      "[269]\ttrain-rmse:0.26420\n",
      "[270]\ttrain-rmse:0.26412\n",
      "[271]\ttrain-rmse:0.26407\n",
      "[272]\ttrain-rmse:0.26398\n",
      "[273]\ttrain-rmse:0.26388\n",
      "[274]\ttrain-rmse:0.26380\n",
      "[275]\ttrain-rmse:0.26367\n",
      "[276]\ttrain-rmse:0.26355\n",
      "[277]\ttrain-rmse:0.26347\n",
      "[278]\ttrain-rmse:0.26341\n",
      "[279]\ttrain-rmse:0.26329\n",
      "[280]\ttrain-rmse:0.26316\n",
      "[281]\ttrain-rmse:0.26307\n",
      "[282]\ttrain-rmse:0.26299\n",
      "[283]\ttrain-rmse:0.26288\n",
      "[284]\ttrain-rmse:0.26283\n",
      "[285]\ttrain-rmse:0.26275\n",
      "[286]\ttrain-rmse:0.26266\n",
      "[287]\ttrain-rmse:0.26254\n",
      "[288]\ttrain-rmse:0.26248\n",
      "[289]\ttrain-rmse:0.26239\n",
      "[290]\ttrain-rmse:0.26232\n",
      "[291]\ttrain-rmse:0.26223\n",
      "[292]\ttrain-rmse:0.26211\n",
      "[293]\ttrain-rmse:0.26203\n",
      "[294]\ttrain-rmse:0.26198\n",
      "[295]\ttrain-rmse:0.26192\n",
      "[296]\ttrain-rmse:0.26185\n",
      "[297]\ttrain-rmse:0.26176\n",
      "[298]\ttrain-rmse:0.26168\n",
      "[299]\ttrain-rmse:0.26159\n",
      "[300]\ttrain-rmse:0.26153\n",
      "[301]\ttrain-rmse:0.26141\n",
      "[302]\ttrain-rmse:0.26134\n",
      "[303]\ttrain-rmse:0.26128\n",
      "[304]\ttrain-rmse:0.26122\n",
      "[305]\ttrain-rmse:0.26117\n",
      "[306]\ttrain-rmse:0.26108\n",
      "[307]\ttrain-rmse:0.26103\n",
      "[308]\ttrain-rmse:0.26094\n",
      "[309]\ttrain-rmse:0.26086\n",
      "[310]\ttrain-rmse:0.26079\n",
      "[311]\ttrain-rmse:0.26071\n",
      "[312]\ttrain-rmse:0.26066\n",
      "[313]\ttrain-rmse:0.26055\n",
      "[314]\ttrain-rmse:0.26048\n",
      "[315]\ttrain-rmse:0.26035\n",
      "[316]\ttrain-rmse:0.26030\n",
      "[317]\ttrain-rmse:0.26025\n",
      "[318]\ttrain-rmse:0.26018\n",
      "[319]\ttrain-rmse:0.26007\n",
      "[320]\ttrain-rmse:0.25995\n",
      "[321]\ttrain-rmse:0.25989\n",
      "[322]\ttrain-rmse:0.25977\n",
      "[323]\ttrain-rmse:0.25966\n",
      "[324]\ttrain-rmse:0.25961\n",
      "[325]\ttrain-rmse:0.25953\n",
      "[326]\ttrain-rmse:0.25947\n",
      "[327]\ttrain-rmse:0.25939\n",
      "[328]\ttrain-rmse:0.25932\n",
      "[329]\ttrain-rmse:0.25927\n",
      "[330]\ttrain-rmse:0.25923\n",
      "[331]\ttrain-rmse:0.25917\n",
      "[332]\ttrain-rmse:0.25912\n",
      "[333]\ttrain-rmse:0.25904\n",
      "[334]\ttrain-rmse:0.25900\n",
      "[335]\ttrain-rmse:0.25887\n",
      "[336]\ttrain-rmse:0.25880\n",
      "[337]\ttrain-rmse:0.25868\n",
      "[338]\ttrain-rmse:0.25863\n",
      "[339]\ttrain-rmse:0.25854\n",
      "[340]\ttrain-rmse:0.25843\n",
      "[341]\ttrain-rmse:0.25837\n",
      "[342]\ttrain-rmse:0.25821\n",
      "[343]\ttrain-rmse:0.25811\n",
      "[344]\ttrain-rmse:0.25800\n",
      "[345]\ttrain-rmse:0.25794\n",
      "[346]\ttrain-rmse:0.25787\n",
      "[347]\ttrain-rmse:0.25782\n",
      "[348]\ttrain-rmse:0.25775\n",
      "[349]\ttrain-rmse:0.25769\n",
      "[350]\ttrain-rmse:0.25761\n",
      "[351]\ttrain-rmse:0.25756\n",
      "[352]\ttrain-rmse:0.25751\n",
      "[353]\ttrain-rmse:0.25745\n",
      "[354]\ttrain-rmse:0.25739\n",
      "[355]\ttrain-rmse:0.25729\n",
      "[356]\ttrain-rmse:0.25718\n",
      "[357]\ttrain-rmse:0.25713\n",
      "[358]\ttrain-rmse:0.25703\n",
      "[359]\ttrain-rmse:0.25698\n",
      "[360]\ttrain-rmse:0.25693\n",
      "[361]\ttrain-rmse:0.25686\n",
      "[362]\ttrain-rmse:0.25680\n",
      "[363]\ttrain-rmse:0.25671\n",
      "[364]\ttrain-rmse:0.25665\n",
      "[365]\ttrain-rmse:0.25659\n",
      "[366]\ttrain-rmse:0.25651\n",
      "[367]\ttrain-rmse:0.25640\n",
      "[368]\ttrain-rmse:0.25634\n",
      "[369]\ttrain-rmse:0.25628\n",
      "[370]\ttrain-rmse:0.25624\n",
      "[371]\ttrain-rmse:0.25619\n",
      "[372]\ttrain-rmse:0.25611\n",
      "[373]\ttrain-rmse:0.25601\n",
      "[374]\ttrain-rmse:0.25596\n",
      "[375]\ttrain-rmse:0.25589\n",
      "[376]\ttrain-rmse:0.25584\n",
      "[377]\ttrain-rmse:0.25579\n",
      "[378]\ttrain-rmse:0.25572\n",
      "[379]\ttrain-rmse:0.25567\n",
      "[380]\ttrain-rmse:0.25553\n",
      "[381]\ttrain-rmse:0.25548\n",
      "[382]\ttrain-rmse:0.25539\n",
      "[383]\ttrain-rmse:0.25532\n",
      "[384]\ttrain-rmse:0.25528\n",
      "[385]\ttrain-rmse:0.25521\n",
      "[386]\ttrain-rmse:0.25515\n",
      "[387]\ttrain-rmse:0.25510\n",
      "[388]\ttrain-rmse:0.25502\n",
      "[389]\ttrain-rmse:0.25498\n",
      "[390]\ttrain-rmse:0.25488\n",
      "[391]\ttrain-rmse:0.25482\n",
      "[392]\ttrain-rmse:0.25475\n",
      "[393]\ttrain-rmse:0.25467\n",
      "[394]\ttrain-rmse:0.25461\n",
      "[395]\ttrain-rmse:0.25455\n",
      "[396]\ttrain-rmse:0.25449\n",
      "[397]\ttrain-rmse:0.25445\n",
      "[398]\ttrain-rmse:0.25439\n",
      "[399]\ttrain-rmse:0.25432\n",
      "[400]\ttrain-rmse:0.25425\n",
      "[401]\ttrain-rmse:0.25420\n",
      "[402]\ttrain-rmse:0.25412\n",
      "[403]\ttrain-rmse:0.25408\n",
      "[404]\ttrain-rmse:0.25400\n",
      "[405]\ttrain-rmse:0.25396\n",
      "[406]\ttrain-rmse:0.25388\n",
      "[407]\ttrain-rmse:0.25381\n",
      "[408]\ttrain-rmse:0.25376\n",
      "[409]\ttrain-rmse:0.25366\n",
      "[410]\ttrain-rmse:0.25357\n",
      "[411]\ttrain-rmse:0.25348\n",
      "[412]\ttrain-rmse:0.25343\n",
      "[413]\ttrain-rmse:0.25333\n",
      "[414]\ttrain-rmse:0.25327\n",
      "[415]\ttrain-rmse:0.25322\n",
      "[416]\ttrain-rmse:0.25318\n",
      "[417]\ttrain-rmse:0.25313\n",
      "[418]\ttrain-rmse:0.25308\n",
      "[419]\ttrain-rmse:0.25302\n",
      "[420]\ttrain-rmse:0.25297\n",
      "[421]\ttrain-rmse:0.25292\n",
      "[422]\ttrain-rmse:0.25287\n",
      "[423]\ttrain-rmse:0.25283\n",
      "[424]\ttrain-rmse:0.25274\n",
      "[425]\ttrain-rmse:0.25268\n",
      "[426]\ttrain-rmse:0.25261\n",
      "[427]\ttrain-rmse:0.25253\n",
      "[428]\ttrain-rmse:0.25248\n",
      "[429]\ttrain-rmse:0.25244\n",
      "[430]\ttrain-rmse:0.25238\n",
      "[431]\ttrain-rmse:0.25230\n",
      "[432]\ttrain-rmse:0.25227\n",
      "[433]\ttrain-rmse:0.25219\n",
      "[434]\ttrain-rmse:0.25211\n",
      "[435]\ttrain-rmse:0.25206\n",
      "[436]\ttrain-rmse:0.25198\n",
      "[437]\ttrain-rmse:0.25190\n",
      "[438]\ttrain-rmse:0.25181\n",
      "[439]\ttrain-rmse:0.25174\n",
      "[440]\ttrain-rmse:0.25169\n",
      "[441]\ttrain-rmse:0.25164\n",
      "[442]\ttrain-rmse:0.25156\n",
      "[443]\ttrain-rmse:0.25146\n",
      "[444]\ttrain-rmse:0.25141\n",
      "[445]\ttrain-rmse:0.25136\n",
      "[446]\ttrain-rmse:0.25124\n",
      "[447]\ttrain-rmse:0.25119\n",
      "[448]\ttrain-rmse:0.25114\n",
      "[449]\ttrain-rmse:0.25109\n",
      "[450]\ttrain-rmse:0.25099\n",
      "[451]\ttrain-rmse:0.25092\n",
      "[452]\ttrain-rmse:0.25084\n",
      "[453]\ttrain-rmse:0.25080\n",
      "[454]\ttrain-rmse:0.25075\n",
      "[455]\ttrain-rmse:0.25067\n",
      "[456]\ttrain-rmse:0.25063\n",
      "[457]\ttrain-rmse:0.25056\n",
      "[458]\ttrain-rmse:0.25051\n",
      "[459]\ttrain-rmse:0.25037\n",
      "[460]\ttrain-rmse:0.25032\n",
      "[461]\ttrain-rmse:0.25027\n",
      "[462]\ttrain-rmse:0.25022\n",
      "[463]\ttrain-rmse:0.25016\n",
      "[464]\ttrain-rmse:0.25005\n",
      "[465]\ttrain-rmse:0.24995\n",
      "[466]\ttrain-rmse:0.24985\n",
      "[467]\ttrain-rmse:0.24981\n",
      "[468]\ttrain-rmse:0.24976\n",
      "[469]\ttrain-rmse:0.24971\n",
      "[470]\ttrain-rmse:0.24964\n",
      "[471]\ttrain-rmse:0.24955\n",
      "[472]\ttrain-rmse:0.24947\n",
      "[473]\ttrain-rmse:0.24937\n",
      "[474]\ttrain-rmse:0.24926\n",
      "[475]\ttrain-rmse:0.24917\n",
      "[476]\ttrain-rmse:0.24910\n",
      "[477]\ttrain-rmse:0.24902\n",
      "[478]\ttrain-rmse:0.24889\n",
      "[479]\ttrain-rmse:0.24884\n",
      "[480]\ttrain-rmse:0.24876\n",
      "[481]\ttrain-rmse:0.24867\n",
      "[482]\ttrain-rmse:0.24857\n",
      "[483]\ttrain-rmse:0.24847\n",
      "[484]\ttrain-rmse:0.24842\n",
      "[485]\ttrain-rmse:0.24834\n",
      "[486]\ttrain-rmse:0.24825\n",
      "[487]\ttrain-rmse:0.24816\n",
      "[488]\ttrain-rmse:0.24810\n",
      "[489]\ttrain-rmse:0.24802\n",
      "[490]\ttrain-rmse:0.24795\n",
      "[491]\ttrain-rmse:0.24782\n",
      "[492]\ttrain-rmse:0.24775\n",
      "[493]\ttrain-rmse:0.24769\n",
      "[494]\ttrain-rmse:0.24757\n",
      "[495]\ttrain-rmse:0.24750\n",
      "[496]\ttrain-rmse:0.24745\n",
      "[497]\ttrain-rmse:0.24738\n",
      "[498]\ttrain-rmse:0.24733\n",
      "[499]\ttrain-rmse:0.24722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[11:13:36] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[11:13:36] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[11:13:36] task [xgboost.dask-2]:tcp://127.0.0.1:43763 got new rank 2\n",
      "[11:13:36] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28986\n",
      "[1]\ttrain-rmse:0.28973\n",
      "[2]\ttrain-rmse:0.28960\n",
      "[3]\ttrain-rmse:0.28948\n",
      "[4]\ttrain-rmse:0.28935\n",
      "[5]\ttrain-rmse:0.28921\n",
      "[6]\ttrain-rmse:0.28908\n",
      "[7]\ttrain-rmse:0.28895\n",
      "[8]\ttrain-rmse:0.28883\n",
      "[9]\ttrain-rmse:0.28869\n",
      "[10]\ttrain-rmse:0.28856\n",
      "[11]\ttrain-rmse:0.28845\n",
      "[12]\ttrain-rmse:0.28835\n",
      "[13]\ttrain-rmse:0.28821\n",
      "[14]\ttrain-rmse:0.28808\n",
      "[15]\ttrain-rmse:0.28797\n",
      "[16]\ttrain-rmse:0.28784\n",
      "[17]\ttrain-rmse:0.28774\n",
      "[18]\ttrain-rmse:0.28761\n",
      "[19]\ttrain-rmse:0.28749\n",
      "[20]\ttrain-rmse:0.28737\n",
      "[21]\ttrain-rmse:0.28724\n",
      "[22]\ttrain-rmse:0.28714\n",
      "[23]\ttrain-rmse:0.28702\n",
      "[24]\ttrain-rmse:0.28694\n",
      "[25]\ttrain-rmse:0.28681\n",
      "[26]\ttrain-rmse:0.28667\n",
      "[27]\ttrain-rmse:0.28654\n",
      "[28]\ttrain-rmse:0.28648\n",
      "[29]\ttrain-rmse:0.28634\n",
      "[30]\ttrain-rmse:0.28625\n",
      "[31]\ttrain-rmse:0.28613\n",
      "[32]\ttrain-rmse:0.28607\n",
      "[33]\ttrain-rmse:0.28596\n",
      "[34]\ttrain-rmse:0.28581\n",
      "[35]\ttrain-rmse:0.28568\n",
      "[36]\ttrain-rmse:0.28554\n",
      "[37]\ttrain-rmse:0.28546\n",
      "[38]\ttrain-rmse:0.28532\n",
      "[39]\ttrain-rmse:0.28525\n",
      "[40]\ttrain-rmse:0.28517\n",
      "[41]\ttrain-rmse:0.28504\n",
      "[42]\ttrain-rmse:0.28492\n",
      "[43]\ttrain-rmse:0.28484\n",
      "[44]\ttrain-rmse:0.28472\n",
      "[45]\ttrain-rmse:0.28463\n",
      "[46]\ttrain-rmse:0.28456\n",
      "[47]\ttrain-rmse:0.28440\n",
      "[48]\ttrain-rmse:0.28428\n",
      "[49]\ttrain-rmse:0.28416\n",
      "[50]\ttrain-rmse:0.28405\n",
      "[51]\ttrain-rmse:0.28396\n",
      "[52]\ttrain-rmse:0.28385\n",
      "[53]\ttrain-rmse:0.28376\n",
      "[54]\ttrain-rmse:0.28361\n",
      "[55]\ttrain-rmse:0.28350\n",
      "[56]\ttrain-rmse:0.28339\n",
      "[57]\ttrain-rmse:0.28330\n",
      "[58]\ttrain-rmse:0.28323\n",
      "[59]\ttrain-rmse:0.28315\n",
      "[60]\ttrain-rmse:0.28301\n",
      "[61]\ttrain-rmse:0.28292\n",
      "[62]\ttrain-rmse:0.28279\n",
      "[63]\ttrain-rmse:0.28264\n",
      "[64]\ttrain-rmse:0.28257\n",
      "[65]\ttrain-rmse:0.28242\n",
      "[66]\ttrain-rmse:0.28229\n",
      "[67]\ttrain-rmse:0.28217\n",
      "[68]\ttrain-rmse:0.28209\n",
      "[69]\ttrain-rmse:0.28201\n",
      "[70]\ttrain-rmse:0.28191\n",
      "[71]\ttrain-rmse:0.28182\n",
      "[72]\ttrain-rmse:0.28174\n",
      "[73]\ttrain-rmse:0.28160\n",
      "[74]\ttrain-rmse:0.28153\n",
      "[75]\ttrain-rmse:0.28142\n",
      "[76]\ttrain-rmse:0.28135\n",
      "[77]\ttrain-rmse:0.28125\n",
      "[78]\ttrain-rmse:0.28118\n",
      "[79]\ttrain-rmse:0.28110\n",
      "[80]\ttrain-rmse:0.28103\n",
      "[81]\ttrain-rmse:0.28089\n",
      "[82]\ttrain-rmse:0.28081\n",
      "[83]\ttrain-rmse:0.28069\n",
      "[84]\ttrain-rmse:0.28062\n",
      "[85]\ttrain-rmse:0.28054\n",
      "[86]\ttrain-rmse:0.28043\n",
      "[87]\ttrain-rmse:0.28036\n",
      "[88]\ttrain-rmse:0.28027\n",
      "[89]\ttrain-rmse:0.28015\n",
      "[90]\ttrain-rmse:0.28004\n",
      "[91]\ttrain-rmse:0.27996\n",
      "[92]\ttrain-rmse:0.27990\n",
      "[93]\ttrain-rmse:0.27981\n",
      "[94]\ttrain-rmse:0.27974\n",
      "[95]\ttrain-rmse:0.27965\n",
      "[96]\ttrain-rmse:0.27949\n",
      "[97]\ttrain-rmse:0.27936\n",
      "[98]\ttrain-rmse:0.27927\n",
      "[99]\ttrain-rmse:0.27920\n",
      "[100]\ttrain-rmse:0.27912\n",
      "[101]\ttrain-rmse:0.27905\n",
      "[102]\ttrain-rmse:0.27890\n",
      "[103]\ttrain-rmse:0.27883\n",
      "[104]\ttrain-rmse:0.27875\n",
      "[105]\ttrain-rmse:0.27864\n",
      "[106]\ttrain-rmse:0.27858\n",
      "[107]\ttrain-rmse:0.27845\n",
      "[108]\ttrain-rmse:0.27839\n",
      "[109]\ttrain-rmse:0.27832\n",
      "[110]\ttrain-rmse:0.27822\n",
      "[111]\ttrain-rmse:0.27816\n",
      "[112]\ttrain-rmse:0.27805\n",
      "[113]\ttrain-rmse:0.27796\n",
      "[114]\ttrain-rmse:0.27782\n",
      "[115]\ttrain-rmse:0.27774\n",
      "[116]\ttrain-rmse:0.27767\n",
      "[117]\ttrain-rmse:0.27755\n",
      "[118]\ttrain-rmse:0.27746\n",
      "[119]\ttrain-rmse:0.27738\n",
      "[120]\ttrain-rmse:0.27731\n",
      "[121]\ttrain-rmse:0.27720\n",
      "[122]\ttrain-rmse:0.27711\n",
      "[123]\ttrain-rmse:0.27699\n",
      "[124]\ttrain-rmse:0.27691\n",
      "[125]\ttrain-rmse:0.27683\n",
      "[126]\ttrain-rmse:0.27676\n",
      "[127]\ttrain-rmse:0.27669\n",
      "[128]\ttrain-rmse:0.27659\n",
      "[129]\ttrain-rmse:0.27651\n",
      "[130]\ttrain-rmse:0.27639\n",
      "[131]\ttrain-rmse:0.27630\n",
      "[132]\ttrain-rmse:0.27620\n",
      "[133]\ttrain-rmse:0.27613\n",
      "[134]\ttrain-rmse:0.27604\n",
      "[135]\ttrain-rmse:0.27596\n",
      "[136]\ttrain-rmse:0.27587\n",
      "[137]\ttrain-rmse:0.27580\n",
      "[138]\ttrain-rmse:0.27573\n",
      "[139]\ttrain-rmse:0.27562\n",
      "[140]\ttrain-rmse:0.27553\n",
      "[141]\ttrain-rmse:0.27547\n",
      "[142]\ttrain-rmse:0.27540\n",
      "[143]\ttrain-rmse:0.27532\n",
      "[144]\ttrain-rmse:0.27519\n",
      "[145]\ttrain-rmse:0.27513\n",
      "[146]\ttrain-rmse:0.27507\n",
      "[147]\ttrain-rmse:0.27494\n",
      "[148]\ttrain-rmse:0.27485\n",
      "[149]\ttrain-rmse:0.27480\n",
      "[150]\ttrain-rmse:0.27472\n",
      "[151]\ttrain-rmse:0.27468\n",
      "[152]\ttrain-rmse:0.27456\n",
      "[153]\ttrain-rmse:0.27450\n",
      "[154]\ttrain-rmse:0.27442\n",
      "[155]\ttrain-rmse:0.27429\n",
      "[156]\ttrain-rmse:0.27425\n",
      "[157]\ttrain-rmse:0.27419\n",
      "[158]\ttrain-rmse:0.27411\n",
      "[159]\ttrain-rmse:0.27400\n",
      "[160]\ttrain-rmse:0.27393\n",
      "[161]\ttrain-rmse:0.27382\n",
      "[162]\ttrain-rmse:0.27376\n",
      "[163]\ttrain-rmse:0.27372\n",
      "[164]\ttrain-rmse:0.27368\n",
      "[165]\ttrain-rmse:0.27357\n",
      "[166]\ttrain-rmse:0.27351\n",
      "[167]\ttrain-rmse:0.27344\n",
      "[168]\ttrain-rmse:0.27333\n",
      "[169]\ttrain-rmse:0.27327\n",
      "[170]\ttrain-rmse:0.27310\n",
      "[171]\ttrain-rmse:0.27306\n",
      "[172]\ttrain-rmse:0.27295\n",
      "[173]\ttrain-rmse:0.27283\n",
      "[174]\ttrain-rmse:0.27280\n",
      "[175]\ttrain-rmse:0.27276\n",
      "[176]\ttrain-rmse:0.27270\n",
      "[177]\ttrain-rmse:0.27253\n",
      "[178]\ttrain-rmse:0.27242\n",
      "[179]\ttrain-rmse:0.27236\n",
      "[180]\ttrain-rmse:0.27227\n",
      "[181]\ttrain-rmse:0.27217\n",
      "[182]\ttrain-rmse:0.27211\n",
      "[183]\ttrain-rmse:0.27202\n",
      "[184]\ttrain-rmse:0.27196\n",
      "[185]\ttrain-rmse:0.27179\n",
      "[186]\ttrain-rmse:0.27170\n",
      "[187]\ttrain-rmse:0.27158\n",
      "[188]\ttrain-rmse:0.27147\n",
      "[189]\ttrain-rmse:0.27144\n",
      "[190]\ttrain-rmse:0.27133\n",
      "[191]\ttrain-rmse:0.27127\n",
      "[192]\ttrain-rmse:0.27110\n",
      "[193]\ttrain-rmse:0.27100\n",
      "[194]\ttrain-rmse:0.27095\n",
      "[195]\ttrain-rmse:0.27089\n",
      "[196]\ttrain-rmse:0.27078\n",
      "[197]\ttrain-rmse:0.27071\n",
      "[198]\ttrain-rmse:0.27063\n",
      "[199]\ttrain-rmse:0.27060\n",
      "[200]\ttrain-rmse:0.27043\n",
      "[201]\ttrain-rmse:0.27033\n",
      "[202]\ttrain-rmse:0.27026\n",
      "[203]\ttrain-rmse:0.27022\n",
      "[204]\ttrain-rmse:0.27013\n",
      "[205]\ttrain-rmse:0.27008\n",
      "[206]\ttrain-rmse:0.26995\n",
      "[207]\ttrain-rmse:0.26991\n",
      "[208]\ttrain-rmse:0.26982\n",
      "[209]\ttrain-rmse:0.26976\n",
      "[210]\ttrain-rmse:0.26967\n",
      "[211]\ttrain-rmse:0.26960\n",
      "[212]\ttrain-rmse:0.26944\n",
      "[213]\ttrain-rmse:0.26935\n",
      "[214]\ttrain-rmse:0.26924\n",
      "[215]\ttrain-rmse:0.26917\n",
      "[216]\ttrain-rmse:0.26911\n",
      "[217]\ttrain-rmse:0.26899\n",
      "[218]\ttrain-rmse:0.26891\n",
      "[219]\ttrain-rmse:0.26888\n",
      "[220]\ttrain-rmse:0.26881\n",
      "[221]\ttrain-rmse:0.26868\n",
      "[222]\ttrain-rmse:0.26855\n",
      "[223]\ttrain-rmse:0.26844\n",
      "[224]\ttrain-rmse:0.26832\n",
      "[225]\ttrain-rmse:0.26828\n",
      "[226]\ttrain-rmse:0.26819\n",
      "[227]\ttrain-rmse:0.26806\n",
      "[228]\ttrain-rmse:0.26800\n",
      "[229]\ttrain-rmse:0.26790\n",
      "[230]\ttrain-rmse:0.26783\n",
      "[231]\ttrain-rmse:0.26770\n",
      "[232]\ttrain-rmse:0.26760\n",
      "[233]\ttrain-rmse:0.26756\n",
      "[234]\ttrain-rmse:0.26746\n",
      "[235]\ttrain-rmse:0.26728\n",
      "[236]\ttrain-rmse:0.26721\n",
      "[237]\ttrain-rmse:0.26710\n",
      "[238]\ttrain-rmse:0.26693\n",
      "[239]\ttrain-rmse:0.26684\n",
      "[240]\ttrain-rmse:0.26673\n",
      "[241]\ttrain-rmse:0.26663\n",
      "[242]\ttrain-rmse:0.26648\n",
      "[243]\ttrain-rmse:0.26640\n",
      "[244]\ttrain-rmse:0.26629\n",
      "[245]\ttrain-rmse:0.26624\n",
      "[246]\ttrain-rmse:0.26615\n",
      "[247]\ttrain-rmse:0.26610\n",
      "[248]\ttrain-rmse:0.26596\n",
      "[249]\ttrain-rmse:0.26591\n",
      "[250]\ttrain-rmse:0.26581\n",
      "[251]\ttrain-rmse:0.26564\n",
      "[252]\ttrain-rmse:0.26559\n",
      "[253]\ttrain-rmse:0.26552\n",
      "[254]\ttrain-rmse:0.26539\n",
      "[255]\ttrain-rmse:0.26530\n",
      "[256]\ttrain-rmse:0.26521\n",
      "[257]\ttrain-rmse:0.26508\n",
      "[258]\ttrain-rmse:0.26499\n",
      "[259]\ttrain-rmse:0.26484\n",
      "[260]\ttrain-rmse:0.26478\n",
      "[261]\ttrain-rmse:0.26475\n",
      "[262]\ttrain-rmse:0.26465\n",
      "[263]\ttrain-rmse:0.26459\n",
      "[264]\ttrain-rmse:0.26451\n",
      "[265]\ttrain-rmse:0.26442\n",
      "[266]\ttrain-rmse:0.26430\n",
      "[267]\ttrain-rmse:0.26424\n",
      "[268]\ttrain-rmse:0.26410\n",
      "[269]\ttrain-rmse:0.26399\n",
      "[270]\ttrain-rmse:0.26394\n",
      "[271]\ttrain-rmse:0.26387\n",
      "[272]\ttrain-rmse:0.26375\n",
      "[273]\ttrain-rmse:0.26370\n",
      "[274]\ttrain-rmse:0.26360\n",
      "[275]\ttrain-rmse:0.26347\n",
      "[276]\ttrain-rmse:0.26342\n",
      "[277]\ttrain-rmse:0.26327\n",
      "[278]\ttrain-rmse:0.26322\n",
      "[279]\ttrain-rmse:0.26310\n",
      "[280]\ttrain-rmse:0.26298\n",
      "[281]\ttrain-rmse:0.26292\n",
      "[282]\ttrain-rmse:0.26287\n",
      "[283]\ttrain-rmse:0.26281\n",
      "[284]\ttrain-rmse:0.26268\n",
      "[285]\ttrain-rmse:0.26255\n",
      "[286]\ttrain-rmse:0.26249\n",
      "[287]\ttrain-rmse:0.26237\n",
      "[288]\ttrain-rmse:0.26232\n",
      "[289]\ttrain-rmse:0.26227\n",
      "[290]\ttrain-rmse:0.26214\n",
      "[291]\ttrain-rmse:0.26204\n",
      "[292]\ttrain-rmse:0.26200\n",
      "[293]\ttrain-rmse:0.26189\n",
      "[294]\ttrain-rmse:0.26176\n",
      "[295]\ttrain-rmse:0.26170\n",
      "[296]\ttrain-rmse:0.26157\n",
      "[297]\ttrain-rmse:0.26148\n",
      "[298]\ttrain-rmse:0.26144\n",
      "[299]\ttrain-rmse:0.26133\n",
      "[300]\ttrain-rmse:0.26122\n",
      "[301]\ttrain-rmse:0.26111\n",
      "[302]\ttrain-rmse:0.26102\n",
      "[303]\ttrain-rmse:0.26099\n",
      "[304]\ttrain-rmse:0.26084\n",
      "[305]\ttrain-rmse:0.26078\n",
      "[306]\ttrain-rmse:0.26072\n",
      "[307]\ttrain-rmse:0.26062\n",
      "[308]\ttrain-rmse:0.26056\n",
      "[309]\ttrain-rmse:0.26045\n",
      "[310]\ttrain-rmse:0.26035\n",
      "[311]\ttrain-rmse:0.26023\n",
      "[312]\ttrain-rmse:0.26013\n",
      "[313]\ttrain-rmse:0.26000\n",
      "[314]\ttrain-rmse:0.25988\n",
      "[315]\ttrain-rmse:0.25978\n",
      "[316]\ttrain-rmse:0.25973\n",
      "[317]\ttrain-rmse:0.25970\n",
      "[318]\ttrain-rmse:0.25966\n",
      "[319]\ttrain-rmse:0.25956\n",
      "[320]\ttrain-rmse:0.25943\n",
      "[321]\ttrain-rmse:0.25929\n",
      "[322]\ttrain-rmse:0.25921\n",
      "[323]\ttrain-rmse:0.25909\n",
      "[324]\ttrain-rmse:0.25895\n",
      "[325]\ttrain-rmse:0.25884\n",
      "[326]\ttrain-rmse:0.25875\n",
      "[327]\ttrain-rmse:0.25864\n",
      "[328]\ttrain-rmse:0.25856\n",
      "[329]\ttrain-rmse:0.25850\n",
      "[330]\ttrain-rmse:0.25836\n",
      "[331]\ttrain-rmse:0.25825\n",
      "[332]\ttrain-rmse:0.25817\n",
      "[333]\ttrain-rmse:0.25807\n",
      "[334]\ttrain-rmse:0.25795\n",
      "[335]\ttrain-rmse:0.25789\n",
      "[336]\ttrain-rmse:0.25778\n",
      "[337]\ttrain-rmse:0.25773\n",
      "[338]\ttrain-rmse:0.25760\n",
      "[339]\ttrain-rmse:0.25757\n",
      "[340]\ttrain-rmse:0.25753\n",
      "[341]\ttrain-rmse:0.25746\n",
      "[342]\ttrain-rmse:0.25733\n",
      "[343]\ttrain-rmse:0.25722\n",
      "[344]\ttrain-rmse:0.25714\n",
      "[345]\ttrain-rmse:0.25710\n",
      "[346]\ttrain-rmse:0.25702\n",
      "[347]\ttrain-rmse:0.25693\n",
      "[348]\ttrain-rmse:0.25686\n",
      "[349]\ttrain-rmse:0.25681\n",
      "[350]\ttrain-rmse:0.25669\n",
      "[351]\ttrain-rmse:0.25664\n",
      "[352]\ttrain-rmse:0.25652\n",
      "[353]\ttrain-rmse:0.25647\n",
      "[354]\ttrain-rmse:0.25643\n",
      "[355]\ttrain-rmse:0.25629\n",
      "[356]\ttrain-rmse:0.25616\n",
      "[357]\ttrain-rmse:0.25605\n",
      "[358]\ttrain-rmse:0.25593\n",
      "[359]\ttrain-rmse:0.25587\n",
      "[360]\ttrain-rmse:0.25577\n",
      "[361]\ttrain-rmse:0.25565\n",
      "[362]\ttrain-rmse:0.25556\n",
      "[363]\ttrain-rmse:0.25545\n",
      "[364]\ttrain-rmse:0.25531\n",
      "[365]\ttrain-rmse:0.25527\n",
      "[366]\ttrain-rmse:0.25517\n",
      "[367]\ttrain-rmse:0.25505\n",
      "[368]\ttrain-rmse:0.25494\n",
      "[369]\ttrain-rmse:0.25480\n",
      "[370]\ttrain-rmse:0.25472\n",
      "[371]\ttrain-rmse:0.25460\n",
      "[372]\ttrain-rmse:0.25449\n",
      "[373]\ttrain-rmse:0.25441\n",
      "[374]\ttrain-rmse:0.25436\n",
      "[375]\ttrain-rmse:0.25421\n",
      "[376]\ttrain-rmse:0.25408\n",
      "[377]\ttrain-rmse:0.25403\n",
      "[378]\ttrain-rmse:0.25397\n",
      "[379]\ttrain-rmse:0.25384\n",
      "[380]\ttrain-rmse:0.25374\n",
      "[381]\ttrain-rmse:0.25362\n",
      "[382]\ttrain-rmse:0.25358\n",
      "[383]\ttrain-rmse:0.25347\n",
      "[384]\ttrain-rmse:0.25342\n",
      "[385]\ttrain-rmse:0.25329\n",
      "[386]\ttrain-rmse:0.25319\n",
      "[387]\ttrain-rmse:0.25315\n",
      "[388]\ttrain-rmse:0.25310\n",
      "[389]\ttrain-rmse:0.25298\n",
      "[390]\ttrain-rmse:0.25287\n",
      "[391]\ttrain-rmse:0.25283\n",
      "[392]\ttrain-rmse:0.25275\n",
      "[393]\ttrain-rmse:0.25272\n",
      "[394]\ttrain-rmse:0.25261\n",
      "[395]\ttrain-rmse:0.25253\n",
      "[396]\ttrain-rmse:0.25247\n",
      "[397]\ttrain-rmse:0.25237\n",
      "[398]\ttrain-rmse:0.25229\n",
      "[399]\ttrain-rmse:0.25224\n",
      "[400]\ttrain-rmse:0.25215\n",
      "[401]\ttrain-rmse:0.25205\n",
      "[402]\ttrain-rmse:0.25195\n",
      "[403]\ttrain-rmse:0.25188\n",
      "[404]\ttrain-rmse:0.25185\n",
      "[405]\ttrain-rmse:0.25173\n",
      "[406]\ttrain-rmse:0.25164\n",
      "[407]\ttrain-rmse:0.25158\n",
      "[408]\ttrain-rmse:0.25147\n",
      "[409]\ttrain-rmse:0.25140\n",
      "[410]\ttrain-rmse:0.25130\n",
      "[411]\ttrain-rmse:0.25126\n",
      "[412]\ttrain-rmse:0.25115\n",
      "[413]\ttrain-rmse:0.25107\n",
      "[414]\ttrain-rmse:0.25101\n",
      "[415]\ttrain-rmse:0.25094\n",
      "[416]\ttrain-rmse:0.25085\n",
      "[417]\ttrain-rmse:0.25075\n",
      "[418]\ttrain-rmse:0.25069\n",
      "[419]\ttrain-rmse:0.25057\n",
      "[420]\ttrain-rmse:0.25048\n",
      "[421]\ttrain-rmse:0.25039\n",
      "[422]\ttrain-rmse:0.25030\n",
      "[423]\ttrain-rmse:0.25022\n",
      "[424]\ttrain-rmse:0.25014\n",
      "[425]\ttrain-rmse:0.25006\n",
      "[426]\ttrain-rmse:0.24997\n",
      "[427]\ttrain-rmse:0.24991\n",
      "[428]\ttrain-rmse:0.24980\n",
      "[429]\ttrain-rmse:0.24975\n",
      "[430]\ttrain-rmse:0.24970\n",
      "[431]\ttrain-rmse:0.24956\n",
      "[432]\ttrain-rmse:0.24950\n",
      "[433]\ttrain-rmse:0.24945\n",
      "[434]\ttrain-rmse:0.24936\n",
      "[435]\ttrain-rmse:0.24927\n",
      "[436]\ttrain-rmse:0.24919\n",
      "[437]\ttrain-rmse:0.24906\n",
      "[438]\ttrain-rmse:0.24896\n",
      "[439]\ttrain-rmse:0.24887\n",
      "[440]\ttrain-rmse:0.24881\n",
      "[441]\ttrain-rmse:0.24866\n",
      "[442]\ttrain-rmse:0.24857\n",
      "[443]\ttrain-rmse:0.24849\n",
      "[444]\ttrain-rmse:0.24843\n",
      "[445]\ttrain-rmse:0.24833\n",
      "[446]\ttrain-rmse:0.24823\n",
      "[447]\ttrain-rmse:0.24815\n",
      "[448]\ttrain-rmse:0.24806\n",
      "[449]\ttrain-rmse:0.24801\n",
      "[450]\ttrain-rmse:0.24790\n",
      "[451]\ttrain-rmse:0.24782\n",
      "[452]\ttrain-rmse:0.24773\n",
      "[453]\ttrain-rmse:0.24762\n",
      "[454]\ttrain-rmse:0.24754\n",
      "[455]\ttrain-rmse:0.24748\n",
      "[456]\ttrain-rmse:0.24745\n",
      "[457]\ttrain-rmse:0.24738\n",
      "[458]\ttrain-rmse:0.24725\n",
      "[459]\ttrain-rmse:0.24710\n",
      "[460]\ttrain-rmse:0.24702\n",
      "[461]\ttrain-rmse:0.24696\n",
      "[462]\ttrain-rmse:0.24693\n",
      "[463]\ttrain-rmse:0.24685\n",
      "[464]\ttrain-rmse:0.24672\n",
      "[465]\ttrain-rmse:0.24662\n",
      "[466]\ttrain-rmse:0.24649\n",
      "[467]\ttrain-rmse:0.24640\n",
      "[468]\ttrain-rmse:0.24633\n",
      "[469]\ttrain-rmse:0.24630\n",
      "[470]\ttrain-rmse:0.24624\n",
      "[471]\ttrain-rmse:0.24618\n",
      "[472]\ttrain-rmse:0.24606\n",
      "[473]\ttrain-rmse:0.24601\n",
      "[474]\ttrain-rmse:0.24594\n",
      "[475]\ttrain-rmse:0.24582\n",
      "[476]\ttrain-rmse:0.24576\n",
      "[477]\ttrain-rmse:0.24562\n",
      "[478]\ttrain-rmse:0.24559\n",
      "[479]\ttrain-rmse:0.24550\n",
      "[480]\ttrain-rmse:0.24544\n",
      "[481]\ttrain-rmse:0.24541\n",
      "[482]\ttrain-rmse:0.24535\n",
      "[483]\ttrain-rmse:0.24523\n",
      "[484]\ttrain-rmse:0.24519\n",
      "[485]\ttrain-rmse:0.24506\n",
      "[486]\ttrain-rmse:0.24492\n",
      "[487]\ttrain-rmse:0.24487\n",
      "[488]\ttrain-rmse:0.24480\n",
      "[489]\ttrain-rmse:0.24468\n",
      "[490]\ttrain-rmse:0.24465\n",
      "[491]\ttrain-rmse:0.24453\n",
      "[492]\ttrain-rmse:0.24445\n",
      "[493]\ttrain-rmse:0.24437\n",
      "[494]\ttrain-rmse:0.24431\n",
      "[495]\ttrain-rmse:0.24420\n",
      "[496]\ttrain-rmse:0.24407\n",
      "[497]\ttrain-rmse:0.24400\n",
      "[498]\ttrain-rmse:0.24394\n",
      "[499]\ttrain-rmse:0.24389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "result_tain_list = []\n",
    "result_test_list = []\n",
    "\n",
    "\n",
    "param = {\"verbosity\": 0, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\",\n",
    "                         \"max_depth\": \"10\", \"learning_rate\": 0.01, \"max_bin\": 256 }\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_base, y_base):\n",
    "    X_train, y_train = X_base[train_idx], y_base[train_idx]\n",
    "    X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "    dtrain = xgb.dask.DaskDMatrix(client, X_train, y_train)\n",
    "    dtest = xgb.dask.DaskDMatrix(client, X_test, y_test)\n",
    "\n",
    "    best_model = xgb.dask.train(\n",
    "        client,\n",
    "        param, \n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        # early_stopping_rounds=50, \n",
    "        evals=[(dtrain, \"train\")],\n",
    "    )\n",
    "    \n",
    "    # booster = output[\"booster\"]\n",
    "    # print(booster.best_iteration)\n",
    "    # best_model = booster[: booster.best_iteration]\n",
    "    train_preds = xgb.dask.predict(client, best_model, dtrain)\n",
    "    test_preds = xgb.dask.predict(client, best_model, dtest)\n",
    "\n",
    "    result_tain_list.append(mean_squared_error(train_preds, y_train))\n",
    "    result_test_list.append(mean_squared_error(test_preds, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abfe3a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN..... 0.060298736358880174\n",
      "MEAN TEST..... 0.08494893198384584\n",
      "TRAIN-TEST DIFF..... 0.02465019562496567\n",
      "HOLDOUT .....  0.0830387511983989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "holdout_pred = xgb.dask.predict(client, best_model, X_holdout)\n",
    "\n",
    "train_test_diff = np.abs(np.mean(result_tain_list) - np.mean(result_test_list))       \n",
    "\n",
    "print('MEAN TRAIN.....', np.mean(result_tain_list))\n",
    "print('MEAN TEST.....', np.mean(result_test_list))\n",
    "print('TRAIN-TEST DIFF.....', train_test_diff)\n",
    "print('HOLDOUT ..... ', mean_squared_error(holdout_pred, y_holdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e467b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local dask client created: localhost:8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[11:57:35] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[11:57:35] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[11:57:35] task [xgboost.dask-2]:tcp://127.0.0.1:43763 got new rank 2\n",
      "[11:57:35] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28932\n",
      "[1]\ttrain-rmse:0.28919\n",
      "[2]\ttrain-rmse:0.28907\n",
      "[3]\ttrain-rmse:0.28896\n",
      "[4]\ttrain-rmse:0.28885\n",
      "[5]\ttrain-rmse:0.28873\n",
      "[6]\ttrain-rmse:0.28862\n",
      "[7]\ttrain-rmse:0.28852\n",
      "[8]\ttrain-rmse:0.28843\n",
      "[9]\ttrain-rmse:0.28831\n",
      "[10]\ttrain-rmse:0.28821\n",
      "[11]\ttrain-rmse:0.28811\n",
      "[12]\ttrain-rmse:0.28800\n",
      "[13]\ttrain-rmse:0.28790\n",
      "[14]\ttrain-rmse:0.28777\n",
      "[15]\ttrain-rmse:0.28767\n",
      "[16]\ttrain-rmse:0.28757\n",
      "[17]\ttrain-rmse:0.28748\n",
      "[18]\ttrain-rmse:0.28737\n",
      "[19]\ttrain-rmse:0.28728\n",
      "[20]\ttrain-rmse:0.28718\n",
      "[21]\ttrain-rmse:0.28710\n",
      "[22]\ttrain-rmse:0.28700\n",
      "[23]\ttrain-rmse:0.28690\n",
      "[24]\ttrain-rmse:0.28678\n",
      "[25]\ttrain-rmse:0.28669\n",
      "[26]\ttrain-rmse:0.28659\n",
      "[27]\ttrain-rmse:0.28647\n",
      "[28]\ttrain-rmse:0.28637\n",
      "[29]\ttrain-rmse:0.28625\n",
      "[30]\ttrain-rmse:0.28617\n",
      "[31]\ttrain-rmse:0.28606\n",
      "[32]\ttrain-rmse:0.28595\n",
      "[33]\ttrain-rmse:0.28585\n",
      "[34]\ttrain-rmse:0.28574\n",
      "[35]\ttrain-rmse:0.28563\n",
      "[36]\ttrain-rmse:0.28555\n",
      "[37]\ttrain-rmse:0.28543\n",
      "[38]\ttrain-rmse:0.28534\n",
      "[39]\ttrain-rmse:0.28527\n",
      "[40]\ttrain-rmse:0.28518\n",
      "[41]\ttrain-rmse:0.28511\n",
      "[42]\ttrain-rmse:0.28500\n",
      "[43]\ttrain-rmse:0.28490\n",
      "[44]\ttrain-rmse:0.28480\n",
      "[45]\ttrain-rmse:0.28472\n",
      "[46]\ttrain-rmse:0.28464\n",
      "[47]\ttrain-rmse:0.28457\n",
      "[48]\ttrain-rmse:0.28448\n",
      "[49]\ttrain-rmse:0.28440\n",
      "[50]\ttrain-rmse:0.28428\n",
      "[51]\ttrain-rmse:0.28418\n",
      "[52]\ttrain-rmse:0.28406\n",
      "[53]\ttrain-rmse:0.28397\n",
      "[54]\ttrain-rmse:0.28386\n",
      "[55]\ttrain-rmse:0.28379\n",
      "[56]\ttrain-rmse:0.28368\n",
      "[57]\ttrain-rmse:0.28356\n",
      "[58]\ttrain-rmse:0.28347\n",
      "[59]\ttrain-rmse:0.28336\n",
      "[60]\ttrain-rmse:0.28328\n",
      "[61]\ttrain-rmse:0.28316\n",
      "[62]\ttrain-rmse:0.28308\n",
      "[63]\ttrain-rmse:0.28301\n",
      "[64]\ttrain-rmse:0.28285\n",
      "[65]\ttrain-rmse:0.28278\n",
      "[66]\ttrain-rmse:0.28262\n",
      "[67]\ttrain-rmse:0.28255\n",
      "[68]\ttrain-rmse:0.28244\n",
      "[69]\ttrain-rmse:0.28236\n",
      "[70]\ttrain-rmse:0.28228\n",
      "[71]\ttrain-rmse:0.28213\n",
      "[72]\ttrain-rmse:0.28207\n",
      "[73]\ttrain-rmse:0.28198\n",
      "[74]\ttrain-rmse:0.28183\n",
      "[75]\ttrain-rmse:0.28175\n",
      "[76]\ttrain-rmse:0.28167\n",
      "[77]\ttrain-rmse:0.28159\n",
      "[78]\ttrain-rmse:0.28151\n",
      "[79]\ttrain-rmse:0.28142\n",
      "[80]\ttrain-rmse:0.28134\n",
      "[81]\ttrain-rmse:0.28127\n",
      "[82]\ttrain-rmse:0.28120\n",
      "[83]\ttrain-rmse:0.28106\n",
      "[84]\ttrain-rmse:0.28098\n",
      "[85]\ttrain-rmse:0.28089\n",
      "[86]\ttrain-rmse:0.28082\n",
      "[87]\ttrain-rmse:0.28068\n",
      "[88]\ttrain-rmse:0.28061\n",
      "[89]\ttrain-rmse:0.28053\n",
      "[90]\ttrain-rmse:0.28046\n",
      "[91]\ttrain-rmse:0.28034\n",
      "[92]\ttrain-rmse:0.28027\n",
      "[93]\ttrain-rmse:0.28013\n",
      "[94]\ttrain-rmse:0.28006\n",
      "[95]\ttrain-rmse:0.27996\n",
      "[96]\ttrain-rmse:0.27989\n",
      "[97]\ttrain-rmse:0.27979\n",
      "[98]\ttrain-rmse:0.27966\n",
      "[99]\ttrain-rmse:0.27958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[11:58:00] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[11:58:00] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[11:58:00] task [xgboost.dask-2]:tcp://127.0.0.1:43763 got new rank 2\n",
      "[11:58:00] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28956\n",
      "[1]\ttrain-rmse:0.28945\n",
      "[2]\ttrain-rmse:0.28934\n",
      "[3]\ttrain-rmse:0.28924\n",
      "[4]\ttrain-rmse:0.28914\n",
      "[5]\ttrain-rmse:0.28903\n",
      "[6]\ttrain-rmse:0.28893\n",
      "[7]\ttrain-rmse:0.28882\n",
      "[8]\ttrain-rmse:0.28872\n",
      "[9]\ttrain-rmse:0.28863\n",
      "[10]\ttrain-rmse:0.28853\n",
      "[11]\ttrain-rmse:0.28843\n",
      "[12]\ttrain-rmse:0.28833\n",
      "[13]\ttrain-rmse:0.28823\n",
      "[14]\ttrain-rmse:0.28809\n",
      "[15]\ttrain-rmse:0.28800\n",
      "[16]\ttrain-rmse:0.28787\n",
      "[17]\ttrain-rmse:0.28775\n",
      "[18]\ttrain-rmse:0.28765\n",
      "[19]\ttrain-rmse:0.28752\n",
      "[20]\ttrain-rmse:0.28743\n",
      "[21]\ttrain-rmse:0.28732\n",
      "[22]\ttrain-rmse:0.28723\n",
      "[23]\ttrain-rmse:0.28709\n",
      "[24]\ttrain-rmse:0.28699\n",
      "[25]\ttrain-rmse:0.28690\n",
      "[26]\ttrain-rmse:0.28681\n",
      "[27]\ttrain-rmse:0.28673\n",
      "[28]\ttrain-rmse:0.28658\n",
      "[29]\ttrain-rmse:0.28650\n",
      "[30]\ttrain-rmse:0.28639\n",
      "[31]\ttrain-rmse:0.28629\n",
      "[32]\ttrain-rmse:0.28615\n",
      "[33]\ttrain-rmse:0.28606\n",
      "[34]\ttrain-rmse:0.28594\n",
      "[35]\ttrain-rmse:0.28585\n",
      "[36]\ttrain-rmse:0.28577\n",
      "[37]\ttrain-rmse:0.28563\n",
      "[38]\ttrain-rmse:0.28553\n",
      "[39]\ttrain-rmse:0.28544\n",
      "[40]\ttrain-rmse:0.28536\n",
      "[41]\ttrain-rmse:0.28528\n",
      "[42]\ttrain-rmse:0.28521\n",
      "[43]\ttrain-rmse:0.28514\n",
      "[44]\ttrain-rmse:0.28506\n",
      "[45]\ttrain-rmse:0.28498\n",
      "[46]\ttrain-rmse:0.28484\n",
      "[47]\ttrain-rmse:0.28476\n",
      "[48]\ttrain-rmse:0.28469\n",
      "[49]\ttrain-rmse:0.28461\n",
      "[50]\ttrain-rmse:0.28453\n",
      "[51]\ttrain-rmse:0.28445\n",
      "[52]\ttrain-rmse:0.28437\n",
      "[53]\ttrain-rmse:0.28429\n",
      "[54]\ttrain-rmse:0.28421\n",
      "[55]\ttrain-rmse:0.28407\n",
      "[56]\ttrain-rmse:0.28398\n",
      "[57]\ttrain-rmse:0.28391\n",
      "[58]\ttrain-rmse:0.28384\n",
      "[59]\ttrain-rmse:0.28378\n",
      "[60]\ttrain-rmse:0.28369\n",
      "[61]\ttrain-rmse:0.28362\n",
      "[62]\ttrain-rmse:0.28354\n",
      "[63]\ttrain-rmse:0.28347\n",
      "[64]\ttrain-rmse:0.28337\n",
      "[65]\ttrain-rmse:0.28328\n",
      "[66]\ttrain-rmse:0.28320\n",
      "[67]\ttrain-rmse:0.28309\n",
      "[68]\ttrain-rmse:0.28300\n",
      "[69]\ttrain-rmse:0.28289\n",
      "[70]\ttrain-rmse:0.28282\n",
      "[71]\ttrain-rmse:0.28270\n",
      "[72]\ttrain-rmse:0.28263\n",
      "[73]\ttrain-rmse:0.28257\n",
      "[74]\ttrain-rmse:0.28247\n",
      "[75]\ttrain-rmse:0.28236\n",
      "[76]\ttrain-rmse:0.28229\n",
      "[77]\ttrain-rmse:0.28222\n",
      "[78]\ttrain-rmse:0.28212\n",
      "[79]\ttrain-rmse:0.28205\n",
      "[80]\ttrain-rmse:0.28193\n",
      "[81]\ttrain-rmse:0.28187\n",
      "[82]\ttrain-rmse:0.28180\n",
      "[83]\ttrain-rmse:0.28173\n",
      "[84]\ttrain-rmse:0.28159\n",
      "[85]\ttrain-rmse:0.28142\n",
      "[86]\ttrain-rmse:0.28127\n",
      "[87]\ttrain-rmse:0.28111\n",
      "[88]\ttrain-rmse:0.28106\n",
      "[89]\ttrain-rmse:0.28099\n",
      "[90]\ttrain-rmse:0.28092\n",
      "[91]\ttrain-rmse:0.28078\n",
      "[92]\ttrain-rmse:0.28071\n",
      "[93]\ttrain-rmse:0.28059\n",
      "[94]\ttrain-rmse:0.28043\n",
      "[95]\ttrain-rmse:0.28031\n",
      "[96]\ttrain-rmse:0.28012\n",
      "[97]\ttrain-rmse:0.28000\n",
      "[98]\ttrain-rmse:0.27981\n",
      "[99]\ttrain-rmse:0.27969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda3/envs/test/lib/python3.8/site-packages/xgboost/dask.py:855: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[11:58:21] task [xgboost.dask-0]:tcp://127.0.0.1:40007 got new rank 0\n",
      "[11:58:21] task [xgboost.dask-1]:tcp://127.0.0.1:44045 got new rank 1\n",
      "[11:58:21] task [xgboost.dask-2]:tcp://127.0.0.1:43763 got new rank 2\n",
      "[11:58:21] task [xgboost.dask-3]:tcp://127.0.0.1:38021 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.28985\n",
      "[1]\ttrain-rmse:0.28971\n",
      "[2]\ttrain-rmse:0.28958\n",
      "[3]\ttrain-rmse:0.28945\n",
      "[4]\ttrain-rmse:0.28932\n",
      "[5]\ttrain-rmse:0.28919\n",
      "[6]\ttrain-rmse:0.28905\n",
      "[7]\ttrain-rmse:0.28891\n",
      "[8]\ttrain-rmse:0.28877\n",
      "[9]\ttrain-rmse:0.28865\n",
      "[10]\ttrain-rmse:0.28855\n",
      "[11]\ttrain-rmse:0.28841\n",
      "[12]\ttrain-rmse:0.28831\n",
      "[13]\ttrain-rmse:0.28818\n",
      "[14]\ttrain-rmse:0.28808\n",
      "[15]\ttrain-rmse:0.28800\n",
      "[16]\ttrain-rmse:0.28786\n",
      "[17]\ttrain-rmse:0.28775\n",
      "[18]\ttrain-rmse:0.28766\n",
      "[19]\ttrain-rmse:0.28752\n",
      "[20]\ttrain-rmse:0.28740\n",
      "[21]\ttrain-rmse:0.28732\n",
      "[22]\ttrain-rmse:0.28720\n",
      "[23]\ttrain-rmse:0.28713\n",
      "[24]\ttrain-rmse:0.28702\n",
      "[25]\ttrain-rmse:0.28690\n",
      "[26]\ttrain-rmse:0.28681\n",
      "[27]\ttrain-rmse:0.28669\n",
      "[28]\ttrain-rmse:0.28661\n",
      "[29]\ttrain-rmse:0.28647\n",
      "[30]\ttrain-rmse:0.28635\n",
      "[31]\ttrain-rmse:0.28627\n",
      "[32]\ttrain-rmse:0.28618\n",
      "[33]\ttrain-rmse:0.28605\n",
      "[34]\ttrain-rmse:0.28597\n",
      "[35]\ttrain-rmse:0.28585\n",
      "[36]\ttrain-rmse:0.28578\n",
      "[37]\ttrain-rmse:0.28564\n",
      "[38]\ttrain-rmse:0.28551\n",
      "[39]\ttrain-rmse:0.28538\n",
      "[40]\ttrain-rmse:0.28524\n",
      "[41]\ttrain-rmse:0.28513\n",
      "[42]\ttrain-rmse:0.28502\n",
      "[43]\ttrain-rmse:0.28489\n",
      "[44]\ttrain-rmse:0.28482\n",
      "[45]\ttrain-rmse:0.28469\n",
      "[46]\ttrain-rmse:0.28462\n",
      "[47]\ttrain-rmse:0.28448\n",
      "[48]\ttrain-rmse:0.28436\n",
      "[49]\ttrain-rmse:0.28422\n",
      "[50]\ttrain-rmse:0.28409\n",
      "[51]\ttrain-rmse:0.28397\n",
      "[52]\ttrain-rmse:0.28387\n",
      "[53]\ttrain-rmse:0.28375\n",
      "[54]\ttrain-rmse:0.28367\n",
      "[55]\ttrain-rmse:0.28359\n",
      "[56]\ttrain-rmse:0.28347\n",
      "[57]\ttrain-rmse:0.28334\n",
      "[58]\ttrain-rmse:0.28321\n",
      "[59]\ttrain-rmse:0.28310\n",
      "[60]\ttrain-rmse:0.28299\n",
      "[61]\ttrain-rmse:0.28292\n",
      "[62]\ttrain-rmse:0.28282\n",
      "[63]\ttrain-rmse:0.28269\n",
      "[64]\ttrain-rmse:0.28260\n",
      "[65]\ttrain-rmse:0.28252\n",
      "[66]\ttrain-rmse:0.28241\n",
      "[67]\ttrain-rmse:0.28231\n",
      "[68]\ttrain-rmse:0.28219\n",
      "[69]\ttrain-rmse:0.28213\n",
      "[70]\ttrain-rmse:0.28201\n",
      "[71]\ttrain-rmse:0.28196\n",
      "[72]\ttrain-rmse:0.28187\n",
      "[73]\ttrain-rmse:0.28180\n",
      "[74]\ttrain-rmse:0.28172\n",
      "[75]\ttrain-rmse:0.28161\n",
      "[76]\ttrain-rmse:0.28152\n",
      "[77]\ttrain-rmse:0.28144\n",
      "[78]\ttrain-rmse:0.28136\n",
      "[79]\ttrain-rmse:0.28126\n",
      "[80]\ttrain-rmse:0.28115\n",
      "[81]\ttrain-rmse:0.28103\n",
      "[82]\ttrain-rmse:0.28095\n",
      "[83]\ttrain-rmse:0.28087\n",
      "[84]\ttrain-rmse:0.28077\n",
      "[85]\ttrain-rmse:0.28070\n",
      "[86]\ttrain-rmse:0.28064\n",
      "[87]\ttrain-rmse:0.28051\n",
      "[88]\ttrain-rmse:0.28040\n",
      "[89]\ttrain-rmse:0.28034\n",
      "[90]\ttrain-rmse:0.28029\n",
      "[91]\ttrain-rmse:0.28014\n",
      "[92]\ttrain-rmse:0.28000\n",
      "[93]\ttrain-rmse:0.27988\n",
      "[94]\ttrain-rmse:0.27982\n",
      "[95]\ttrain-rmse:0.27966\n",
      "[96]\ttrain-rmse:0.27959\n",
      "[97]\ttrain-rmse:0.27946\n",
      "[98]\ttrain-rmse:0.27941\n",
      "[99]\ttrain-rmse:0.27932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "\n",
    "\n",
    "client = dasker.get_dask_client()\n",
    "print(f'Local dask client created: localhost:{util_config.dask_local_scheduler_port}')\n",
    "\n",
    "cv = KFold(n_splits=3, random_state=None, shuffle=False)\n",
    "\n",
    "briskmodels = BriskXGBoost(client, cv, logger = None, pred_type = 'regression')\n",
    "res = briskmodels.fit(X,y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93d940f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_train_err': 0.07813503569086387,\n",
       " 'mean_test_err': 0.0841429247638892,\n",
       " 'train_test_err_diff': 0.006007889073025324,\n",
       " 'holdout_err': 0.08260488788395538}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df6adf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"verbosity\": 0, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\",\n",
    "                         \"max_depth\": \"10\", \"learning_rate\": 0.01, \"max_bin\": 256, \"num_boost_round\" : 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3102459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class BriskXGBoost():\n",
    "    def __init__(self, client, cv, logger, pred_type) -> None:\n",
    "        self.client = client \n",
    "        self.cv = cv\n",
    "        self.logger = logger\n",
    "        self.mean_train_error = None\n",
    "        self.mean_test_error = None\n",
    "        self.holdout_error = None\n",
    "        self.pred_type = pred_type\n",
    "        self.model = None\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        result_tain_list = []\n",
    "        result_test_list = []\n",
    "\n",
    "        X_base, X_holdout, y_base, y_holdout = train_test_split(X, y, \n",
    "                                                                                                                                    random_state=config.rand_state)\n",
    "\n",
    "        for train_idx, test_idx in cv.split(X_base, y_base):\n",
    "            X_train, y_train = X_base[train_idx], y_base[train_idx]\n",
    "            X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "            dtrain = xgb.dask.DaskDMatrix(client, X_train, y_train)\n",
    "            dtest = xgb.dask.DaskDMatrix(client, X_test, y_test)\n",
    "\n",
    "            trained_model = xgb.dask.train(\n",
    "                client,\n",
    "                param, \n",
    "                dtrain,\n",
    "                num_boost_round=param[\"num_boost_round\"],\n",
    "                # early_stopping_rounds=50, \n",
    "                evals=[(dtrain, \"train\")],\n",
    "            )\n",
    "            \n",
    "            # booster = output[\"booster\"]\n",
    "            # print(booster.best_iteration)\n",
    "            # best_model = booster[: booster.best_iteration]\n",
    "            train_preds = xgb.dask.predict(client, trained_model, dtrain)\n",
    "            test_preds = xgb.dask.predict(client, trained_model, dtest)\n",
    "\n",
    "            if self.pred_type == 'classification': \n",
    "                result_tain_list = -1\n",
    "                result_test_list = -1\n",
    "            else:\n",
    "                result_tain_list.append(mean_squared_error(train_preds, y_train))\n",
    "                result_test_list.append(mean_squared_error(test_preds, y_test))\n",
    "\n",
    "        \n",
    "        \n",
    "        self.mean_train_err = np.mean(result_tain_list)\n",
    "        self.mean_test_err = np.mean(result_test_list)\n",
    "        self.train_test_err_diff = np.abs(self.mean_train_err - self.mean_test_err)\n",
    "\n",
    "\n",
    "        holdout_pred = xgb.dask.predict(client, trained_model, X_holdout)\n",
    "\n",
    "        if self.pred_type == 'classification': \n",
    "            self.holdout_err = -1\n",
    "        else:\n",
    "            self.holdout_err = mean_squared_error(holdout_pred, y_holdout)    \n",
    "\n",
    "\n",
    "        self.model = trained_model\n",
    "\n",
    "        return {\n",
    "            \"mean_train_err\": self.mean_train_err,\n",
    "            \"mean_test_err\": self.mean_test_err,\n",
    "            \"train_test_err_diff\": self.train_test_err_diff,\n",
    "            \"holdout_err\": self.holdout_err\n",
    "        }\n",
    "\n",
    "\n",
    "    def get_result_stats(self):\n",
    "\n",
    "        return {\n",
    "            \"mean_train_err\": self.mean_train_err,\n",
    "            \"mean_test_err\": self.mean_test_err,\n",
    "            \"train_test_err_diff\": self.train_test_err_diff,\n",
    "            \"holdout_err\": self.holdout_err\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f84a8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aac93934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x7efbc938c220>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d74b34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = xgb.dask.predict(client, best_model, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e9a7908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 117.19 kiB </td>\n",
       "                        <td> 3.52 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (30000,) </td>\n",
       "                        <td> (900,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 69 Graph Layers </td>\n",
       "                        <td> 34 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"1\" y1=\"0\" x2=\"1\" y2=\"25\" />\n",
       "  <line x1=\"8\" y1=\"0\" x2=\"8\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"25\" />\n",
       "  <line x1=\"33\" y1=\"0\" x2=\"33\" y2=\"25\" />\n",
       "  <line x1=\"40\" y1=\"0\" x2=\"40\" y2=\"25\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
       "  <line x1=\"55\" y1=\"0\" x2=\"55\" y2=\"25\" />\n",
       "  <line x1=\"58\" y1=\"0\" x2=\"58\" y2=\"25\" />\n",
       "  <line x1=\"66\" y1=\"0\" x2=\"66\" y2=\"25\" />\n",
       "  <line x1=\"73\" y1=\"0\" x2=\"73\" y2=\"25\" />\n",
       "  <line x1=\"80\" y1=\"0\" x2=\"80\" y2=\"25\" />\n",
       "  <line x1=\"87\" y1=\"0\" x2=\"87\" y2=\"25\" />\n",
       "  <line x1=\"91\" y1=\"0\" x2=\"91\" y2=\"25\" />\n",
       "  <line x1=\"98\" y1=\"0\" x2=\"98\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >30000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<concatenate, shape=(30000,), dtype=float32, chunksize=(900,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37214cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_base, X_holdout, y_base, y_holdout = train_test_split(\n",
    "    X, y, random_state=config.rand_state)\n",
    "\n",
    "split_scores_ = []\n",
    "holdout_scores_ = []\n",
    "estimators_ = []            \n",
    "\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_base, y_base):\n",
    "    \n",
    "\n",
    "    # print(test_idx)\n",
    "\n",
    "    X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "    X_train, y_train = X_base.loc[X_base.index[train_idx]], y_base.loc[y_base.index[train_idx]]\n",
    "\n",
    "\n",
    "    # X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "    # X_train, y_train = X_base[train_idx], y_base[train_idx]\n",
    "\n",
    "    estimator_ = clone(self.estimator)\n",
    "    estimator_.fit(X_train, y_train, **fit_kws)\n",
    "\n",
    "    self.logger.info(\"... log things ...\")\n",
    "    self.estimators_.append(estimator_)\n",
    "    self.split_scores_.append(estimator_.score(X_test, y_test))            \n",
    "    self.holdout_scores_.append(\n",
    "        estimator_.score(X_holdout, y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f804c2a-3805-4a1a-9d2d-8bd7a0b0bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "class CustomCrossVal(BaseEstimator):\n",
    "    def __init__(self, client, estimator, cv, logger):\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.logger = logger\n",
    "        self.client = client\n",
    "    \n",
    "\n",
    "    def fit(self, X, y, **fit_kws):\n",
    "\n",
    "\n",
    "\n",
    "        X_base, X_holdout, y_base, y_holdout = train_test_split(X, y, \n",
    "                                                                                                                                    random_state=config.rand_state)\n",
    "\n",
    "        \n",
    "        self.split_scores_ = []\n",
    "        self.holdout_scores_ = []\n",
    "        self.estimators_ = []            \n",
    "        \n",
    "\n",
    "        result_tain_list = []\n",
    "        result_test_list = []\n",
    "\n",
    "\n",
    "        param = {\"verbosity\": 0, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\",\n",
    "                                \"max_depth\": \"10\", \"learning_rate\": 0.01, \"max_bin\": 256 }\n",
    "\n",
    "\n",
    "        for train_idx, test_idx in cv.split(X_base, y_base):\n",
    "            X_train, y_train = X_base[train_idx], y_base[train_idx]\n",
    "            X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "            dtrain = xgb.dask.DaskDMatrix(client, X_train, y_train)\n",
    "            dtest = xgb.dask.DaskDMatrix(client, X_test, y_test)\n",
    "\n",
    "            best_model = xgb.dask.train(\n",
    "                client,\n",
    "                param, \n",
    "                dtrain,\n",
    "                num_boost_round=500,\n",
    "                # early_stopping_rounds=50, \n",
    "                evals=[(dtrain, \"train\")],\n",
    "            )\n",
    "            \n",
    "            # booster = output[\"booster\"]\n",
    "            # print(booster.best_iteration)\n",
    "            # best_model = booster[: booster.best_iteration]\n",
    "            train_preds = xgb.dask.predict(client, best_model, dtrain)\n",
    "            test_preds = xgb.dask.predict(client, best_model, dtest)\n",
    "\n",
    "            result_tain_list.append(mean_squared_error(train_preds, y_train))\n",
    "            result_test_list.append(mean_squared_error(test_preds, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for train_idx, test_idx in self.cv.split(X_base, y_base):\n",
    "            \n",
    "\n",
    "            # print(test_idx)\n",
    "\n",
    "            X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "            X_train, y_train = X_base.loc[X_base.index[train_idx]], y_base.loc[y_base.index[train_idx]]\n",
    "        \n",
    "\n",
    "            # X_test, y_test = X_base[test_idx], y_base[test_idx]\n",
    "            # X_train, y_train = X_base[train_idx], y_base[train_idx]\n",
    "\n",
    "            estimator_ = clone(self.estimator)\n",
    "            estimator_.fit(X_train, y_train, **fit_kws)\n",
    "\n",
    "            self.logger.info(\"... log things ...\")\n",
    "            self.estimators_.append(estimator_)\n",
    "            self.split_scores_.append(estimator_.score(X_test, y_test))            \n",
    "            self.holdout_scores_.append(\n",
    "                estimator_.score(X_holdout, y_holdout))\n",
    "    \n",
    "        self.best_estimator_ = \\\n",
    "                self.estimators_[np.argmax(self.holdout_scores_)]\n",
    "\n",
    "\n",
    "\n",
    "        holdout_pred = xgb.dask.predict(client, best_model, X_holdout)\n",
    "\n",
    "        train_test_diff = np.abs(np.mean(result_tain_list) - np.mean(result_test_list))       \n",
    "\n",
    "        print('MEAN TRAIN.....', np.mean(result_tain_list))\n",
    "        print('MEAN TEST.....', np.mean(result_test_list))\n",
    "        print('TRAIN-TEST DIFF.....', train_test_diff)\n",
    "        print('HOLDOUT ..... ', mean_squared_error(holdout_pred, y_holdout))                \n",
    "        return self\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95678926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.90'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ff931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6ff7914d2bc405bfa61a835d0564ba294eb5f3f9b4c24865f45d9397593b123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
