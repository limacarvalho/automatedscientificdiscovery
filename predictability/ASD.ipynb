{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76442d14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "from plotly.subplots import make_subplots        \n",
    "#from PIL import ImageColor\n",
    "import pickle\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import curve_fit\n",
    "import dcor\n",
    "\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "# for power law fit \"model\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1167b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5436b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Framework for automated evaluation of column tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a198a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The aim is to provide a routine that gets fed a dataframe / csv-file, runs data analysis routines and returns metrics and plots à la\n",
    "\n",
    "`metrics, plot = predictability(df, num_input_columns, num_target_columns, list_of_considered_columns, \"analysis method\")`\n",
    "\n",
    "The metrics we use* are \n",
    "\n",
    "| r2  |  RMSE | RMSE/std | MAPE  | RAE  | Distance correlation  |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| $$1-\\frac{\\sum (\\hat{y}-y)^2}{\\sum (\\bar{y}-y)^2}$$ | $$\\sqrt{\\frac{1}{N} \\sum (\\hat{y}-y)^2 }$$ | $$\\sqrt{\\frac{1}{N} \\sum \\frac{(\\hat{y}-y)^2}{\\sigma_y{}^2} }$$ | $$\\frac{1}{N}\\sum \\frac{\\lvert \\hat{y}-y \\rvert}{\\lvert y\\rvert}$$ | $$\\frac{\\sum \\lvert \\hat{y}-y\\rvert}{\\sum \\lvert \\bar{y}-y\\rvert }$$ |  [cf. documentation](https://dcor.readthedocs.io/en/latest/theory.html)<br/> [cf. paper](https://projecteuclid.org/journals/annals-of-statistics/volume-35/issue-6/Measuring-and-testing-dependence-by-correlation-of-distances/10.1214/009053607000000505.full)<br/> [cf. wiki](https://en.wikipedia.org/wiki/Distance_correlation) |\n",
    "\n",
    "with\n",
    "\n",
    "$y$: observed data<br/>\n",
    "$\\hat{y}$: predicted counterpart of $y$<br/>\n",
    "$N$: number of $y$ and $\\hat{y}$<br/>\n",
    "$\\bar{y}$: average of $y$<br/>\n",
    "$\\sigma_y$: error in measurement of $y$\n",
    "\n",
    "*) Note that RMSE/std is not yet implemented as we don't work with data that includes measurement errors so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d8788",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c885a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Should primary keys be considered or do we assume the data(frame) is handed over properly also with respect to fixing possible primary keys?\\\n",
    "In the example of Country Indicators data: Year and Country is not a normal data column. But it also depends on the choice of what we want to investigate whether we drop them or fix one of them.\n",
    "* Should input be possible as dataframe only, or also as csv- / txt-file?\n",
    "* We should also go through all relevant permutations of the data tuples.\\\n",
    "If we have, e.g., four data columns [A, B, C, D] and want to analyse 2-2 connections, it does not suffice to only consider input=[A, B], output=[C, D]. There may well be no causal connection between any of A,B and any of C,D, but instead between C and D. So we need to consider all $\\frac{N!}{I!\\cdot O!}$ many combinations, given $N$ data columns, $I$-many inputs and $O$-many outputs.\n",
    "* Currently, RMSE/std relies on the standard deviation of the test values $y$. One could of course also use the overall available target values – the combined train and test values.\n",
    "* Decision on whether outliers are extracted or not is currently based on *test* score.\n",
    "* Currently, also the metrics of the linear regression and power law fits are computed for the test data set only.\n",
    "* Fitting in log-log-space results in asymmetric error distributions as predicitions higher than the actual value are squeezed and lower values spreaded.\\\n",
    "Use packages for powerlaw-fitting? \"Normal\" fitting of exponential laws is quite sensitive to small deviations.\\\n",
    "Also different treatment of errors $\\epsilon$, $\\eta$:\n",
    "\n",
    "|  | log-log space  | | linear space | error in log-log space | error in linear space |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear in linear space | | | $$ y = C\\cdot x^a + \\epsilon$$  | | additive |\n",
    "| linear in log-log space | $$ \\log y = \\log C + a\\cdot\\log x {\\color{red}\\oplus} \\eta$$ | $\\Leftrightarrow$ | $$ y = C\\cdot x^a {\\color{blue}\\odot} \\mathrm{e}^\\eta $$ | $${\\color{red}{\\mathrm{additive}}}$$ | $${\\color{blue}{\\mathrm{multiplicative}}}$$ |\n",
    "\n",
    "* So far, scaling is included as optional argument and is either done on all columns or none (depending on yes/no/try as the argument input where the latter means scaling is part of the GridSearchCV). However, it should be done column-wise and automated. So check range of input columns' values and then apply scaler automatically, assuming it never worsens the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5733244",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### load example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1c828",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_country_indicators.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6671eb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebea6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# to work with 2007 data only\n",
    "df2007 = df.loc[df[\"Year\"]==2007]\n",
    "df2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724e9e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd0d46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "The above dataset contains the two primary keys \"Country Name\" and \"Year\" which are not supposed to be part of the analysis.\n",
    "\n",
    "Primary keys can be used to \"zoom in\" on more detailed analyses. In this case, e.g., check how numbers for Afghanistan evolved over time. Or only take data from year 2007 and find a connection between two columns, then compare it to the same data but for 2002 etc.\n",
    "\n",
    "Therefore, the primary keys have to be treated differently from the remaining *data columns*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c09bff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prim_keys = [\"Country Name\", \"Year\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15125e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7059c8a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Helper routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbd909",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### relative absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837885e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def rae(true, predicted):\n",
    "    numerator = np.sum(np.abs(predicted - true))\n",
    "    denominator = np.sum(np.abs(np.mean(true) - true))\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d002719",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3d plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51437571",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_3d_result(data_tuple, metrics, datas, show=False):\n",
    "    \n",
    "    \n",
    "    '''fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    row_heights=[0.7, 0.15, 0.15],\n",
    "    specs=[[{\"type\": \"scatter3d\"}],\n",
    "           [{\"type\": \"scatter\", \"t\": -.07}],\n",
    "           [{\"type\": \"histogram\", \"t\": .05}]],\n",
    "    vertical_spacing=.1,\n",
    "    #shared_xaxes = True\n",
    "    )'''\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=[i[0] for i in datas[data_tuple][\"X_train\"]],\n",
    "                     y=[i[1] for i in datas[data_tuple][\"X_train\"]],\n",
    "                     z=datas[data_tuple][\"y_train\"].flatten(),\n",
    "                     #xaxis=\"x\",\n",
    "                     #yaxis=\"y\",\n",
    "                     name=\"training data\",\n",
    "                     mode=\"markers\",\n",
    "                     marker_color=datas[data_tuple][\"y_train\"].flatten(),\n",
    "                     marker_size=3,\n",
    "                     opacity=.6\n",
    "                    ),\n",
    "        #row=1, col=1\n",
    "                         ]\n",
    "                   )\n",
    "    \n",
    "     \n",
    "    fig.update_layout(\n",
    "        title=data_tuple[2]+'  vs.  '+data_tuple[0]+' & '+data_tuple[1],\n",
    "        scene=dict(xaxis=dict(title=data_tuple[0],\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "            #type='log',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=data_tuple[1],\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "            #type='log',\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title=data_tuple[2],\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "            #type='log',\n",
    "        )\n",
    "        ),\n",
    "        #yaxis_range=[y_min*1.01,y_max*1.01],\n",
    "        #xaxis2=dict(title=data_tuple[0], matches=\"x\"),\n",
    "        #yaxis2=dict(title=\"pred. error\"),\n",
    "        #xaxis3=dict(title=r\"$\\text{error } y_{pred}-y$\"),\n",
    "        #yaxis3=dict(title=\"frequency\"),\n",
    "        legend=dict(bgcolor=\"white\"),\n",
    "        paper_bgcolor='rgb(243, 243, 243)',\n",
    "        plot_bgcolor='rgb(243, 243, 243)',\n",
    "        width=920,\n",
    "        height=720\n",
    "    )\n",
    "    \n",
    "    if show==True:\n",
    "        fig.show()\n",
    "    else:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b258e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2d plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d23161",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_result(data_tuple, metrics, datas, show=False):\n",
    "    \n",
    "    # need to order test values for correct connection of data points during line plotting\n",
    "    pred_MLP_data = list(zip(datas[data_tuple][\"X_test\"].reshape(len(datas[data_tuple][\"X_test\"]),), \n",
    "             datas[data_tuple][\"y_test_pred\"]))\n",
    "    pred_MLP_df = pd.DataFrame(data=pred_MLP_data,\n",
    "             columns=[\"X_test\", \"y_test_pred\"],\n",
    "             ).sort_values(by=\"X_test\")\n",
    "    \n",
    "    # get max and min plotting values\n",
    "    y_min = min(0, min(datas[data_tuple][\"y_train\"]), min(datas[data_tuple][\"y_test\"]), min(datas[data_tuple][\"y_test_pred\"]))\n",
    "    y_max = max(0, max(datas[data_tuple][\"y_train\"]), max(datas[data_tuple][\"y_test\"]), max(datas[data_tuple][\"y_test_pred\"]))\n",
    "    \n",
    "    fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    row_heights=[0.7, 0.15, 0.15],\n",
    "    specs=[[{\"type\": \"scatter\"}],\n",
    "           [{\"type\": \"scatter\", \"t\": -.07}],\n",
    "           [{\"type\": \"histogram\", \"t\": .05}]],\n",
    "    vertical_spacing=.1,\n",
    "    #shared_xaxes = True\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=datas[data_tuple][\"X_train\"].reshape(len(datas[data_tuple][\"X_train\"]),), \n",
    "                   y=datas[data_tuple][\"y_train\"].flatten(),\n",
    "                   xaxis=\"x\",\n",
    "                   yaxis=\"y\",\n",
    "                   name=\"training data\",\n",
    "                   mode=\"markers\", marker_color=\"Maroon\", marker_size=3, opacity=.6\n",
    "                    ),\n",
    "        row=1, col=1\n",
    "                 )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=datas[data_tuple][\"X_test\"].reshape(len(datas[data_tuple][\"X_test\"]),), \n",
    "                   y=datas[data_tuple][\"y_test\"].flatten(),  \n",
    "                   xaxis=\"x\",\n",
    "                   yaxis=\"y\",\n",
    "                   name=\"test data\",\n",
    "                   mode=\"markers\", marker_color=\"LightSeaGreen\", opacity=.8 \n",
    "                    ),\n",
    "        row=1, col=1\n",
    "                 )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=pred_MLP_df[\"X_test\"],#.reshape(len(datas[data_tuple][\"X_test\"]),), \n",
    "                   y=pred_MLP_df[\"y_test_pred\"], \n",
    "                   xaxis=\"x\",\n",
    "                   yaxis=\"y\",\n",
    "                   name=\"predictions MLP\",\n",
    "                   mode='lines+markers',\n",
    "                   #mode=\"markers\",\n",
    "                   marker_color=\"Tomato\", \n",
    "                    ),\n",
    "        row=1, col=1\n",
    "                 )\n",
    "    # add power law predictions\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=datas[data_tuple][\"X_test\"].reshape(len(datas[data_tuple][\"X_test\"]),), \n",
    "                   y=datas[data_tuple][\"y_test_pred_pl\"].flatten(), \n",
    "                   xaxis=\"x\",\n",
    "                   yaxis=\"y\",\n",
    "                   name=\"predictions pl\",\n",
    "                   mode=\"markers\", marker_color=\"SteelBlue\", \n",
    "                    ),\n",
    "        row=1, col=1\n",
    "                 )\n",
    "        \n",
    "    # add metrics\n",
    "    \n",
    "    fig.add_annotation(text='mean y_train: '+str(round(datas[data_tuple][\"y_test_pred_mean\"][0])),\n",
    "                      align=\"right\",\n",
    "                      showarrow=False,\n",
    "                        xref='paper',\n",
    "                        yref='paper',\n",
    "                        x=1.223,\n",
    "                        y=.73,\n",
    "                        bgcolor=\"white\")\n",
    "    \n",
    "    fig.add_annotation(text='<b>r2 MLP:   </b>'+str(round(metrics[data_tuple][\"MLP r2\"],2))+\n",
    "                       ' <i><br>r2 pow. law:   </i>'+str(round(metrics[data_tuple][\"pow. law r2\"],2))+\n",
    "                       ' <i><br>r2 lin. reg.:   </i>'+str(round(metrics[data_tuple][\"linear r2\"],2))+\n",
    "                       ' <i><br>r2 mean pred.:   </i>'+str(round(metrics[data_tuple][\"mean r2\"],2))+\n",
    "                       ' <b><br>RMSE MLP:   </b>'+str(round(metrics[data_tuple][\"MLP RMSE\"],2))+\n",
    "                       ' <i><br>RMSE pow. law:   </i>'+str(round(metrics[data_tuple][\"pow. law RMSE\"],2))+\n",
    "                       ' <i><br>RMSE lin. reg.:   </i>'+str(round(metrics[data_tuple][\"linear RMSE\"],2))+\n",
    "                       ' <i><br>RMSE nean pred.:   </i>'+str(round(metrics[data_tuple][\"mean RMSE\"],2))+\n",
    "                       ' <b><br>RMSE/std MLP:   </b>'+str(round(metrics[data_tuple][\"MLP RMSE/std\"],2))+\n",
    "                       ' <i><br>RMSE/std pow. law:   </i>'+str(round(metrics[data_tuple][\"pow. law RMSE/std\"],2))+\n",
    "                       ' <i><br>RMSE/std lin. reg.:   </i>'+str(round(metrics[data_tuple][\"linear RMSE/std\"],2))+\n",
    "                       ' <i><br>RMSE/std mean pred.:   </i>'+str(round(metrics[data_tuple][\"mean RMSE/std\"],2))+\n",
    "                       ' <b><br>MAPE MLP:   </b>'+str(round(metrics[data_tuple][\"MLP MAPE\"],2))+\n",
    "                       ' <i><br>MAPE pow. law:   </i>'+str(round(metrics[data_tuple][\"pow. law MAPE\"],2))+\n",
    "                       ' <i><br>MAPE lin. reg.:   </i>'+str(round(metrics[data_tuple][\"linear MAPE\"],2))+\n",
    "                       ' <i><br>MAPE mean pred.:   </i>'+str(round(metrics[data_tuple][\"mean MAPE\"],2))+\n",
    "                       ' <b><br>rae MLP:   </b>'+str(round(metrics[data_tuple][\"MLP rae\"],2))+\n",
    "                       ' <i><br>rae pow. law:   </i>'+str(round(metrics[data_tuple][\"pow. law rae\"],2))+\n",
    "                       ' <i><br>rae lin. reg.:   </i>'+str(round(metrics[data_tuple][\"linear rae\"],2))+\n",
    "                       ' <i><br>rae mean pred.:   </i>'+str(round(metrics[data_tuple][\"mean rae\"],2))+\n",
    "                       ' <b><br>dcor MLP:   </b>'+str(round(metrics[data_tuple][\"MLP dcor\"],2))+\n",
    "                       ' <i><br>dcor pow. law:   </i>'+str(round(metrics[data_tuple][\"pow. law dcor\"],2))+\n",
    "                       ' <i><br>dcor lin. reg.:   </i>'+str(round(metrics[data_tuple][\"linear dcor\"],2))+\n",
    "                       ' <i><br>dcor mean pred.:   </i>'+str(round(metrics[data_tuple][\"mean dcor\"],2)),\n",
    "                       #' <br>Spearman corr.:   '+str(round(metrics[data_tuple][\"Spearman\"],2))+\n",
    "                       #' <br>Pearson corr.:   '+str(round(metrics[data_tuple][\"Pearson\"],2)), \n",
    "                        align='right',\n",
    "                        showarrow=False,\n",
    "                        xref='paper',\n",
    "                        yref='paper',\n",
    "                        x=1.223,\n",
    "                        y=.68,\n",
    "                        bgcolor=\"white\",\n",
    "                        #bordercolor='black',\n",
    "                        #borderwidth=1\n",
    "                      )\n",
    "\n",
    "    # local plot of errors\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=datas[data_tuple][\"X_test\"].reshape(len(datas[data_tuple][\"X_test\"]),), \n",
    "                   y=datas[data_tuple][\"y_test_pred\"].flatten()-datas[data_tuple][\"y_test\"].flatten(), \n",
    "                   xaxis=\"x2\",\n",
    "                   yaxis=\"y2\",\n",
    "                   mode=\"markers\", marker_color=\"Tomato\",\n",
    "                   legendgroup=\"MLP\",\n",
    "                   name=\"pred. error MLP\" \n",
    "                    ),\n",
    "        row=2, col=1\n",
    "                 )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=datas[data_tuple][\"X_test\"].reshape(len(datas[data_tuple][\"X_test\"]),), \n",
    "                   y=datas[data_tuple][\"y_test_pred_pl\"].flatten()-datas[data_tuple][\"y_test\"].flatten(), \n",
    "                   xaxis=\"x2\",\n",
    "                   yaxis=\"y2\",\n",
    "                   mode=\"markers\", marker_color=\"SteelBlue\",\n",
    "                   legendgroup=\"pl\",\n",
    "                   name=\"pred. error pl\" \n",
    "                    ),\n",
    "        row=2, col=1\n",
    "                 )\n",
    "    \n",
    "    # add line as separator\n",
    "    fig.add_shape(type='line',\n",
    "                x0=-.05,\n",
    "                y0=.1,\n",
    "                x1=1.05,\n",
    "                y1=.1,\n",
    "                line=dict(color='white',),\n",
    "                xref='paper',\n",
    "                yref='paper'\n",
    "    )\n",
    "    \n",
    "    # histogram of errors\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=datas[data_tuple][\"y_test_pred\"]-datas[data_tuple][\"y_test\"].flatten(),\n",
    "                   xaxis=\"x3\",\n",
    "                   yaxis=\"y3\",\n",
    "                   nbinsx=100,\n",
    "                   marker_color='Tomato',\n",
    "                   legendgroup=\"MLP\",\n",
    "                   name=\"pred. error MLP\",\n",
    "                    showlegend=False),\n",
    "        row=3, col=1\n",
    "                 )\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=datas[data_tuple][\"y_test_pred_pl\"].flatten()-datas[data_tuple][\"y_test\"].flatten(),\n",
    "                   xaxis=\"x3\",\n",
    "                   yaxis=\"y3\",\n",
    "                   nbinsx=100,\n",
    "                   marker_color='SteelBlue',\n",
    "                   legendgroup=\"pl\",\n",
    "                   name=\"pred. error pl\",\n",
    "                    showlegend=False),\n",
    "        row=3, col=1\n",
    "                 )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=data_tuple[1]+'  vs.  '+data_tuple[0],\n",
    "        xaxis=dict(\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "            #type='log',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=data_tuple[1],\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "            #type='log',\n",
    "        ),\n",
    "        yaxis_range=[y_min*1.01,y_max*1.01],\n",
    "        xaxis2=dict(title=data_tuple[0],\n",
    "                    matches=\"x\"),\n",
    "        yaxis2=dict(title=\"pred. error\"),\n",
    "        xaxis3=dict(title=r\"$\\text{error } y_{pred}-y$\"),\n",
    "        yaxis3=dict(title=\"frequency\"),\n",
    "        legend=dict(bgcolor=\"white\"),\n",
    "        paper_bgcolor='rgb(243, 243, 243)',\n",
    "        plot_bgcolor='rgb(243, 243, 243)',\n",
    "        width=920,\n",
    "        height=720\n",
    "    )\n",
    "    fig.update_layout(legend_tracegroupgap=0)\n",
    "    \n",
    "    if show==True:\n",
    "        fig.show()\n",
    "    else:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e116a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### outlier extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2759ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### via class, if potentially inside pipeline\n",
    "\n",
    "not in use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba71f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "class OutlierExtractor(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a transformer to remove outliers. A threshold is set for selection\n",
    "        criteria, and further arguments are passed to the LocalOutlierFactor class\n",
    "\n",
    "        Keyword Args:\n",
    "            neg_conf_val (float): The threshold for excluding samples with a lower\n",
    "               negative outlier factor.\n",
    "\n",
    "        Returns:\n",
    "            object: to be used as a transformer method as part of Pipeline()\n",
    "        \"\"\"\n",
    "\n",
    "        self.threshold = kwargs.pop('neg_conf_val', -10.0)\n",
    "\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        \"\"\"\n",
    "        Uses LocalOutlierFactor class to subselect data based on some threshold\n",
    "\n",
    "        Returns:\n",
    "            ndarray: subsampled data\n",
    "\n",
    "        Notes:\n",
    "            X should be of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        lcf = LocalOutlierFactor(**self.kwargs)\n",
    "        lcf.fit(X)\n",
    "        return (X[lcf.negative_outlier_factor_ > self.threshold, :],\n",
    "                y[lcf.negative_outlier_factor_ > self.threshold])\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7bb68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### the standard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143d8f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_outliers(data):\n",
    "    \n",
    "    extractor = LocalOutlierFactor(n_neighbors=20)\n",
    "    \n",
    "    data_extr_pred = extractor.fit_predict(data)\n",
    "    \n",
    "    outliers_index = np.where(data_extr_pred==-1)\n",
    "    outliers = data.iloc[outliers_index]\n",
    "    inliers_index = np.where(data_extr_pred==1)\n",
    "    data_extr = data.iloc[inliers_index]\n",
    "    \n",
    "    data_scores = extractor.negative_outlier_factor_\n",
    "    \n",
    "    return data_extr, data_scores, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c17c14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### data preparation, train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bdd64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_prep_split(data, inputs, outputs):\n",
    "    # get x and y value(s)\n",
    "    curr_x = np.array(data[inputs])#.reshape(-1, 1)\n",
    "    curr_y = np.array(data[outputs])\n",
    "    \n",
    "    \n",
    "    # train test split\n",
    "    curr_X_train, curr_X_test, curr_y_train, curr_y_test = train_test_split(curr_x, curr_y, random_state=1,\n",
    "                                                                            test_size=.3, shuffle=True)\n",
    "    \n",
    "    \n",
    "    #curr_y_train = curr_y_train.ravel()\n",
    "    #curr_y_test = curr_y_test.ravel()\n",
    "    \n",
    "    return curr_X_train, curr_X_test, curr_y_train, curr_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae61cc4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### scoring mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7b54c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_dict = {\n",
    "    \"r2\": \"r2\",\n",
    "    \"MAPE\": \"neg_mean_absolute_percentage_error\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"neg_mean_absolute_percentage_error\",\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32d733",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### get column combinations of desired number of input and output columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87456758",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_column_combinations(all_cols, inputs, outputs):\n",
    "    \n",
    "    assert inputs+outputs <= len(all_cols), \"More input and output columns specified than there are columns.\"\n",
    "    \n",
    "    # initialise final list of column combinations\n",
    "    col_combinations = []\n",
    "    # first, draw possible input tuples\n",
    "    input_combinations = list(itertools.combinations(all_cols, inputs))\n",
    "    # now go through all possible input combinations\n",
    "    for i in input_combinations:\n",
    "        # get list of possible output columns, i.e. columns that are not yet part of current input columns\n",
    "        curr_output_cols = [o for o in all_cols if o not in i]\n",
    "        # now draw from that list all currently possible output combinations\n",
    "        output_combinations = list(itertools.combinations(curr_output_cols, outputs))\n",
    "        # add all currently possible output combinations to the current input columns and save in final list\n",
    "        for oc in output_combinations:\n",
    "            col_combinations.append(i+(*oc,))\n",
    "        \n",
    "    return col_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638a7a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### power law fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ebb23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### w/o errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59661d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757d26e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a275f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef7d1fd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2cd13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_power_law_1_1(logx, logC, a1):\n",
    "    return logC+a1*logx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633b90d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def power_law_1_1(x, logC, a1):\n",
    "    return np.e**logC*x**a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411189d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit_predict_power_law_1_1(curr_X_train,\n",
    "                      curr_X_test, \n",
    "                      curr_y_train, \n",
    "                      curr_y_test\n",
    "                     ):\n",
    "    \n",
    "    # move data so everything is positive for fitting\n",
    "    min_x = min(min(curr_X_train), min(curr_X_test))\n",
    "    min_y = min(min(curr_y_train), min(curr_y_test))\n",
    "    if min_x < 0:\n",
    "        x_subtraction = 1.05*min_x\n",
    "    elif min_x == 0:\n",
    "        x_subtraction = -0.05\n",
    "    else:\n",
    "        x_subtraction = 0\n",
    "    if min_y < 0:\n",
    "        y_subtraction = 1.05*min_y\n",
    "    elif min_y == 0:\n",
    "        y_subtraction = -0.05\n",
    "    else:\n",
    "        y_subtraction = 0\n",
    "    curr_X_train, curr_X_test = curr_X_train.flatten()-x_subtraction, curr_X_test.flatten()-x_subtraction\n",
    "    curr_y_train, curr_y_test = curr_y_train.flatten()-y_subtraction, curr_y_test.flatten()-y_subtraction\n",
    "    \n",
    "    # values in log-space\n",
    "    log_curr_X_train, log_curr_y_train = np.log(curr_X_train), np.log(curr_y_train)\n",
    "    \n",
    "    # fit\n",
    "    fit_params, cov = curve_fit(log_power_law_1_1, log_curr_X_train, log_curr_y_train)\n",
    "    \n",
    "    curr_y_test_pred_pl = power_law_1_1(curr_X_test, *fit_params)+y_subtraction\n",
    "    \n",
    "    return curr_y_test_pred_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78df94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712faa9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ad618",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18078fc4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d0e2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predictability(data, input_cols=1, output_cols=1, col_set=None, primkey_cols=[], targets=[],\n",
    "                   method=\"MLP\", hidden_layers=None, alphas=None, scoring=\"r2\", scaling=True, \n",
    "                   max_iter=10000, n_jobs=-1, verbose=1):\n",
    "    \n",
    "    # TODO: map scoring to possible options\n",
    "    scoring_dict = {\n",
    "        \"r2\": \"r2\",\n",
    "        \"MAPE\": \"neg_mean_absolute_percentage_error\",\n",
    "        \"neg_mean_absolute_percentage_error\": \"neg_mean_absolute_percentage_error\",\n",
    "        \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "        \"MAE\": \"neg_mean_absolute_error\",\n",
    "        \"neg_mean_absolute_error\": \"neg_mean_absolute_error\"\n",
    "    }\n",
    "    scoring = scoring_dict[scoring]\n",
    "    \n",
    "    # if we want to measure the overall time\n",
    "    start = time.time()\n",
    "    \n",
    "    # initialise the dictionary that is going to save the metrics per tuple\n",
    "    metric_dict = {}\n",
    "    \n",
    "    # dict to save x-/y-train/-test and predicted values for subsequent plotting\n",
    "    data_dict = {}\n",
    "    \n",
    "    # if primary keys are fed in, data columns should not contain these\n",
    "    data_cols = [col for col in data.columns.to_list() if col not in primkey_cols]\n",
    "    \n",
    "    # if set of columns that should be considered is fed in, use this\n",
    "    if col_set is not None:\n",
    "        data_cols = list(set(col_set))\n",
    "    \n",
    "    # get the list of tuples of input and output columns\n",
    "    if targets:\n",
    "        data_tuples = get_column_combinations_w_targets(data_cols, input_cols, output_cols, targets)\n",
    "    else:\n",
    "        data_tuples = get_column_combinations(data_cols, input_cols, output_cols)    \n",
    "    \n",
    "    # for printing the progress of the analysis\n",
    "    counter_tuples = 0\n",
    "    \n",
    "    # go through all tuples\n",
    "    # or testing subset only:\n",
    "    #data_tuples = [(\"Electric power consumption (kWh per capita)\", \"Life expectancy at birth, total (years)\")]+data_tuples[:5]\n",
    "    #\n",
    "    for curr_tuple in data_tuples:\n",
    "        \n",
    "        # if we want to measure the current tuple's analysis time\n",
    "        curr_start = time.time()\n",
    "        \n",
    "        print(\"Analysing \"+str(curr_tuple)+\" now.\")\n",
    "        \n",
    "        # TODO: implement going through all permutations\n",
    "        \n",
    "        # get current inputs and outputs\n",
    "        curr_inputs = list(curr_tuple[:input_cols])\n",
    "        curr_outputs = list(curr_tuple[input_cols:])\n",
    "        \n",
    "        # reduce data to current columns and drop NAs\n",
    "        curr_data = data[curr_inputs+curr_outputs].dropna()\n",
    "        \n",
    "        # dict of min values of current columns, used for power law fitting\n",
    "        mi_dict = {}\n",
    "        for col in curr_inputs+curr_outputs:\n",
    "            curr_min = min(curr_data[col])\n",
    "            if curr_min < 0:\n",
    "                x_subtraction = 1.05*curr_min\n",
    "            elif curr_min == 0:\n",
    "                x_subtraction = -0.05\n",
    "            else:\n",
    "                x_subtraction = 0\n",
    "            mi_dict[col] = x_subtraction\n",
    "            \n",
    "        \n",
    "        # do data preparations and train-test-split\n",
    "        curr_X_train, curr_X_test, curr_y_train, curr_y_test = data_prep_split(curr_data, curr_inputs, curr_outputs)\n",
    "        \n",
    "        # compute standard deviation of curr_y_test for later scaling of the RMSE\n",
    "        curr_y_test_std = np.std(curr_y_test)\n",
    "        \n",
    "        #\n",
    "        # y-mean \"prediction\"\n",
    "        #\n",
    "        curr_y_train_mean = np.mean(curr_y_train)\n",
    "        curr_y_test_pred_mean = curr_y_train_mean*np.ones(len(curr_X_test))\n",
    "        # metrics\n",
    "        curr_mean_r2 = r2_score(curr_y_test, curr_y_test_pred_mean)\n",
    "        curr_mean_rmse = mean_squared_error(curr_y_test, curr_y_test_pred_mean, squared=False)\n",
    "        curr_mean_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred_mean)\n",
    "        curr_mean_rae = rae(curr_y_test, curr_y_test_pred_mean)\n",
    "        curr_mean_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred_mean)\n",
    "        \n",
    "        #\n",
    "        # linear regression\n",
    "        #\n",
    "        lin_reg = LinearRegression().fit(curr_X_train,curr_y_train)\n",
    "        curr_y_test_pred = lin_reg.predict(curr_X_test)\n",
    "        # metrics\n",
    "        curr_lin_r2 = r2_score(curr_y_test, curr_y_test_pred)\n",
    "        curr_lin_rmse = mean_squared_error(curr_y_test, curr_y_test_pred, squared=False)\n",
    "        curr_lin_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred)\n",
    "        curr_lin_rae = rae(curr_y_test, curr_y_test_pred)\n",
    "        curr_lin_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred)\n",
    "        \n",
    "        '''\n",
    "        # power law fit so far only for 1-1 connections implemented\n",
    "        if input_cols==1 and output_cols==1:\n",
    "            #\n",
    "            # power law fit\n",
    "            #\n",
    "            curr_y_test_pred_pl = fit_predict_power_law_1_1(curr_X_train, curr_X_test, curr_y_train, curr_y_test)\n",
    "\n",
    "            # metrics\n",
    "            curr_pl_r2 = r2_score(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rmse = mean_squared_error(curr_y_test, curr_y_test_pred_pl, squared=False)\n",
    "            curr_pl_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rae = rae(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred_pl)\n",
    "            '''\n",
    "        #\n",
    "        # power law fit\n",
    "        #\n",
    "        if ((curr_X_train>0).all().all()) and ((curr_X_test>0).all().all()):\n",
    "            do_pl_fit = True\n",
    "        else:\n",
    "            do_pl_fit = False\n",
    "        \n",
    "        if do_pl_fit:\n",
    "            \n",
    "            curr_X_train_log = curr_X_train.apply(lambda x: np.log(x))\n",
    "            curr_X_test_log = curr_X_test.apply(lambda x: np.log(x))\n",
    "            curr_y_train_log = curr_y_train.apply(lambda x: np.log(x))\n",
    "            #curr_y_test_log = curr_y_test.apply(lambda x: np.log(x))\n",
    "            \n",
    "            pl_fit = LinearRegression().fit(curr_X_train_log, curr_y_train_log)\n",
    "            \n",
    "            curr_y_test_pred_pl = pl_fit.predict(curr_X_test_log)\n",
    "            \n",
    "            curr_y_test_pred_pl = np.exp(curr_y_test_pred_pl)\n",
    "            \n",
    "            # metrics\n",
    "            curr_pl_r2 = r2_score(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rmse = mean_squared_error(curr_y_test, curr_y_test_pred_pl, squared=False)\n",
    "            curr_pl_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rae = rae(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred_pl)\n",
    "            \n",
    "        \n",
    "        #\n",
    "        # MLP regression\n",
    "        print(\"start MLP routine\")\n",
    "        #\n",
    "        # list of hidden layer sizes for GridSearch\n",
    "        if hidden_layers is None:\n",
    "            hidden_layers = [(12,), \n",
    "                              (50,), \n",
    "                              (70,5,), \n",
    "                              #(40,18,3,)\n",
    "                            ]\n",
    "        # list of alpha values for GridSearch\n",
    "        if alphas is None:\n",
    "            alphas = [0.001, \n",
    "                      0.0001, \n",
    "                      0.00001\n",
    "                     ]\n",
    "\n",
    "        # via pipeline (with and without scaler)\n",
    "        if scaling==\"yes\":\n",
    "            pipe = Pipeline([\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('mlp', MLPRegressor(max_iter=max_iter))\n",
    "                            ])\n",
    "            pipe_params = [\n",
    "                           {'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}\n",
    "                            ]\n",
    "            clf = GridSearchCV(pipe,\n",
    "                               param_grid=pipe_params,\n",
    "                               cv=3,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                               verbose=verbose,\n",
    "                               n_jobs=n_jobs\n",
    "                              )        \n",
    "        elif scaling==\"no\":\n",
    "            pipe = Pipeline([\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('mlp', MLPRegressor(max_iter=max_iter))\n",
    "                            ])\n",
    "            pipe_params = [{'scaler': ['passthrough'],\n",
    "                            'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}]\n",
    "            clf = GridSearchCV(pipe,\n",
    "                               param_grid=pipe_params,\n",
    "                               cv=3,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                               verbose=verbose,\n",
    "                               n_jobs=n_jobs\n",
    "                              )\n",
    "        else:\n",
    "            pipe = Pipeline([\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('mlp', MLPRegressor(max_iter=max_iter))\n",
    "                            ])\n",
    "            pipe_params = [{'scaler': ['passthrough'],\n",
    "                            'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}, \n",
    "                           {'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}]\n",
    "            clf = GridSearchCV(pipe,\n",
    "                               param_grid=pipe_params,\n",
    "                               cv=3,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                               verbose=verbose,\n",
    "                               n_jobs=n_jobs\n",
    "                              )\n",
    "        \n",
    "        clf.fit(curr_X_train, curr_y_train)\n",
    "        \n",
    "        curr_best_params = clf.best_params_\n",
    "        curr_y_test_pred = clf.predict(curr_X_test)\n",
    "        \n",
    "        # metrics\n",
    "        curr_mlp_r2 = r2_score(curr_y_test, curr_y_test_pred)\n",
    "        curr_mlp_rmse = mean_squared_error(curr_y_test, curr_y_test_pred, squared=False)\n",
    "        curr_mlp_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred)\n",
    "        curr_mlp_rae = rae(curr_y_test, curr_y_test_pred)\n",
    "        curr_mlp_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred)\n",
    "\n",
    "        # save metrics into dict\n",
    "        # power law fit so far only for 1-1 connections implemented\n",
    "        if do_pl_fit:\n",
    "            metric_dict[curr_tuple] = {\"MLP r2\": curr_mlp_r2, \"linear r2\": curr_lin_r2, \n",
    "                                       \"pow. law r2\": curr_pl_r2, \"mean r2\": curr_mean_r2, \n",
    "                                        \"MLP RMSE\": curr_mlp_rmse, \"linear RMSE\": curr_lin_rmse,\n",
    "                                        \"pow. law RMSE\": curr_pl_rmse, \"mean RMSE\": curr_mean_rmse,\n",
    "                                        \"MLP RMSE/std\": curr_mlp_rmse/curr_y_test_std, \"linear RMSE/std\": curr_lin_rmse/curr_y_test_std,\n",
    "                                       \"pow. law RMSE/std\": curr_pl_rmse/curr_y_test_std, \"mean RMSE/std\": curr_mean_rmse/curr_y_test_std,\n",
    "                                        \"MLP MAPE\": curr_mlp_mape, \"linear MAPE\": curr_lin_mape,\n",
    "                                       \"pow. law MAPE\": curr_pl_mape, \"mean MAPE\": curr_mean_mape,\n",
    "                                        \"MLP rae\": curr_mlp_rae, \"linear rae\": curr_lin_rae,\n",
    "                                        \"pow. law rae\": curr_pl_rae, \"mean rae\": curr_mean_rae,\n",
    "                                        \"MLP dcor\": curr_mlp_dcor, \"linear dcor\": curr_lin_dcor,\n",
    "                                        \"pow. law dcor\": curr_pl_dcor, \"mean dcor\": curr_mean_dcor,\n",
    "                                               }\n",
    "        else:\n",
    "            metric_dict[curr_tuple] = {\"MLP r2\": curr_mlp_r2, \"linear r2\": curr_lin_r2, \"mean r2\": curr_mean_r2, \n",
    "                                        \"MLP RMSE\": curr_mlp_rmse, \"linear RMSE\": curr_lin_rmse, \"mean RMSE\": curr_mean_rmse,\n",
    "                                        \"MLP RMSE/std\": curr_mlp_rmse/curr_y_test_std, \"linear RMSE/std\": curr_lin_rmse/curr_y_test_std,\n",
    "                                        \"mean RMSE/std\": curr_mean_rmse/curr_y_test_std,\n",
    "                                        \"MLP MAPE\": curr_mlp_mape, \"linear MAPE\": curr_lin_mape, \"mean MAPE\": curr_mean_mape,\n",
    "                                        \"MLP rae\": curr_mlp_rae, \"linear rae\": curr_lin_rae, \"mean rae\": curr_mean_rae,\n",
    "                                        \"MLP dcor\": curr_mlp_dcor, \"linear dcor\": curr_lin_dcor, \"mean dcor\": curr_mean_dcor,\n",
    "                                               }\n",
    "\n",
    "        # save values into dict\n",
    "        # power law fit so far only for 1-1 connections implemented\n",
    "        if do_pl_fit:\n",
    "            \n",
    "            data_dict[curr_tuple] = {\"X_train\": curr_X_train, \"X_test\": curr_X_test,\n",
    "                                     \"y_train\": curr_y_train, \"y_test\": curr_y_test, \"y_test_pred\": curr_y_test_pred,\n",
    "                                     \"y_test_pred_pl\": curr_y_test_pred_pl, \"y_test_pred_mean\": curr_y_test_pred_mean,\n",
    "                                     \"GridSearchParams\": curr_best_params, \"scores\": clf.cv_results_\n",
    "                                    }\n",
    "        else:\n",
    "            \n",
    "            data_dict[curr_tuple] = {\"X_train\": curr_X_train, \"X_test\": curr_X_test,\n",
    "                                     \"y_train\": curr_y_train, \"y_test\": curr_y_test, \"y_test_pred\": curr_y_test_pred,\n",
    "                                     \"y_test_pred_mean\": curr_y_test_pred_mean,\n",
    "                                     \"GridSearchParams\": curr_best_params, \"scores\": clf.cv_results_\n",
    "                                    }\n",
    "        \n",
    "                \n",
    "        # for printing the CV results per tuple\n",
    "        #print(clf.cv_results_)\n",
    "        \n",
    "        print(\"The analysis of this tuple took \"+str(round(time.time()-curr_start,2))+\"s.\")\n",
    "        # for printing the progress of the analysis\n",
    "        counter_tuples += 1\n",
    "        print(\"-----\"+str(counter_tuples)+\"/\"+str(len(data_tuples))+\"-----\")\n",
    "    \n",
    "    print(\"The whole run took \"+str(round(time.time()-start,2))+\"s.\")\n",
    "    \n",
    "    return metric_dict, data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802e527",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics, datas = predictability(data=df2007,\n",
    "                                input_cols=1,\n",
    "                                output_cols=1,\n",
    "                                col_set = ['Electric power consumption (kWh per capita)', \n",
    "                                           'Agriculture, value added (% of GDP)',\n",
    "                                           'Life expectancy at birth, total (years)', \n",
    "                                           'CO2 emissions (metric tons per capita)'],\n",
    "                                primkey_cols = prim_keys,\n",
    "                                scoring=\"RMSE\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437e7be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict(metrics).transpose()\n",
    "\n",
    "# or 3d ones\n",
    "#metrics_df = pd.DataFrame.from_dict(metrics3d).transpose()\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92c734",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3-1 connections metrics\n",
    "metrics3_1_df = pd.DataFrame.from_dict(metrics3_1).transpose()\n",
    "# may show MLP metrics only\n",
    "metrics3_1_df[[\"MLP r2\", \"MLP RMSE\", \"MLP MAPE\", \"MLP rae\", \"MLP dcor\"]].sort_values(by=\"MLP r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e0c8c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run the plotting routine alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b86b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "issues:\n",
    "* [-2]: r2 of power law fit = 0 ! But dcor is good. MAPE high due to one y-value = 0.\n",
    "* [5]: r2 of MLP = 0 ! But actually, w.r.t. training data a rather good fit. dcor is good, too!\n",
    "* [-3]: bad MLP fit, but MAPE rather good due to y-values far away from 0.\n",
    "* [-4]: similar to above, MAPE again okay as high deviations exist mainly for predictions of high y-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa67fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_result(list(datas.keys())[-2], metrics, datas, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f6954",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#plot_3d_result(list(datas.keys())[2], metrics, datas, show=True)\n",
    "plot_3d_result(list(datas3d.keys())[11], metrics3d, datas3d, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a31344",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb87830",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9cd46ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### save dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd928f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3d data\n",
    "with open('metrics3d.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "with open('datas3d.pkl', 'wb') as f:\n",
    "    pickle.dump(datas, f)\n",
    "#with open('plots3d.pkl', 'wb') as f:\n",
    "#    pickle.dump(plots, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0775e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2d data\n",
    "with open('metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "with open('datas.pkl', 'wb') as f:\n",
    "    pickle.dump(datas, f)\n",
    "#with open('plots.pkl', 'wb') as f:\n",
    "#    pickle.dump(plots, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f2060",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### load dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2777f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2d data\n",
    "with open('metrics.pkl', 'rb') as f:\n",
    "    metrics = pickle.load(f)\n",
    "with open('datas.pkl', 'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "#with open('plots.pkl', 'rb') as f:\n",
    "#    plots = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e1f96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3d data\n",
    "with open('metrics3d.pkl', 'rb') as f:\n",
    "    metrics3d = pickle.load(f)\n",
    "with open('datas3d.pkl', 'rb') as f:\n",
    "    datas3d = pickle.load(f)\n",
    "#with open('plots3d.pkl', 'rb') as f:\n",
    "#    plots = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705ceaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "with open('metrics3_1.pkl', 'rb') as f:\n",
    "    metrics3_1 = pickle.load(f)\n",
    "with open('datas3_1.pkl', 'rb') as f:\n",
    "    datas3_1 = pickle.load(f)\n",
    "#with open('plots3d.pkl', 'rb') as f:\n",
    "#    plots = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077b1b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### or backups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decb9d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('metrics_backup.pkl', 'rb') as f:\n",
    "    metrics_backup = pickle.load(f)\n",
    "with open('datas_backup.pkl', 'rb') as f:\n",
    "    datas_backup = pickle.load(f)\n",
    "with open('plots_backup.pkl', 'rb') as f:\n",
    "    plots_backup = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416a5ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Big run on 4-1 connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8058b5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics_4_1, datas_4_1 = predictability(data=df2007,\n",
    "                                input_cols=4,\n",
    "                                output_cols=1,\n",
    "                                primkey_cols = prim_keys,\n",
    "                                scoring=\"RMSE\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ddf1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datas_4_1[('Agriculture, value added (% of GDP)',\n",
    "  'CO2 emissions (metric tons per capita)',\n",
    "  'Domestic credit provided by financial sector (% of GDP)',\n",
    "  'Electric power consumption (kWh per capita)',\n",
    "  'Exports of goods and services (% of GDP)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f86f57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('metrics_4_1.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_4_1, f)\n",
    "with open('datas_4_1.pkl', 'wb') as f:\n",
    "    pickle.dump(datas_4_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a11ec5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Big run to check dependency on scoring choice during GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ec53f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# big run through all 4 scorings\n",
    "metrics_scorings = {}\n",
    "for scoring in [\"RMSE\", \"MAPE\", \"r2\", \"MAE\"]:\n",
    "    curr_metrics, curr_datas = predictability(data=df2007,\n",
    "                                input_cols=1,\n",
    "                                output_cols=1,\n",
    "                                primkey_cols = prim_keys,\n",
    "                                scoring=scoring\n",
    "                               )\n",
    "    metrics_scorings[scoring] = curr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07415f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('metrics_scorings.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_scorings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf8bf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics_scorings_df = pd.DataFrame.from_dict(metrics_scorings)#.transpose()\n",
    "RMSE_metrics = metrics_scorings_df['RMSE'].apply(pd.Series)[[\"MLP r2\", \"MLP RMSE\", \"MLP MAPE\", \"MLP rae\", \"MLP dcor\"]]\n",
    "RMSE_metrics.columns = pd.MultiIndex.from_product([[\"RMSE scoring\"], RMSE_metrics.columns])\n",
    "all_metrics_df = RMSE_metrics.copy(deep=True)\n",
    "for scoring in [\"r2\", \"MAPE\", \"MAE\"]:\n",
    "    curr_metrics_df = metrics_scorings_df[scoring].apply(pd.Series)[[\"MLP r2\", \"MLP RMSE\", \"MLP MAPE\", \"MLP rae\", \"MLP dcor\"]]\n",
    "    curr_metrics_df.columns = pd.MultiIndex.from_product([[scoring+\" scoring\"], curr_metrics_df.columns])\n",
    "    all_metrics_df = pd.concat([all_metrics_df, curr_metrics_df], axis=1)\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84929554",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e5e5799",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tests and checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccae09f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### all combinatinos for, e.g., 2-1 connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8210ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_cols = [\"a\", \"b\", \"c\", \n",
    "            \"d\",# \"e\", \"f\"\n",
    "           ]\n",
    "inputs = 2\n",
    "outputs = 1\n",
    "def get_column_combinations(all_cols, inputs, outputs):\n",
    "    \n",
    "    assert inputs+outputs <= len(all_cols), \"More input and output columns specified than there are columns.\"\n",
    "    \n",
    "    # initialise final list of column combinations\n",
    "    col_combinations = []\n",
    "    # first, draw possible input tuples\n",
    "    input_combinations = list(itertools.combinations(all_cols, inputs))\n",
    "    # now go through all possible input combinations\n",
    "    for i in input_combinations:\n",
    "        # get list of possible output columns, i.e. columns that are not yet part of current input columns\n",
    "        curr_output_cols = [o for o in all_cols if o not in i]\n",
    "        # now draw from that list all currently possible output combinations\n",
    "        output_combinations = list(itertools.combinations(curr_output_cols, outputs))\n",
    "        # add all currently possible output combinations to the current input columns and save in final list\n",
    "        for oc in output_combinations:\n",
    "            col_combinations.append(i+(*oc,))\n",
    "        \n",
    "    return col_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06e853",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_column_combinations(all_cols, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e528972",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53881630",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df = df2007[[\"Electric power consumption (kWh per capita)\", \"Life expectancy at birth, total (years)\"]].dropna()\n",
    "test_x = test_df[[\"Electric power consumption (kWh per capita)\"]].values.flatten()\n",
    "test_y = test_df[[\"Life expectancy at birth, total (years)\"]].values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bbd46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['Agriculture, value added (% of GDP)', 'Domestic credit provided by financial sector (% of GDP)']\n",
    "test_df = df2007[cols].dropna()\n",
    "x_subtraction = 1.05*min(test_df[cols[0]].values)-0.01\n",
    "y_subtraction = 1.05*min(test_df[cols[1]].values)-0.01\n",
    "test_x = test_df[cols[0]].values.flatten()-x_subtraction\n",
    "test_y = test_df[cols[1]].values.flatten()-y_subtraction\n",
    "print(x_subtraction, y_subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd0389",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_params = fit_power_law_1_1(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae9592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92dad6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_test_y = power_law_1_1(test_x, *test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549cad1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(test_x+x_subtraction, test_y+y_subtraction, \"bo\", label=\"data\")\n",
    "plt.plot(test_x+x_subtraction, pred_test_y+y_subtraction, \"ro\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8831ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec60f007",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modify get_column_combinations to also allow for specifying target column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2facf64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_column_combinations_w_targets(all_cols, inputs, outputs, targets):\n",
    "    \n",
    "    assert inputs+outputs <= len(all_cols), \"More input and output columns specified than there are columns.\"\n",
    "    \n",
    "    # initialise final list of column combinations\n",
    "    col_combinations = []\n",
    "    \n",
    "    if targets:\n",
    "        all_input_cols = [x for x in all_cols if x not in targets]\n",
    "    else:\n",
    "        all_input_cols = all_cols\n",
    "        \n",
    "    # first, draw possible input tuples\n",
    "    input_combinations = list(itertools.combinations(all_input_cols, inputs))\n",
    "    # now go through all possible input combinations\n",
    "    for i in input_combinations:\n",
    "        if targets:\n",
    "            curr_output_cols = targets\n",
    "        else:\n",
    "            # get list of possible output columns, i.e. columns that are not yet part of current input columns\n",
    "            curr_output_cols = [o for o in all_cols if o not in i]\n",
    "        # now draw from that list all currently possible output combinations\n",
    "        output_combinations = list(itertools.combinations(curr_output_cols, outputs))\n",
    "        # add all currently possible output combinations to the current input columns and save in final list\n",
    "        for oc in output_combinations:\n",
    "            col_combinations.append(i+(*oc,))\n",
    "        \n",
    "    return col_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8958f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_column_combinations([\"a\", \"b\", \"c\", \"d\", \"e\"], 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb6bd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_column_combinations_w_targets([\"a\", \"b\", \"c\", \"d\", \"e\"], 2, 2, [\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c64498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbe524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc3a3dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5b5a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predictability(data, input_cols=1, output_cols=1, col_set=None, primkey_cols=[], targets=[],\n",
    "                   method=\"MLP\", hidden_layers=None, alphas=None, scoring=\"r2\", scaling=True, \n",
    "                   max_iter=10000, n_jobs=-1, verbose=1):\n",
    "    \n",
    "    # TODO: map scoring to possible options\n",
    "    scoring_dict = {\n",
    "        \"r2\": \"r2\",\n",
    "        \"MAPE\": \"neg_mean_absolute_percentage_error\",\n",
    "        \"neg_mean_absolute_percentage_error\": \"neg_mean_absolute_percentage_error\",\n",
    "        \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "        \"MAE\": \"neg_mean_absolute_error\",\n",
    "        \"neg_mean_absolute_error\": \"neg_mean_absolute_error\"\n",
    "    }\n",
    "    scoring = scoring_dict[scoring]\n",
    "    \n",
    "    # if we want to measure the overall time\n",
    "    start = time.time()\n",
    "    \n",
    "    # initialise the dictionary that is going to save the metrics per tuple\n",
    "    metric_dict = {}\n",
    "    \n",
    "    # dict to save x-/y-train/-test and predicted values for subsequent plotting\n",
    "    data_dict = {}\n",
    "    \n",
    "    # if primary keys are fed in, data columns should not contain these\n",
    "    data_cols = [col for col in data.columns.to_list() if col not in primkey_cols]\n",
    "    \n",
    "    # if set of columns that should be considered is fed in, use this\n",
    "    if col_set is not None:\n",
    "        data_cols = list(set(col_set))\n",
    "    \n",
    "    # get the list of tuples of input and output columns\n",
    "    if targets:\n",
    "        data_tuples = get_column_combinations_w_targets(data_cols, input_cols, output_cols, targets)\n",
    "    else:\n",
    "        data_tuples = get_column_combinations(data_cols, input_cols, output_cols)    \n",
    "    \n",
    "    # for printing the progress of the analysis\n",
    "    counter_tuples = 0\n",
    "    \n",
    "    # go through all tuples\n",
    "    # or testing subset only:\n",
    "    #data_tuples = [(\"Electric power consumption (kWh per capita)\", \"Life expectancy at birth, total (years)\")]+data_tuples[:5]\n",
    "    #\n",
    "    for curr_tuple in data_tuples:\n",
    "        \n",
    "        # if we want to measure the current tuple's analysis time\n",
    "        curr_start = time.time()\n",
    "        \n",
    "        print(\"Analysing \"+str(curr_tuple)+\" now.\")\n",
    "        \n",
    "        # TODO: implement going through all permutations\n",
    "        \n",
    "        # get current inputs and outputs\n",
    "        curr_inputs = list(curr_tuple[:input_cols])\n",
    "        curr_outputs = list(curr_tuple[input_cols:])\n",
    "        \n",
    "        # reduce data to current columns and drop NAs\n",
    "        curr_data = data[curr_inputs+curr_outputs].dropna()\n",
    "        \n",
    "        # dict of min values of current columns, used for power law fitting\n",
    "        mi_dict = {}\n",
    "        for col in curr_inputs+curr_outputs:\n",
    "            curr_min = min(curr_data[col])\n",
    "            if curr_min < 0:\n",
    "                x_subtraction = 1.05*curr_min\n",
    "            elif curr_min == 0:\n",
    "                x_subtraction = -0.05\n",
    "            else:\n",
    "                x_subtraction = 0\n",
    "            mi_dict[col] = x_subtraction\n",
    "            \n",
    "        \n",
    "        # do data preparations and train-test-split\n",
    "        curr_X_train, curr_X_test, curr_y_train, curr_y_test = data_prep_split(curr_data, curr_inputs, curr_outputs)\n",
    "        \n",
    "        # compute standard deviation of curr_y_test for later scaling of the RMSE\n",
    "        curr_y_test_std = np.std(curr_y_test)\n",
    "        \n",
    "        #\n",
    "        # y-mean \"prediction\"\n",
    "        #\n",
    "        curr_y_train_mean = np.mean(curr_y_train)\n",
    "        curr_y_test_pred_mean = curr_y_train_mean*np.ones(len(curr_X_test))\n",
    "        # metrics\n",
    "        curr_mean_r2 = r2_score(curr_y_test, curr_y_test_pred_mean)\n",
    "        curr_mean_rmse = mean_squared_error(curr_y_test, curr_y_test_pred_mean, squared=False)\n",
    "        curr_mean_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred_mean)\n",
    "        curr_mean_rae = rae(curr_y_test, curr_y_test_pred_mean)\n",
    "        curr_mean_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred_mean)\n",
    "        \n",
    "        #\n",
    "        # linear regression\n",
    "        #\n",
    "        lin_reg = LinearRegression().fit(curr_X_train,curr_y_train)\n",
    "        curr_y_test_pred = lin_reg.predict(curr_X_test)\n",
    "        # metrics\n",
    "        curr_lin_r2 = r2_score(curr_y_test, curr_y_test_pred)\n",
    "        curr_lin_rmse = mean_squared_error(curr_y_test, curr_y_test_pred, squared=False)\n",
    "        curr_lin_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred)\n",
    "        curr_lin_rae = rae(curr_y_test, curr_y_test_pred)\n",
    "        curr_lin_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred)\n",
    "        \n",
    "        '''\n",
    "        # power law fit so far only for 1-1 connections implemented\n",
    "        if input_cols==1 and output_cols==1:\n",
    "            #\n",
    "            # power law fit\n",
    "            #\n",
    "            curr_y_test_pred_pl = fit_predict_power_law_1_1(curr_X_train, curr_X_test, curr_y_train, curr_y_test)\n",
    "\n",
    "            # metrics\n",
    "            curr_pl_r2 = r2_score(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rmse = mean_squared_error(curr_y_test, curr_y_test_pred_pl, squared=False)\n",
    "            curr_pl_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rae = rae(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred_pl)\n",
    "            '''\n",
    "        #\n",
    "        # power law fit\n",
    "        #\n",
    "        if ((curr_X_train>0).all().all()) and ((curr_X_test>0).all().all()):\n",
    "            do_pl_fit = True\n",
    "        else:\n",
    "            do_pl_fit = False\n",
    "        \n",
    "        if do_pl_fit:\n",
    "            \n",
    "            curr_X_train_log = curr_X_train.apply(lambda x: np.log(x))\n",
    "            curr_X_test_log = curr_X_test.apply(lambda x: np.log(x))\n",
    "            curr_y_train_log = curr_y_train.apply(lambda x: np.log(x))\n",
    "            #curr_y_test_log = curr_y_test.apply(lambda x: np.log(x))\n",
    "            \n",
    "            pl_fit = LinearRegression().fit(curr_X_train_log, curr_y_train_log)\n",
    "            \n",
    "            curr_y_test_pred_pl = pl_fit.predict(curr_X_test_log)\n",
    "            \n",
    "            curr_y_test_pred_pl = np.exp(curr_y_test_pred_pl)\n",
    "            \n",
    "            # metrics\n",
    "            curr_pl_r2 = r2_score(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rmse = mean_squared_error(curr_y_test, curr_y_test_pred_pl, squared=False)\n",
    "            curr_pl_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_rae = rae(curr_y_test, curr_y_test_pred_pl)\n",
    "            curr_pl_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred_pl)\n",
    "            \n",
    "        \n",
    "        #\n",
    "        # MLP regression\n",
    "        print(\"start MLP routine\")\n",
    "        #\n",
    "        # list of hidden layer sizes for GridSearch\n",
    "        if hidden_layers is None:\n",
    "            hidden_layers = [(12,), \n",
    "                              (50,), \n",
    "                              (70,5,), \n",
    "                              #(40,18,3,)\n",
    "                            ]\n",
    "        # list of alpha values for GridSearch\n",
    "        if alphas is None:\n",
    "            alphas = [0.001, \n",
    "                      0.0001, \n",
    "                      0.00001\n",
    "                     ]\n",
    "\n",
    "        # via pipeline (with and without scaler)\n",
    "        if scaling==\"yes\":\n",
    "            pipe = Pipeline([\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('mlp', MLPRegressor(max_iter=max_iter))\n",
    "                            ])\n",
    "            pipe_params = [\n",
    "                           {'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}\n",
    "                            ]\n",
    "            clf = GridSearchCV(pipe,\n",
    "                               param_grid=pipe_params,\n",
    "                               cv=3,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                               verbose=verbose,\n",
    "                               n_jobs=n_jobs\n",
    "                              )        \n",
    "        elif scaling==\"no\":\n",
    "            pipe = Pipeline([\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('mlp', MLPRegressor(max_iter=max_iter))\n",
    "                            ])\n",
    "            pipe_params = [{'scaler': ['passthrough'],\n",
    "                            'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}]\n",
    "            clf = GridSearchCV(pipe,\n",
    "                               param_grid=pipe_params,\n",
    "                               cv=3,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                               verbose=verbose,\n",
    "                               n_jobs=n_jobs\n",
    "                              )\n",
    "        else:\n",
    "            pipe = Pipeline([\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('mlp', MLPRegressor(max_iter=max_iter))\n",
    "                            ])\n",
    "            pipe_params = [{'scaler': ['passthrough'],\n",
    "                            'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}, \n",
    "                           {'mlp__hidden_layer_sizes': hidden_layers,\n",
    "                            'mlp__alpha': alphas}]\n",
    "            clf = GridSearchCV(pipe,\n",
    "                               param_grid=pipe_params,\n",
    "                               cv=3,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                               verbose=verbose,\n",
    "                               n_jobs=n_jobs\n",
    "                              )\n",
    "        \n",
    "        clf.fit(curr_X_train, curr_y_train)\n",
    "        \n",
    "        curr_best_params = clf.best_params_\n",
    "        curr_y_test_pred = clf.predict(curr_X_test)\n",
    "        \n",
    "        # metrics\n",
    "        curr_mlp_r2 = r2_score(curr_y_test, curr_y_test_pred)\n",
    "        curr_mlp_rmse = mean_squared_error(curr_y_test, curr_y_test_pred, squared=False)\n",
    "        curr_mlp_mape = mean_absolute_percentage_error(curr_y_test, curr_y_test_pred)\n",
    "        curr_mlp_rae = rae(curr_y_test, curr_y_test_pred)\n",
    "        curr_mlp_dcor = dcor.distance_correlation(curr_y_test, curr_y_test_pred)\n",
    "\n",
    "        # save metrics into dict\n",
    "        # power law fit so far only for 1-1 connections implemented\n",
    "        if do_pl_fit:\n",
    "            metric_dict[curr_tuple] = {\"MLP r2\": curr_mlp_r2, \"linear r2\": curr_lin_r2, \n",
    "                                       \"pow. law r2\": curr_pl_r2, \"mean r2\": curr_mean_r2, \n",
    "                                        \"MLP RMSE\": curr_mlp_rmse, \"linear RMSE\": curr_lin_rmse,\n",
    "                                        \"pow. law RMSE\": curr_pl_rmse, \"mean RMSE\": curr_mean_rmse,\n",
    "                                        \"MLP RMSE/std\": curr_mlp_rmse/curr_y_test_std, \"linear RMSE/std\": curr_lin_rmse/curr_y_test_std,\n",
    "                                       \"pow. law RMSE/std\": curr_pl_rmse/curr_y_test_std, \"mean RMSE/std\": curr_mean_rmse/curr_y_test_std,\n",
    "                                        \"MLP MAPE\": curr_mlp_mape, \"linear MAPE\": curr_lin_mape,\n",
    "                                       \"pow. law MAPE\": curr_pl_mape, \"mean MAPE\": curr_mean_mape,\n",
    "                                        \"MLP rae\": curr_mlp_rae, \"linear rae\": curr_lin_rae,\n",
    "                                        \"pow. law rae\": curr_pl_rae, \"mean rae\": curr_mean_rae,\n",
    "                                        \"MLP dcor\": curr_mlp_dcor, \"linear dcor\": curr_lin_dcor,\n",
    "                                        \"pow. law dcor\": curr_pl_dcor, \"mean dcor\": curr_mean_dcor,\n",
    "                                               }\n",
    "        else:\n",
    "            metric_dict[curr_tuple] = {\"MLP r2\": curr_mlp_r2, \"linear r2\": curr_lin_r2, \"mean r2\": curr_mean_r2, \n",
    "                                        \"MLP RMSE\": curr_mlp_rmse, \"linear RMSE\": curr_lin_rmse, \"mean RMSE\": curr_mean_rmse,\n",
    "                                        \"MLP RMSE/std\": curr_mlp_rmse/curr_y_test_std, \"linear RMSE/std\": curr_lin_rmse/curr_y_test_std,\n",
    "                                        \"mean RMSE/std\": curr_mean_rmse/curr_y_test_std,\n",
    "                                        \"MLP MAPE\": curr_mlp_mape, \"linear MAPE\": curr_lin_mape, \"mean MAPE\": curr_mean_mape,\n",
    "                                        \"MLP rae\": curr_mlp_rae, \"linear rae\": curr_lin_rae, \"mean rae\": curr_mean_rae,\n",
    "                                        \"MLP dcor\": curr_mlp_dcor, \"linear dcor\": curr_lin_dcor, \"mean dcor\": curr_mean_dcor,\n",
    "                                               }\n",
    "\n",
    "        # save values into dict\n",
    "        # power law fit so far only for 1-1 connections implemented\n",
    "        if do_pl_fit:\n",
    "            \n",
    "            data_dict[curr_tuple] = {\"X_train\": curr_X_train, \"X_test\": curr_X_test,\n",
    "                                     \"y_train\": curr_y_train, \"y_test\": curr_y_test, \"y_test_pred\": curr_y_test_pred,\n",
    "                                     \"y_test_pred_pl\": curr_y_test_pred_pl, \"y_test_pred_mean\": curr_y_test_pred_mean,\n",
    "                                     \"GridSearchParams\": curr_best_params, \"scores\": clf.cv_results_\n",
    "                                    }\n",
    "        else:\n",
    "            \n",
    "            data_dict[curr_tuple] = {\"X_train\": curr_X_train, \"X_test\": curr_X_test,\n",
    "                                     \"y_train\": curr_y_train, \"y_test\": curr_y_test, \"y_test_pred\": curr_y_test_pred,\n",
    "                                     \"y_test_pred_mean\": curr_y_test_pred_mean,\n",
    "                                     \"GridSearchParams\": curr_best_params, \"scores\": clf.cv_results_\n",
    "                                    }\n",
    "        \n",
    "                \n",
    "        # for printing the CV results per tuple\n",
    "        #print(clf.cv_results_)\n",
    "        \n",
    "        print(\"The analysis of this tuple took \"+str(round(time.time()-curr_start,2))+\"s.\")\n",
    "        # for printing the progress of the analysis\n",
    "        counter_tuples += 1\n",
    "        print(\"-----\"+str(counter_tuples)+\"/\"+str(len(data_tuples))+\"-----\")\n",
    "    \n",
    "    print(\"The whole run took \"+str(round(time.time()-start,2))+\"s.\")\n",
    "    \n",
    "    return metric_dict, data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ab9ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics, datas = predictability(data=df2007,\n",
    "                                input_cols=1,\n",
    "                                output_cols=1,\n",
    "                                col_set = ['Electric power consumption (kWh per capita)', \n",
    "                                           'Agriculture, value added (% of GDP)',\n",
    "                                           'Life expectancy at birth, total (years)', \n",
    "                                           'CO2 emissions (metric tons per capita)'],\n",
    "                                primkey_cols = prim_keys,\n",
    "                                scoring=\"RMSE\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict(metrics).transpose()\n",
    "\n",
    "# or 3d ones\n",
    "#metrics_df = pd.DataFrame.from_dict(metrics3d).transpose()\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de097b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3-1 connections metrics\n",
    "metrics3_1_df = pd.DataFrame.from_dict(metrics3_1).transpose()\n",
    "# may show MLP metrics only\n",
    "metrics3_1_df[[\"MLP r2\", \"MLP RMSE\", \"MLP MAPE\", \"MLP rae\", \"MLP dcor\"]].sort_values(by=\"MLP r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4c643",
   "metadata": {},
   "source": [
    "### Run the plotting routine alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f0e92",
   "metadata": {},
   "source": [
    "issues:\n",
    "* [-2]: r2 of power law fit = 0 ! But dcor is good. MAPE high due to one y-value = 0.\n",
    "* [5]: r2 of MLP = 0 ! But actually, w.r.t. training data a rather good fit. dcor is good, too!\n",
    "* [-3]: bad MLP fit, but MAPE rather good due to y-values far away from 0.\n",
    "* [-4]: similar to above, MAPE again okay as high deviations exist mainly for predictions of high y-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b838b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_2d_result(list(datas.keys())[-2], metrics, datas, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac014c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_3d_result(list(datas.keys())[2], metrics, datas, show=True)\n",
    "plot_3d_result(list(datas3d.keys())[11], metrics3d, datas3d, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eb1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e720d08",
   "metadata": {},
   "source": [
    "### save dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d data\n",
    "with open('metrics3d.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "with open('datas3d.pkl', 'wb') as f:\n",
    "    pickle.dump(datas, f)\n",
    "#with open('plots3d.pkl', 'wb') as f:\n",
    "#    pickle.dump(plots, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a596b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d data\n",
    "with open('metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "with open('datas.pkl', 'wb') as f:\n",
    "    pickle.dump(datas, f)\n",
    "#with open('plots.pkl', 'wb') as f:\n",
    "#    pickle.dump(plots, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6931d",
   "metadata": {},
   "source": [
    "### load dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d data\n",
    "with open('metrics.pkl', 'rb') as f:\n",
    "    metrics = pickle.load(f)\n",
    "with open('datas.pkl', 'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "#with open('plots.pkl', 'rb') as f:\n",
    "#    plots = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d data\n",
    "with open('metrics3d.pkl', 'rb') as f:\n",
    "    metrics3d = pickle.load(f)\n",
    "with open('datas3d.pkl', 'rb') as f:\n",
    "    datas3d = pickle.load(f)\n",
    "#with open('plots3d.pkl', 'rb') as f:\n",
    "#    plots = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "with open('metrics3_1.pkl', 'rb') as f:\n",
    "    metrics3_1 = pickle.load(f)\n",
    "with open('datas3_1.pkl', 'rb') as f:\n",
    "    datas3_1 = pickle.load(f)\n",
    "#with open('plots3d.pkl', 'rb') as f:\n",
    "#    plots = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae16e5c",
   "metadata": {},
   "source": [
    "#### or backups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('metrics_backup.pkl', 'rb') as f:\n",
    "    metrics_backup = pickle.load(f)\n",
    "with open('datas_backup.pkl', 'rb') as f:\n",
    "    datas_backup = pickle.load(f)\n",
    "with open('plots_backup.pkl', 'rb') as f:\n",
    "    plots_backup = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a55ad5",
   "metadata": {},
   "source": [
    "### Big run on 4-1 connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eb471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_4_1, datas_4_1 = predictability(data=df2007,\n",
    "                                input_cols=4,\n",
    "                                output_cols=1,\n",
    "                                primkey_cols = prim_keys,\n",
    "                                scoring=\"RMSE\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_4_1[('Agriculture, value added (% of GDP)',\n",
    "  'CO2 emissions (metric tons per capita)',\n",
    "  'Domestic credit provided by financial sector (% of GDP)',\n",
    "  'Electric power consumption (kWh per capita)',\n",
    "  'Exports of goods and services (% of GDP)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metrics_4_1.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_4_1, f)\n",
    "with open('datas_4_1.pkl', 'wb') as f:\n",
    "    pickle.dump(datas_4_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b31126",
   "metadata": {},
   "source": [
    "## Big run to check dependency on scoring choice during GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big run through all 4 scorings\n",
    "metrics_scorings = {}\n",
    "for scoring in [\"RMSE\", \"MAPE\", \"r2\", \"MAE\"]:\n",
    "    curr_metrics, curr_datas = predictability(data=df2007,\n",
    "                                input_cols=1,\n",
    "                                output_cols=1,\n",
    "                                primkey_cols = prim_keys,\n",
    "                                scoring=scoring\n",
    "                               )\n",
    "    metrics_scorings[scoring] = curr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324498f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metrics_scorings.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_scorings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_scorings_df = pd.DataFrame.from_dict(metrics_scorings)#.transpose()\n",
    "RMSE_metrics = metrics_scorings_df['RMSE'].apply(pd.Series)[[\"MLP r2\", \"MLP RMSE\", \"MLP MAPE\", \"MLP rae\", \"MLP dcor\"]]\n",
    "RMSE_metrics.columns = pd.MultiIndex.from_product([[\"RMSE scoring\"], RMSE_metrics.columns])\n",
    "all_metrics_df = RMSE_metrics.copy(deep=True)\n",
    "for scoring in [\"r2\", \"MAPE\", \"MAE\"]:\n",
    "    curr_metrics_df = metrics_scorings_df[scoring].apply(pd.Series)[[\"MLP r2\", \"MLP RMSE\", \"MLP MAPE\", \"MLP rae\", \"MLP dcor\"]]\n",
    "    curr_metrics_df.columns = pd.MultiIndex.from_product([[scoring+\" scoring\"], curr_metrics_df.columns])\n",
    "    all_metrics_df = pd.concat([all_metrics_df, curr_metrics_df], axis=1)\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb107aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb1fb52",
   "metadata": {},
   "source": [
    "## Tests and checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c53ec",
   "metadata": {},
   "source": [
    "### all combinatinos for, e.g., 2-1 connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [\"a\", \"b\", \"c\", \n",
    "            \"d\",# \"e\", \"f\"\n",
    "           ]\n",
    "inputs = 2\n",
    "outputs = 1\n",
    "def get_column_combinations(all_cols, inputs, outputs):\n",
    "    \n",
    "    assert inputs+outputs <= len(all_cols), \"More input and output columns specified than there are columns.\"\n",
    "    \n",
    "    # initialise final list of column combinations\n",
    "    col_combinations = []\n",
    "    # first, draw possible input tuples\n",
    "    input_combinations = list(itertools.combinations(all_cols, inputs))\n",
    "    # now go through all possible input combinations\n",
    "    for i in input_combinations:\n",
    "        # get list of possible output columns, i.e. columns that are not yet part of current input columns\n",
    "        curr_output_cols = [o for o in all_cols if o not in i]\n",
    "        # now draw from that list all currently possible output combinations\n",
    "        output_combinations = list(itertools.combinations(curr_output_cols, outputs))\n",
    "        # add all currently possible output combinations to the current input columns and save in final list\n",
    "        for oc in output_combinations:\n",
    "            col_combinations.append(i+(*oc,))\n",
    "        \n",
    "    return col_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf220af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_combinations(all_cols, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f2691",
   "metadata": {},
   "source": [
    "### other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df2007[[\"Electric power consumption (kWh per capita)\", \"Life expectancy at birth, total (years)\"]].dropna()\n",
    "test_x = test_df[[\"Electric power consumption (kWh per capita)\"]].values.flatten()\n",
    "test_y = test_df[[\"Life expectancy at birth, total (years)\"]].values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d128bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Agriculture, value added (% of GDP)', 'Domestic credit provided by financial sector (% of GDP)']\n",
    "test_df = df2007[cols].dropna()\n",
    "x_subtraction = 1.05*min(test_df[cols[0]].values)-0.01\n",
    "y_subtraction = 1.05*min(test_df[cols[1]].values)-0.01\n",
    "test_x = test_df[cols[0]].values.flatten()-x_subtraction\n",
    "test_y = test_df[cols[1]].values.flatten()-y_subtraction\n",
    "print(x_subtraction, y_subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = fit_power_law_1_1(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2eabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = power_law_1_1(test_x, *test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_x+x_subtraction, test_y+y_subtraction, \"bo\", label=\"data\")\n",
    "plt.plot(test_x+x_subtraction, pred_test_y+y_subtraction, \"ro\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2ebc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8ce5232",
   "metadata": {},
   "source": [
    "## Modify get_column_combinations to also allow for specifying target column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20937b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_combinations_w_targets(all_cols, inputs, outputs, targets):\n",
    "    \n",
    "    assert inputs+outputs <= len(all_cols), \"More input and output columns specified than there are columns.\"\n",
    "    \n",
    "    # initialise final list of column combinations\n",
    "    col_combinations = []\n",
    "    \n",
    "    if targets:\n",
    "        all_input_cols = [x for x in all_cols if x not in targets]\n",
    "    else:\n",
    "        all_input_cols = all_cols\n",
    "        \n",
    "    # first, draw possible input tuples\n",
    "    input_combinations = list(itertools.combinations(all_input_cols, inputs))\n",
    "    # now go through all possible input combinations\n",
    "    for i in input_combinations:\n",
    "        if targets:\n",
    "            curr_output_cols = targets\n",
    "        else:\n",
    "            # get list of possible output columns, i.e. columns that are not yet part of current input columns\n",
    "            curr_output_cols = [o for o in all_cols if o not in i]\n",
    "        # now draw from that list all currently possible output combinations\n",
    "        output_combinations = list(itertools.combinations(curr_output_cols, outputs))\n",
    "        # add all currently possible output combinations to the current input columns and save in final list\n",
    "        for oc in output_combinations:\n",
    "            col_combinations.append(i+(*oc,))\n",
    "        \n",
    "    return col_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_combinations([\"a\", \"b\", \"c\", \"d\", \"e\"], 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_combinations_w_targets([\"a\", \"b\", \"c\", \"d\", \"e\"], 2, 2, [\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837dc64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
